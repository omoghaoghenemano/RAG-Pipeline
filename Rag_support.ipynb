{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dad12d06c1a44a018c6026fb27244c6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ce480ef53764d6485afe8063bf2b2d0",
              "IPY_MODEL_e1bcc1acf1d342bbb59bf98936fa112a",
              "IPY_MODEL_3fa53b961f394848b6031ad986699e1a"
            ],
            "layout": "IPY_MODEL_5f56720d07c540e1b1145c06efbccf7a"
          }
        },
        "8ce480ef53764d6485afe8063bf2b2d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba1dcbb19bb84283925a5b3849ab5e4c",
            "placeholder": "​",
            "style": "IPY_MODEL_ef974dc5bbd849d8881174903c251ecf",
            "value": "Fetching 30 files: 100%"
          }
        },
        "e1bcc1acf1d342bbb59bf98936fa112a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b43bf0a6d21403f914acf762fa61682",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9054c7eb35f840a990d5a10f26cb82e9",
            "value": 30
          }
        },
        "3fa53b961f394848b6031ad986699e1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c3c47250bb145bebc202815be3aea2a",
            "placeholder": "​",
            "style": "IPY_MODEL_362dede522cd4fbe96f86790d2c403e8",
            "value": " 30/30 [00:00&lt;00:00, 659.80it/s]"
          }
        },
        "5f56720d07c540e1b1145c06efbccf7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba1dcbb19bb84283925a5b3849ab5e4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef974dc5bbd849d8881174903c251ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b43bf0a6d21403f914acf762fa61682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9054c7eb35f840a990d5a10f26cb82e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5c3c47250bb145bebc202815be3aea2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "362dede522cd4fbe96f86790d2c403e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX_VRLiQ10S-",
        "outputId": "61bac203-46ad-4a5b-8c5d-2cf54f2ec3d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting FlagEmbedding\n",
            "  Downloading FlagEmbedding-1.2.10.tar.gz (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (2.3.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from FlagEmbedding) (4.41.2)\n",
            "Collecting datasets (from FlagEmbedding)\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate>=0.20.1 (from FlagEmbedding)\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentence_transformers (from FlagEmbedding)\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.23.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.1->FlagEmbedding) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->FlagEmbedding)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->FlagEmbedding) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->FlagEmbedding)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->FlagEmbedding) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->FlagEmbedding) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->FlagEmbedding) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->FlagEmbedding) (4.66.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets->FlagEmbedding)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->FlagEmbedding)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (2.0.3)\n",
            "Collecting requests (from transformers>=4.33.0->FlagEmbedding)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash (from datasets->FlagEmbedding)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets->FlagEmbedding)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->FlagEmbedding) (3.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers->FlagEmbedding) (9.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->FlagEmbedding) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->FlagEmbedding) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->FlagEmbedding) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->FlagEmbedding) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.33.0->FlagEmbedding) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->FlagEmbedding) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->FlagEmbedding) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->FlagEmbedding) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->FlagEmbedding) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers->FlagEmbedding) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->FlagEmbedding) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->FlagEmbedding) (1.16.0)\n",
            "Building wheels for collected packages: FlagEmbedding\n",
            "  Building wheel for FlagEmbedding (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for FlagEmbedding: filename=FlagEmbedding-1.2.10-py3-none-any.whl size=166100 sha256=1b1ed489e33a1c6dc8c8af2296b8e79903ccca54fa6824c141689d36aed48422\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/1d/d2/eec38cd59144f4c9767d7c55cfae8e8feec699071aa41ca5da\n",
            "Successfully built FlagEmbedding\n",
            "Installing collected packages: xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, sentence_transformers, accelerate, FlagEmbedding\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed FlagEmbedding-1.2.10 accelerate-0.32.1 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pyarrow-16.1.0 requests-2.32.3 sentence_transformers-3.0.1 xxhash-3.4.1\n"
          ]
        }
      ],
      "source": [
        "pip install -U FlagEmbedding\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import string\n",
        "\n",
        "# Load the spaCy model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Tokenize the context\n",
        "def tokenize_context(context):\n",
        "    doc = nlp(context)\n",
        "    tokens = [token.text.lower() for token in doc if not token.is_stop and not token.is_punct  and not token.is_space ]\n",
        "    return tokens\n",
        "\n",
        "def chunk_context(context, batch_size=512):\n",
        "    doc = nlp(context)\n",
        "    chunks = []\n",
        "    for i in range(0, len(doc), batch_size):\n",
        "        chunk = \" \".join([token.text.lower() for token in doc[i:i+batch_size] if not token.is_stop and not token.is_punct  and not token.is_space])\n",
        "        chunks.append(chunk)\n",
        "    return chunks\n",
        "\n",
        "\n",
        "context = \"\"\"\n",
        "For the journal, see Machine Learning (journal).\n",
        "\"Statistical learning\" redirects here. For statistical learning in linguistics, see statistical learning in language acquisition.\n",
        "Part of a series on\n",
        "Machine learning\n",
        "and data mining\n",
        "Paradigms\n",
        "Problems\n",
        "Supervised learning\n",
        "(classification • regression)\n",
        "Clustering\n",
        "Dimensionality reduction\n",
        "Structured prediction\n",
        "Anomaly detection\n",
        "Artificial neural network\n",
        "Reinforcement learning\n",
        "Learning with humans\n",
        "Model diagnostics\n",
        "Mathematical foundations\n",
        "Machine-learning venues\n",
        "Related articles\n",
        "vte\n",
        "Part of a series on\n",
        "Artificial intelligence\n",
        "\n",
        "Major goals\n",
        "Artificial general intelligenceIntelligent AgentRecursive self-improvementPlanningComputer visionGeneral game playingKnowledge reasoningNatural language processingRoboticsAI safety\n",
        "Approaches\n",
        "Applications\n",
        "Philosophy\n",
        "History\n",
        "Glossary\n",
        "vte\n",
        "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data and thus perform tasks without explicit instructions.[1] Recently, artificial neural networks have been able to surpass many previous approaches in performance.[2]\n",
        "\n",
        "ML finds application in many fields, including natural language processing, computer vision, speech recognition, email filtering, agriculture, and medicine.[3][4] When applied to business problems, it is known under the name predictive analytics. Although not all machine learning is statistically based, computational statistics is an important source of the field's methods.\n",
        "\n",
        "The mathematical foundations of ML are provided by mathematical optimization (mathematical programming) methods. Data mining is a related (parallel) field of study, focusing on exploratory data analysis (EDA) through unsupervised learning.[6][7]\n",
        "\n",
        "From a theoretical viewpoint, probably approximately correct (PAC) learning provides a framework for describing machine learning.\n",
        "\n",
        "History\n",
        "See also: Timeline of machine learning\n",
        "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and pioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym self-teaching computers was also used in this time period.[10][11]\n",
        "\n",
        "Although the earliest machine learning model was introduced in the 1950s when Arthur Samuel invented a program that calculated the winning chance in checkers for each side, the history of machine learning roots back to decades of human desire and effort to study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb published the book The Organization of Behavior, in which he introduced a theoretical neural structure formed by certain interactions among nerve cells.[13] Hebb's model of neurons interacting with one another set a groundwork for how AIs and machine learning algorithms work under nodes, or artificial neurons used by computers to communicate data.[12] Other researchers who have studied human cognitive systems contributed to the modern machine learning technologies as well, including logician Walter Pitts and Warren McCulloch, who proposed the early mathematical models of neural networks to come up with algorithms that mirror human thought processes.[12]\n",
        "\n",
        "By the early 1960s an experimental \"learning machine\" with punched tape memory, called Cybertron, had been developed by Raytheon Company to analyze sonar signals, electrocardiograms, and speech patterns using rudimentary reinforcement learning. It was repetitively \"trained\" by a human operator/teacher to recognize patterns and equipped with a \"goof\" button to cause it to reevaluate incorrect decisions.[14] A representative book on research into machine learning during the 1960s was Nilsson's book on Learning Machines, dealing mostly with machine learning for pattern classification.[15] Interest related to pattern recognition continued into the 1970s, as described by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching strategies so that an artificial neural network learns to recognize 40 characters (26 letters, 10 digits, and 4 special symbols) from a computer terminal.[17]\n",
        "\n",
        "Tom M. Mitchell provided a widely quoted, more formal definition of the algorithms studied in the machine learning field: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"[18] This definition of the tasks in which machine learning is concerned offers a fundamentally operational definition rather than defining the field in cognitive terms. This follows Alan Turing's proposal in his paper \"Computing Machinery and Intelligence\", in which the question \"Can machines think?\" is replaced with the question \"Can machines do what we (as thinking entities) can do?\".[19]\n",
        "\n",
        "Modern-day machine learning has two objectives. One is to classify data based on models which have been developed; the other purpose is to make predictions for future outcomes based on these models. A hypothetical algorithm specific to classifying data may use computer vision of moles coupled with supervised learning in order to train it to classify the cancerous moles. A machine learning algorithm for stock trading may inform the trader of future potential predictions.[20]\n",
        "\n",
        "Relationships to other fields\n",
        "Artificial intelligence\n",
        "\n",
        "Machine learning as subfield of AI[21]\n",
        "As a scientific endeavor, machine learning grew out of the quest for artificial intelligence (AI). In the early days of AI as an academic discipline, some researchers were interested in having machines learn from data. They attempted to approach the problem with various symbolic methods, as well as what were then termed \"neural networks\"; these were mostly perceptrons and other models that were later found to be reinventions of the generalized linear models of statistics.[22] Probabilistic reasoning was also employed, especially in automated medical diagnosis.[23]: 488\n",
        "\n",
        "However, an increasing emphasis on the logical, knowledge-based approach caused a rift between AI and machine learning. Probabilistic systems were plagued by theoretical and practical problems of data acquisition and representation.[23]: 488  By 1980, expert systems had come to dominate AI, and statistics was out of favor.[24] Work on symbolic/knowledge-based learning did continue within AI, leading to inductive logic programming(ILP), but the more statistical line of research was now outside the field of AI proper, in pattern recognition and information retrieval.[23]: 708–710, 755  Neural networks research had been abandoned by AI and computer science around the same time. This line, too, was continued outside the AI/CS field, as \"connectionism\", by researchers from other disciplines including Hopfield, Rumelhart, and Hinton. Their main success came in the mid-1980s with the reinvention of backpropagation.[23]: 25\n",
        "\n",
        "Machine learning (ML), reorganized and recognized as its own field, started to flourish in the 1990s. The field changed its goal from achieving artificial intelligence to tackling solvable problems of a practical nature. It shifted focus away from the symbolic approaches it had inherited from AI, and toward methods and models borrowed from statistics, fuzzy logic, and probability theory.[24]\n",
        "\n",
        "Data compression\n",
        "This section is an excerpt from Data compression § Machine learning.[edit]\n",
        "There is a close connection between machine learning and compression. A system that predicts the posterior probabilities of a sequence given its entire history can be used for optimal data compression (by using arithmetic coding on the output distribution). Conversely, an optimal compressor can be used for prediction (by finding the symbol that compresses best, given the previous history). This equivalence has been used as a justification for using data compression as a benchmark for \"general intelligence\".[25][26][27]\n",
        "\n",
        "An alternative view can show compression algorithms implicitly map strings into implicit feature space vectors, and compression-based similarity measures compute similarity within these feature spaces. For each compressor C(.) we define an associated vector space ℵ, such that C(.) maps an input string x, corresponding to the vector norm ||~x||. An exhaustive examination of the feature spaces underlying all compression algorithms is precluded by space; instead, feature vectors chooses to examine three representative lossless compression methods, LZW, LZ77, and PPM.[28]\n",
        "\n",
        "According to AIXI theory, a connection more directly explained in Hutter Prize, the best possible compression of x is the smallest possible software that generates x. For example, in that model, a zip file's compressed size includes both the zip file and the unzipping software, since you can not unzip it without both, but there may be an even smaller combined form.\n",
        "\n",
        "Examples of AI-powered audio/video compression software include NVIDIA Maxine, AIVC.[29] Examples of software that can perform AI-powered image compression include OpenCV, TensorFlow, MATLAB's Image Processing Toolbox (IPT) and High-Fidelity Generative Image Compression.[30]\n",
        "\n",
        "In unsupervised machine learning, k-means clustering can be utilized to compress data by grouping similar data points into clusters. This technique simplifies handling extensive datasets that lack predefined labels and finds widespread use in fields such as image compression.[31]\n",
        "\n",
        "Data compression aims to reduce the size of data files, enhancing storage efficiency and speeding up data transmission. K-means clustering, an unsupervised machine learning algorithm, is employed to partition a dataset into a specified number of clusters, k, each represented by the centroid of its points. This process condenses extensive datasets into a more compact set of representative points. Particularly beneficial in image and signal processing, k-means clustering aids in data reduction by replacing groups of data points with their centroids, thereby preserving the core information of the original data while significantly decreasing the required storage space.[32]\n",
        "\n",
        "Large language models (LLMs) are also capable of lossless data compression, as demonstrated by DeepMind's research with the Chinchilla 70B model. Developed by DeepMind, Chinchilla 70B effectively compressed data, outperforming conventional methods such as Portable Network Graphics (PNG) for images and Free Lossless Audio Codec (FLAC) for audio. It achieved compression of image and audio data to 43.4% and 16.4% of their original sizes, respectively.[33]\n",
        "Data mining\n",
        "Machine learning and data mining often employ the same methods and overlap significantly, but while machine learning focuses on prediction, based on known properties learned from the training data, data mining focuses on the discovery of (previously) unknown properties in the data (this is the analysis step of knowledge discovery in databases). Data mining uses many machine learning methods, but with different goals; on the other hand, machine learning also employs data mining methods as \"unsupervised learning\" or as a preprocessing step to improve learner accuracy. Much of the confusion between these two research communities (which do often have separate conferences and separate journals, ECML PKDD being a major exception) comes from the basic assumptions they work with: in machine learning, performance is usually evaluated with respect to the ability to reproduce known knowledge, while in knowledge discovery and data mining (KDD) the key task is the discovery of previously unknown knowledge. Evaluated with respect to known knowledge, an uninformed (unsupervised) method will easily be outperformed by other supervised methods, while in a typical KDD task, supervised methods cannot be used due to the unavailability of training data.\n",
        "\n",
        "Machine learning also has intimate ties to optimization: Many learning problems are formulated as minimization of some loss function on a training set of examples. Loss functions express the discrepancy between the predictions of the model being trained and the actual problem instances (for example, in classification, one wants to assign a label to instances, and models are trained to correctly predict the preassigned labels of a set of examples).[34]\n",
        "\n",
        "Generalization\n",
        "The difference between optimization and machine learning arises from the goal of generalization: While optimization algorithms can minimize the loss on a training set, machine learning is concerned with minimizing the loss on unseen samples. Characterizing the generalization of various learning algorithms is an active topic of current research, especially for deep learning algorithms.\n",
        "\n",
        "Statistics\n",
        "Machine learning and statistics are closely related fields in terms of methods, but distinct in their principal goal: statistics draws population inferences from a sample, while machine learning finds generalizable predictive patterns.[35] According to Michael I. Jordan, the ideas of machine learning, from methodological principles to theoretical tools, have had a long pre-history in statistics.[36] He also suggested the term data science as a placeholder to call the overall field.[36]\n",
        "\n",
        "Conventional statistical analyses require the a priori selection of a model most suitable for the study data set. In addition, only significant or theoretically relevant variables based on previous experience are included for analysis. In contrast, machine learning is not built on a pre-structured model; rather, the data shape the model by detecting underlying patterns. The more variables (input) used to train the model, the more accurate the ultimate model will be.[37]\n",
        "\n",
        "Leo Breiman distinguished two statistical modeling paradigms: data model and algorithmic model,[38] wherein \"algorithmic model\" means more or less the machine learning algorithms like Random Forest.\n",
        "\n",
        "Some statisticians have adopted methods from machine learning, leading to a combined field that they call statistical learning.[39]\n",
        "\n",
        "Statistical physics\n",
        "Analytical and computational techniques derived from deep-rooted physics of disordered systems can be extended to large-scale problems, including machine learning, e.g., to analyze the weight space of deep neural networks.[40] Statistical physics is thus finding applications in the area of medical diagnostics.[41]\n",
        "\n",
        "Theory\n",
        "Main articles: Computational learning theory and Statistical learning theory\n",
        "A core objective of a learner is to generalize from its experience.[5][42] Generalization in this context is the ability of a learning machine to perform accurately on new, unseen examples/tasks after having experienced a learning data set. The training examples come from some generally unknown probability distribution (considered representative of the space of occurrences) and the learner has to build a general model about this space that enables it to produce sufficiently accurate predictions in new cases.\n",
        "\n",
        "The computational analysis of machine learning algorithms and their performance is a branch of theoretical computer science known as computational learning theory via the Probably Approximately Correct Learning (PAC) model. Because training sets are finite and the future is uncertain, learning theory usually does not yield guarantees of the performance of algorithms. Instead, probabilistic bounds on the performance are quite common. The bias–variance decomposition is one way to quantify generalization error.\n",
        "\n",
        "For the best performance in the context of generalization, the complexity of the hypothesis should match the complexity of the function underlying the data. If the hypothesis is less complex than the function, then the model has under fitted the data. If the complexity of the model is increased in response, then the training error decreases. But if the hypothesis is too complex, then the model is subject to overfitting and generalization will be poorer.[43]\n",
        "\n",
        "In addition to performance bounds, learning theorists study the time complexity and feasibility of learning. In computational learning theory, a computation is considered feasible if it can be done in polynomial time. There are two kinds of time complexity results: Positive results show that a certain class of functions can be learned in polynomial time. Negative results show that certain classes cannot be learned in polynomial time.\n",
        "\n",
        "Approaches\n",
        "Machine learning approaches are traditionally divided into three broad categories, which correspond to learning paradigms, depending on the nature of the \"signal\" or \"feedback\" available to the learning system:\n",
        "\n",
        "Supervised learning: The computer is presented with example inputs and their desired outputs, given by a \"teacher\", and the goal is to learn a general rule that maps inputs to outputs.\n",
        "Unsupervised learning: No labels are given to the learning algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal in itself (discovering hidden patterns in data) or a means towards an end (feature learning).\n",
        "Reinforcement learning: A computer program interacts with a dynamic environment in which it must perform a certain goal (such as driving a vehicle or playing a game against an opponent). As it navigates its problem space, the program is provided feedback that's analogous to rewards, which it tries to maximize.[5]\n",
        "Although each algorithm has advantages and limitations, no single algorithm works for all problems.[44][45][46]\n",
        "\n",
        "Supervised learning\n",
        "Main article: Supervised learning\n",
        "\n",
        "A support-vector machine is a supervised learning model that divides the data into regions separated by a linear boundary. Here, the linear boundary divides the black circles from the white.\n",
        "Supervised learning algorithms build a mathematical model of a set of data that contains both the inputs and the desired outputs.[47] The data, known as training data, consists of a set of training examples. Each training example has one or more inputs and the desired output, also known as a supervisory signal. In the mathematical model, each training example is represented by an array or vector, sometimes called a feature vector, and the training data is represented by a matrix. Through iterative optimization of an objective function, supervised learning algorithms learn a function that can be used to predict the output associated with new inputs.[48] An optimal function allows the algorithm to correctly determine the output for inputs that were not a part of the training data. An algorithm that improves the accuracy of its outputs or predictions over time is said to have learned to perform that task.[18]\n",
        "\n",
        "Types of supervised-learning algorithms include active learning, classification and regression.[49] Classification algorithms are used when the outputs are restricted to a limited set of values, and regression algorithms are used when the outputs may have any numerical value within a range. As an example, for a classification algorithm that filters emails, the input would be an incoming email, and the output would be the name of the folder in which to file the email. Examples of regression would be predicting the height of a person, or the future temperature. [50]\n",
        "\n",
        "Similarity learning is an area of supervised machine learning closely related to regression and classification, but the goal is to learn from examples using a similarity function that measures how similar or related two objects are. It has applications in ranking, recommendation systems, visual identity tracking, face verification, and speaker verification.\n",
        "\n",
        "Unsupervised learning\n",
        "Main article: Unsupervised learning\n",
        "See also: Cluster analysis\n",
        "Unsupervised learning algorithms find structures in data that has not been labeled, classified or categorized. Instead of responding to feedback, unsupervised learning algorithms identify commonalities in the data and react based on the presence or absence of such commonalities in each new piece of data. Central applications of unsupervised machine learning include clustering, dimensionality reduction,[7] and density estimation.[51] Unsupervised learning algorithms also streamlined the process of identifying large indel based haplotypes of a gene of interest from pan-genome.[52]\n",
        "\n",
        "\n",
        "Clustering via Large Indel Permuted Slopes, CLIPS,[53] turns the alignment image into a learning regression problem. The varied slope (b) estimates between each pair of DNA segments enables to identify segments sharing the same set of indels.\n",
        "Cluster analysis is the assignment of a set of observations into subsets (called clusters) so that observations within the same cluster are similar according to one or more predesignated criteria, while observations drawn from different clusters are dissimilar. Different clustering techniques make different assumptions on the structure of the data, often defined by some similarity metric and evaluated, for example, by internal compactness, or the similarity between members of the same cluster, and separation, the difference between clusters. Other methods are based on estimated density and graph connectivity.\n",
        "\n",
        "A special type of unsupervised learning called, self-supervised learning involves training a model by generating the supervisory signal from the data itself.[54][55]\n",
        "\n",
        "Semi-supervised learning\n",
        "Main article: Semi-supervised learning\n",
        "Semi-supervised learning falls between unsupervised learning (without any labeled training data) and supervised learning (with completely labeled training data). Some of the training examples are missing training labels, yet many machine-learning researchers have found that unlabeled data, when used in conjunction with a small amount of labeled data, can produce a considerable improvement in learning accuracy.\n",
        "\n",
        "In weakly supervised learning, the training labels are noisy, limited, or imprecise; however, these labels are often cheaper to obtain, resulting in larger effective training sets.[56]\n",
        "\n",
        "Reinforcement learning\n",
        "Main article: Reinforcement learning\n",
        "Reinforcement learning is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Due to its generality, the field is studied in many other disciplines, such as game theory, control theory, operations research, information theory, simulation-based optimization, multi-agent systems, swarm intelligence, statistics and genetic algorithms. In reinforcement learning, the environment is typically represented as a Markov decision process (MDP). Many reinforcements learning algorithms use dynamic programming techniques.[57] Reinforcement learning algorithms do not assume knowledge of an exact mathematical model of the MDP and are used when exact models are infeasible. Reinforcement learning algorithms are used in autonomous vehicles or in learning to play a game against a human opponent.\n",
        "\n",
        "Dimensionality reduction\n",
        "Dimensionality reduction is a process of reducing the number of random variables under consideration by obtaining a set of principal variables.[58] In other words, it is a process of reducing the dimension of the feature set, also called the \"number of features\". Most of the dimensionality reduction techniques can be considered as either feature elimination or extraction. One of the popular methods of dimensionality reduction is principal component analysis (PCA). PCA involves changing higher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D). The manifold hypothesis proposes that high-dimensional data sets lie along low-dimensional manifolds, and many dimensionality reduction techniques make this assumption, leading to the area of manifold learning and manifold regularization.\n",
        "\n",
        "Other types\n",
        "Other approaches have been developed which do not fit neatly into this three-fold categorization, and sometimes more than one is used by the same machine learning system. For example, topic modeling, meta-learning.[59]\n",
        "\n",
        "Self-learning\n",
        "Self-learning, as a machine learning paradigm was introduced in 1982 along with a neural network capable of self-learning, named crossbar adaptive array (CAA).[60] It is learning with no external rewards and no external teacher advice. The CAA self-learning algorithm computes, in a crossbar fashion, both decisions about actions and emotions (feelings) about consequence situations. The system is driven by the interaction between cognition and emotion.[61] The self-learning algorithm updates a memory matrix W =||w(a,s)|| such that in each iteration executes the following machine learning routine:\n",
        "\n",
        "in situation s perform action a\n",
        "receive a consequence situation s'\n",
        "compute emotion of being in the consequence situation v(s')\n",
        "update crossbar memory w'(a,s) = w(a,s) + v(s')\n",
        "It is a system with only one input, situation, and only one output, action (or behavior) a. There is neither a separate reinforcement input nor an advice input from the environment. The backpropagated value (secondary reinforcement) is the emotion toward the consequence situation. The CAA exists in two environments, one is the behavioral environment where it behaves, and the other is the genetic environment, wherefrom it initially and only once receives initial emotions about situations to be encountered in the behavioral environment. After receiving the genome (species) vector from the genetic environment, the CAA learns a goal-seeking behavior, in an environment that contains both desirable and undesirable situations.[62]\n",
        "\n",
        "Feature learning\n",
        "Main article: Feature learning\n",
        "Several learning algorithms aim at discovering better representations of the inputs provided during training.[63] Classic examples include principal component analysis and cluster analysis. Feature learning algorithms, also called representation learning algorithms, often attempt to preserve the information in their input but also transform it in a way that makes it useful, often as a pre-processing step before performing classification or predictions. This technique allows reconstruction of the inputs coming from the unknown data-generating distribution, while not being necessarily faithful to configurations that are implausible under that distribution. This replaces manual feature engineering, and allows a machine to both learn the features and use them to perform a specific task.\n",
        "\n",
        "Feature learning can be either supervised or unsupervised. In supervised feature learning, features are learned using labeled input data. Examples include artificial neural networks, multilayer perceptrons, and supervised dictionary learning. In unsupervised feature learning, features are learned with unlabeled input data. Examples include dictionary learning, independent component analysis, autoencoders, matrix factorization[64] and various forms of clustering.[65][66][67]\n",
        "\n",
        "Manifold learning algorithms attempt to do so under the constraint that the learned representation is low-dimensional. Sparse coding algorithms attempt to do so under the constraint that the learned representation is sparse, meaning that the mathematical model has many zeros. Multilinear subspace learning algorithms aim to learn low-dimensional representations directly from tensor representations for multidimensional data, without reshaping them into higher-dimensional vectors.[68] Deep learning algorithms discover multiple levels of representation, or a hierarchy of features, with higher-level, more abstract features defined in terms of (or generating) lower-level features. It has been argued that an intelligent machine is one that learns a representation that disentangles the underlying factors of variation that explain the observed data.[69]\n",
        "\n",
        "Feature learning is motivated by the fact that machine learning tasks such as classification often require input that is mathematically and computationally convenient to process. However, real-world data such as images, video, and sensory data has not yielded attempts to algorithmically define specific features. An alternative is to discover such features or representations through examination, without relying on explicit algorithms.\n",
        "\n",
        "Sparse dictionary learning\n",
        "Main article: Sparse dictionary learning\n",
        "Sparse dictionary learning is a feature learning method where a training example is represented as a linear combination of basis functions and assumed to be a sparse matrix. The method is strongly NP-hard and difficult to solve approximately.[70] A popular heuristic method for sparse dictionary learning is the k-SVD algorithm. Sparse dictionary learning has been applied in several contexts. In classification, the problem is to determine the class to which a previously unseen training example belongs. For a dictionary where each class has already been built, a new training example is associated with the class that is best sparsely represented by the corresponding dictionary. Sparse dictionary learning has also been applied in image de-noising. The key idea is that a clean image patch can be sparsely represented by an image dictionary, but the noise cannot.[71]\n",
        "\n",
        "Anomaly detection\n",
        "Main article: Anomaly detection\n",
        "In data mining, anomaly detection, also known as outlier detection, is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data.[72] Typically, the anomalous items represent an issue such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are referred to as outliers, novelties, noise, deviations and exceptions.[73]\n",
        "\n",
        "In particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts of inactivity. This pattern does not adhere to the common statistical definition of an outlier as a rare object. Many outlier detection methods (in particular, unsupervised algorithms) will fail on such data unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro-clusters formed by these patterns.[74]\n",
        "\n",
        "Three broad categories of anomaly detection techniques exist.[75] Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal, by looking for instances that seem to fit the least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference from many other statistical classification problems is the inherently unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set and then test the likelihood of a test instance to be generated by the model.\n",
        "\n",
        "Robot learning\n",
        "Robot learning is inspired by a multitude of machine learning methods, starting from supervised learning, reinforcement learning,[76][77] and finally meta-learning (e.g. MAML).\n",
        "\n",
        "Association rules\n",
        "Main article: Association rule learning\n",
        "See also: Inductive logic programming\n",
        "Association rule learning is a rule-based machine learning method for discovering relationships between variables in large databases. It is intended to identify strong rules discovered in databases using some measure of \"interestingness\".[78]\n",
        "\n",
        "Rule-based machine learning is a general term for any machine learning method that identifies, learns, or evolves \"rules\" to store, manipulate or apply knowledge. The defining characteristic of a rule-based machine learning algorithm is the identification and utilization of a set of relational rules that collectively represent the knowledge captured by the system. This is in contrast to other machine learning algorithms that commonly identify a singular model that can be universally applied to any instance in order to make a prediction.[79] Rule-based machine learning approaches include learning classifier systems, association rule learning, and artificial immune systems.\n",
        "\n",
        "Based on the concept of strong rules, Rakesh Agrawal, Tomasz Imieliński and Arun Swami introduced association rules for discovering regularities between products in large-scale transaction data recorded by point-of-sale (POS) systems in supermarkets.[80] For example, the rule\n",
        "{\n",
        "o\n",
        "n\n",
        "i\n",
        "o\n",
        "n\n",
        "s\n",
        ",\n",
        "p\n",
        "o\n",
        "t\n",
        "a\n",
        "t\n",
        "o\n",
        "e\n",
        "s\n",
        "}\n",
        "⇒\n",
        "{\n",
        "b\n",
        "u\n",
        "r\n",
        "g\n",
        "e\n",
        "r\n",
        "}\n",
        "{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}} found in the sales data of a supermarket would indicate that if a customer buys onions and potatoes together, they are likely to also buy hamburger meat. Such information can be used as the basis for decisions about marketing activities such as promotional pricing or product placements. In addition to market basket analysis, association rules are employed today in application areas including Web usage mining, intrusion detection, continuous production, and bioinformatics. In contrast with sequence mining, association rule learning typically does not consider the order of items either within a transaction or across transactions.\n",
        "\n",
        "Learning classifier systems (LCS) are a family of rule-based machine learning algorithms that combine a discovery component, typically a genetic algorithm, with a learning component, performing either supervised learning, reinforcement learning, or unsupervised learning. They seek to identify a set of context-dependent rules that collectively store and apply knowledge in a piecewise manner in order to make predictions.[81]\n",
        "\n",
        "Inductive logic programming (ILP) is an approach to rule learning using logic programming as a uniform representation for input examples, background knowledge, and hypotheses. Given an encoding of the known background knowledge and a set of examples represented as a logical database of facts, an ILP system will derive a hypothesized logic program that entails all positive and no negative examples. Inductive programming is a related field that considers any kind of programming language for representing hypotheses (and not only logic programming), such as functional programs.\n",
        "\n",
        "Inductive logic programming is particularly useful in bioinformatics and natural language processing. Gordon Plotkin and Ehud Shapiro laid the initial theoretical foundation for inductive machine learning in a logical setting.[82][83][84] Shapiro built their first implementation (Model Inference System) in 1981: a Prolog program that inductively inferred logic programs from positive and negative examples.[85] The term inductive here refers to philosophical induction, suggesting a theory to explain observed facts, rather than mathematical induction, proving a property for all members of a well-ordered set.\n",
        "\n",
        "Models\n",
        "A machine learning model is a type of mathematical model that, after being \"trained\" on a given dataset, can be used to make predictions or classifications on new data. During training, a learning algorithm iteratively adjusts the model's internal parameters to minimize errors in its predictions.[86] By extension, the term \"model\" can refer to several levels of specificity, from a general class of models and their associated learning algorithms to a fully trained model with all its internal parameters tuned.[87]\n",
        "\n",
        "Various types of models have been used and researched for machine learning systems, picking the best model for a task is called model selection.\n",
        "\n",
        "Artificial neural networks\n",
        "Main article: Artificial neural network\n",
        "See also: Deep learning\n",
        "\n",
        "An artificial neural network is an interconnected group of nodes, akin to the vast network of neurons in a brain. Here, each circular node represents an artificial neuron and an arrow represents a connection from the output of one artificial neuron to the input of another.\n",
        "Artificial neural networks (ANNs), or connectionist systems, are computing systems vaguely inspired by the biological neural networks that constitute animal brains. Such systems \"learn\" to perform tasks by considering examples, generally without being programmed with any task-specific rules.\n",
        "\n",
        "An ANN is a model based on a collection of connected units or nodes called \"artificial neurons\", which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit information, a \"signal\", from one artificial neuron to another. An artificial neuron that receives a signal can process it and then signal additional artificial neurons connected to it. In common ANN implementations, the signal at a connection between artificial neurons is a real number, and the output of each artificial neuron is computed by some non-linear function of the sum of its inputs. The connections between artificial neurons are called \"edges\". Artificial neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Artificial neurons may have a threshold such that the signal is only sent if the aggregate signal crosses that threshold. Typically, artificial neurons are aggregated into layers. Different layers may perform different kinds of transformations on their inputs. Signals travel from the first layer (the input layer) to the last layer (the output layer), possibly after traversing the layers multiple times.\n",
        "\n",
        "The original goal of the ANN approach was to solve problems in the same way that a human brain would. However, over time, attention moved to performing specific tasks, leading to deviations from biology. Artificial neural networks have been used on a variety of tasks, including computer vision, speech recognition, machine translation, social network filtering, playing board and video games and medical diagnosis.\n",
        "\n",
        "Deep learning consists of multiple hidden layers in an artificial neural network. This approach tries to model the way the human brain processes light and sound into vision and hearing. Some successful applications of deep learning are computer vision and speech recognition.[88]\n",
        "\n",
        "Decision trees\n",
        "Main article: Decision tree learning\n",
        "\n",
        "A decision tree showing survival probability of passengers on the Titanic\n",
        "Decision tree learning uses a decision tree as a predictive model to go from observations about an item (represented in the branches) to conclusions about the item's target value (represented in the leaves). It is one of the predictive modeling approaches used in statistics, data mining, and machine learning. Tree models where the target variable can take a discrete set of values are called classification trees; in these tree structures, leaves represent class labels, and branches represent conjunctions of features that lead to those class labels. Decision trees where the target variable can take continuous values (typically real numbers) are called regression trees. In decision analysis, a decision tree can be used to visually and explicitly represent decisions and decision making. In data mining, a decision tree describes data, but the resulting classification tree can be an input for decision-making.\n",
        "\n",
        "Support-vector machines\n",
        "Main article: Support-vector machine\n",
        "Support-vector machines (SVMs), also known as support-vector networks, are a set of related supervised learning methods used for classification and regression. Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that predicts whether a new example falls into one category.[89] An SVM training algorithm is a non-probabilistic, binary, linear classifier, although methods such as Platt scaling exist to use SVM in a probabilistic classification setting. In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.\n",
        "\n",
        "Regression analysis\n",
        "Main article: Regression analysis\n",
        "\n",
        "Illustration of linear regression on a data set\n",
        "Regression analysis encompasses a large variety of statistical methods to estimate the relationship between input variables and their associated features. Its most common form is linear regression, where a single line is drawn to best fit the given data according to a mathematical criterion such as ordinary least squares. The latter is often extended by regularization methods to mitigate overfitting and bias, as in ridge regression. When dealing with non-linear problems, go-to models include polynomial regression (for example, used for trendline fitting in Microsoft Excel[90]), logistic regression (often used in statistical classification) or even kernel regression, which introduces non-linearity by taking advantage of the kernel trick to implicitly map input variables to higher-dimensional space.\n",
        "\n",
        "Bayesian networks\n",
        "Main article: Bayesian network\n",
        "\n",
        "A simple Bayesian network. Rain influences whether the sprinkler is activated, and both rain and the sprinkler influence whether the grass is wet.\n",
        "A Bayesian network, belief network, or directed acyclic graphical model is a probabilistic graphical model that represents a set of random variables and their conditional independence with a directed acyclic graph (DAG). For example, a Bayesian network could represent the probabilistic relationships between diseases and symptoms. Given symptoms, the network can be used to compute the probabilities of the presence of various diseases. Efficient algorithms exist that perform inference and learning. Bayesian networks that model sequences of variables, like speech signals or protein sequences, are called dynamic Bayesian networks. Generalizations of Bayesian networks that can represent and solve decision problems under uncertainty are called influence diagrams.\n",
        "\n",
        "Gaussian processes\n",
        "Main article: Gaussian processes\n",
        "\n",
        "An example of Gaussian Process Regression (prediction) compared with other regression models[91]\n",
        "A Gaussian process is a stochastic process in which every finite collection of the random variables in the process has a multivariate normal distribution, and it relies on a pre-defined covariance function, or kernel, that models how pairs of points relate to each other depending on their locations.\n",
        "\n",
        "Given a set of observed points, or input–output examples, the distribution of the (unobserved) output of a new point as function of its input data can be directly computed by looking like the observed points and the covariances between those points and the new, unobserved point.\n",
        "\n",
        "Gaussian processes are popular surrogate models in Bayesian optimization used to do hyperparameter optimization.\n",
        "\n",
        "Genetic algorithms\n",
        "Main article: Genetic algorithm\n",
        "A genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the process of natural selection, using methods such as mutation and crossover to generate new genotypes in the hope of finding good solutions to a given problem. In machine learning, genetic algorithms were used in the 1980s and 1990s.[92][93] Conversely, machine learning techniques have been used to improve the performance of genetic and evolutionary algorithms.[94]\n",
        "\n",
        "Belief functions\n",
        "Main article: Dempster–Shafer theory\n",
        "The theory of belief functions, also referred to as evidence theory or Dempster–Shafer theory, is a general framework for reasoning with uncertainty, with understood connections to other frameworks such as probability, possibility and imprecise probability theories. These theoretical frameworks can be thought of as a kind of learner and have some analogous properties of how evidence is combined (e.g., Dempster's rule of combination), just like how in a pmf-based Bayesian approach[clarification needed] would combine probabilities. However, there are many caveats to these beliefs functions when compared to Bayesian approaches in order to incorporate ignorance and uncertainty quantification. These belief function approaches that are implemented within the machine learning domain typically leverage a fusion approach of various ensemble methods to better handle the learner's decision boundary, low samples, and ambiguous class issues that standard machine learning approach tend to have difficulty resolving.[4][9] However, the computational complexity of these algorithms are dependent on the number of propositions (classes), and can lead to a much higher computation time when compared to other machine learning approaches.\n",
        "\n",
        "Training models\n",
        "Typically, machine learning models require a high quantity of reliable data to perform accurate predictions. When training a machine learning model, machine learning engineers need to target and collect a large and representative sample of data. Data from the training set can be as varied as a corpus of text, a collection of images, sensor data, and data collected from individual users of a service. Overfitting is something to watch out for when training a machine learning model. Trained models derived from biased or non-evaluated data can result in skewed or undesired predictions. Biased models may result in detrimental outcomes, thereby furthering the negative impacts on society or objectives. Algorithmic bias is a potential result of data not being fully prepared for training. Machine learning ethics is becoming a field of study and notably, becoming integrated within machine learning engineering teams.\n",
        "\n",
        "Federated learning\n",
        "Main article: Federated learning\n",
        "Federated learning is an adapted form of distributed artificial intelligence to training machine learning models that decentralizes the training process, allowing for users' privacy to be maintained by not needing to send their data to a centralized server. This also increases efficiency by decentralizing the training process to many devices. For example, Gboard uses federated machine learning to train search query prediction models on users' mobile phones without having to send individual searches back to Google.[95]\n",
        "\n",
        "Applications\n",
        "There are many applications for machine learning, including:\n",
        "\n",
        "Agriculture\n",
        "Anatomy\n",
        "Adaptive website\n",
        "Affective computing\n",
        "Astronomy\n",
        "Automated decision-making\n",
        "Banking\n",
        "Behaviorism\n",
        "Bioinformatics\n",
        "Brain–machine interfaces\n",
        "Cheminformatics\n",
        "Citizen Science\n",
        "Climate Science\n",
        "Computer networks\n",
        "Computer vision\n",
        "Credit-card fraud detection\n",
        "Data quality\n",
        "DNA sequence classification\n",
        "Economics\n",
        "Financial market analysis[96]\n",
        "General game playing\n",
        "Handwriting recognition\n",
        "Healthcare\n",
        "Information retrieval\n",
        "Insurance\n",
        "Internet fraud detection\n",
        "Knowledge graph embedding\n",
        "Linguistics\n",
        "Machine learning control\n",
        "Machine perception\n",
        "Machine translation\n",
        "Marketing\n",
        "Medical diagnosis\n",
        "Natural language processing\n",
        "Natural language understanding\n",
        "Online advertising\n",
        "Optimization\n",
        "Recommender systems\n",
        "Robot locomotion\n",
        "Search engines\n",
        "Sentiment analysis\n",
        "Sequence mining\n",
        "Software engineering\n",
        "Speech recognition\n",
        "Structural health monitoring\n",
        "Syntactic pattern recognition\n",
        "Telecommunication\n",
        "Theorem proving\n",
        "Time-series forecasting\n",
        "Tomographic reconstruction[97]\n",
        "User behavior analytics\n",
        "In 2006, the media-services provider Netflix held the first \"Netflix Prize\" competition to find a program to better predict user preferences and improve the accuracy of its existing Cinematch movie recommendation algorithm by at least 10%. A joint team made up of researchers from AT&T Labs-Research in collaboration with the teams Big Chaos and Pragmatic Theory built an ensemble model to win the Grand Prize in 2009 for $1 million.[98] Shortly after the prize was awarded, Netflix realized that viewers' ratings were not the best indicators of their viewing patterns (\"everything is a recommendation\") and they changed their recommendation engine accordingly.[99] In 2010 The Wall Street Journal wrote about the firm Rebellion Research and their use of machine learning to predict the financial crisis.[100] In 2012, co-founder of Sun Microsystems, Vinod Khosla, predicted that 80% of medical doctors jobs would be lost in the next two decades to automated machine learning medical diagnostic software.[101] In 2014, it was reported that a machine learning algorithm had been applied in the field of art history to study fine art paintings and that it may have revealed previously unrecognized influences among artists.[102] In 2019 Springer Nature published the first research book created using machine learning.[103] In 2020, machine learning technology was used to help make diagnoses and aid researchers in developing a cure for COVID-19.[104] Machine learning was recently applied to predict the pro-environmental behavior of travelers.[105] Recently, machine learning technology was also applied to optimize smartphone's performance and thermal behavior based on the user's interaction with the phone.[106][107][108] When applied correctly, machine learning algorithms (MLAs) can utilize a wide range of company characteristics to predict stock returns without overfitting. By employing effective feature engineering and combining forecasts, MLAs can generate results that far surpass those obtained from basic linear techniques like OLS.[109]\n",
        "\n",
        "Recent advancements in machine learning have extended into the field of quantum chemistry, where novel algorithms now enable the prediction of solvent effects on chemical reactions, thereby offering new tools for chemists to tailor experimental conditions for optimal outcomes.[110]\n",
        "\n",
        "Machine Learning is becoming a useful tool to investigate and predict evacuation decision making in large scale and small scale disasters. Different solutions have been tested to predict if and when householders decide to evacuate during wildfires and hurricanes.[111][112][113] Other applications have been focusing on pre evacuation decisions in building fires.[114][115]\n",
        "\n",
        "Limitations\n",
        "Although machine learning has been transformative in some fields, machine-learning programs often fail to deliver expected results.[116][117][118] Reasons for this are numerous: lack of (suitable) data, lack of access to the data, data bias, privacy problems, badly chosen tasks and algorithms, wrong tools and people, lack of resources, and evaluation problems.[119]\n",
        "\n",
        "The \"black box theory\" poses another yet significant challenge. Black box refers to a situation where the algorithm or the process of producing an output is entirely opaque, meaning that even the coders of the algorithm cannot audit the pattern that the machine extracted out of the data.[120] The House of Lords Select Committee, which claimed that such an “intelligence system” that could have a “substantial impact on an individual’s life” would not be considered acceptable unless it provided “a full and satisfactory explanation for the decisions” it makes.[120]\n",
        "\n",
        "In 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a collision.[121] Attempts to use machine learning in healthcare with the IBM Watson system failed to deliver even after years of time and billions of dollars invested.[122][123] Microsoft's Bing Chat chatbot has been reported to produce hostile and offensive response against its users.[124]\n",
        "\n",
        "Machine learning has been used as a strategy to update the evidence related to a systematic review and increased reviewer burden related to the growth of biomedical literature. While it has improved with training sets, it has not yet developed sufficiently to reduce the workload burden without limiting the necessary sensitivity for the findings research themselves.[125]\n",
        "\n",
        "Bias\n",
        "Main article: Algorithmic bias\n",
        "Different machine learning approaches can suffer from different data biases. A machine learning system trained specifically on current customers may not be able to predict the needs of new customer groups that are not represented in the training data. When trained on human-made data, machine learning is likely to pick up the constitutional and unconscious biases already present in society.[126]\n",
        "\n",
        "Language models learned from data have been shown to contain human-like biases.[127][128] In an experiment carried out by ProPublica, an investigative journalism organization, a machine learning algorithm's insight into the recidivism rates among prisoners falsely flagged \"black defendants high risk twice as often as white defendants.\"[129] In 2015, Google Photos would often tag black people as gorillas,[129] and in 2018, this still was not well resolved, but Google reportedly was still using the workaround to remove all gorillas from the training data and thus was not able to recognize real gorillas at all.[130] Similar issues with recognizing non-white people have been found in many other systems.[131] In 2016, Microsoft tested Tay, a chatbot that learned from Twitter, and it quickly picked up racist and sexist language.[132]\n",
        "\n",
        "Because of such challenges, the effective use of machine learning may take longer to be adopted in other domains.[133] Concern for fairness in machine learning, that is, reducing bias in machine learning and propelling its use for human good, is increasingly expressed by artificial intelligence scientists, including Fei-Fei Li, who reminds engineers that \"[t]here's nothing artificial about AI. It's inspired by people, it's created by people, and—most importantly—it impacts people. It is a powerful tool we are only just beginning to understand, and that is a profound responsibility.\"[134]\n",
        "\n",
        "Explainability\n",
        "Main article: Explainable artificial intelligence\n",
        "Explainable AI (XAI), or Interpretable AI, or Explainable Machine Learning (XML), is artificial intelligence (AI) in which humans can understand the decisions or predictions made by the AI.[135] It contrasts with the \"black box\" concept in machine learning where even its designers cannot explain why an AI arrived at a specific decision.[136] By refining the mental models of users of AI-powered systems and dismantling their misconceptions, XAI promises to help users perform more effectively. XAI may be an implementation of the social right to explanation.\n",
        "\n",
        "Overfitting\n",
        "Main article: Overfitting\n",
        "\n",
        "The blue line could be an example of overfitting a linear function due to random noise.\n",
        "Settling on a bad, overly complex theory gerrymandered to fit all the past training data is known as overfitting. Many systems attempt to reduce overfitting by rewarding a theory in accordance with how well it fits the data but penalizing the theory in accordance with how complex the theory is.[137]\n",
        "\n",
        "Other limitations and vulnerabilities\n",
        "Learners can also disappoint by \"learning the wrong lesson\". A toy example is that an image classifier trained only on pictures of brown horses and black cats might conclude that all brown patches are likely to be horses.[138] A real-world example is that, unlike humans, current image classifiers often do not primarily make judgments from the spatial relationship between components of the picture, and they learn relationships between pixels that humans are oblivious to, but that still correlate with images of certain types of real objects. Modifying these patterns on a legitimate image can result in \"adversarial\" images that the system misclassifies.[139][140]\n",
        "\n",
        "Adversarial vulnerabilities can also result in nonlinear systems, or from non-pattern perturbations. For some systems, it is possible to change the output by only changing a single adversarially chosen pixel.[141] Machine learning models are often vulnerable to manipulation and/or evasion via adversarial machine learning.[142]\n",
        "\n",
        "Researchers have demonstrated how backdoors can be placed undetectably into classifying (e.g., for categories \"spam\" and well-visible \"not spam\" of posts) machine learning models that are often developed and/or trained by third parties. Parties can change the classification of any input, including in cases for which a type of data/software transparency is provided, possibly including white-box access.[143][144][145]\n",
        "\n",
        "Model assessments\n",
        "Classification of machine learning models can be validated by accuracy estimation techniques like the holdout method, which splits the data in a training and test set (conventionally 2/3 training set and 1/3 test set designation) and evaluates the performance of the training model on the test set. In comparison, the K-fold-cross-validation method randomly partitions the data into K subsets and then K experiments are performed each respectively considering 1 subset for evaluation and the remaining K-1 subsets for training the model. In addition to the holdout and cross-validation methods, bootstrap, which samples n instances with replacement from the dataset, can be used to assess model accuracy.[146]\n",
        "\n",
        "In addition to overall accuracy, investigators frequently report sensitivity and specificity meaning True Positive Rate (TPR) and True Negative Rate (TNR) respectively. Similarly, investigators sometimes report the false positive rate (FPR) as well as the false negative rate (FNR). However, these rates are ratios that fail to reveal their numerators and denominators. The total operating characteristic (TOC) is an effective method to express a model's diagnostic ability. TOC shows the numerators and denominators of the previously mentioned rates, thus TOC provides more information than the commonly used receiver operating characteristic (ROC) and ROC's associated area under the curve (AUC).[147]\n",
        "\n",
        "Ethics\n",
        "See also: AI control problem, Toronto Declaration, and Ethics of artificial intelligence\n",
        "Machine learning poses a host of ethical questions. Systems that are trained on datasets collected with biases may exhibit these biases upon use (algorithmic bias), thus digitizing cultural prejudices.[148] For example, in 1988, the UK's Commission for Racial Equality found that St. George's Medical School had been using a computer program trained from data of previous admissions staff and that this program had denied nearly 60 candidates who were found to either be women or have non-European sounding names.[126] Using job hiring data from a firm with racist hiring policies may lead to a machine learning system duplicating the bias by scoring job applicants by similarity to previous successful applicants.[149][150] Another example includes predictive policing company Geolitica's predictive algorithm that resulted in “disproportionately high levels of over-policing in low-income and minority communities” after being trained with historical crime data.[129]\n",
        "\n",
        "While responsible collection of data and documentation of algorithmic rules used by a system is considered a critical part of machine learning, some researchers blame lack of participation and representation of minority population in the field of AI for machine learning's vulnerability to biases.[151] In fact, according to research carried out by the Computing Research Association (CRA) in 2021, “female faculty merely make up 16.1%” of all faculty members who focus on AI among several universities around the world.[152] Furthermore, among the group of “new U.S. resident AI PhD graduates,” 45% identified as white, 22.4% as Asian, 3.2% as Hispanic, and 2.4% as African American, which further demonstrates a lack of diversity in the field of AI.[152]\n",
        "\n",
        "AI can be well-equipped to make decisions in technical fields, which rely heavily on data and historical information. These decisions rely on objectivity and logical reasoning.[153] Because human languages contain biases, machines trained on language corpora will necessarily also learn these biases.[154][155]\n",
        "\n",
        "Other forms of ethical challenges, not related to personal biases, are seen in health care. There are concerns among health care professionals that these systems might not be designed in the public's interest but as income-generating machines.[156] This is especially true in the United States where there is a long-standing ethical dilemma of improving health care, but also increasing profits. For example, the algorithms could be designed to provide patients with unnecessary tests or medication in which the algorithm's proprietary owners hold stakes. There is potential for machine learning in health care to provide professionals an additional tool to diagnose, medicate, and plan recovery paths for patients, but this requires these biases to be mitigated.[157]\n",
        "\n",
        "Hardware\n",
        "Since the 2010s, advances in both machine learning algorithms and computer hardware have led to more efficient methods for training deep neural networks (a particular narrow subdomain of machine learning) that contain many layers of nonlinear hidden units.[158] By 2019, graphic processing units (GPUs), often with AI-specific enhancements, had displaced CPUs as the dominant method of training large-scale commercial cloud AI.[159] OpenAI estimated the hardware computing used in the largest deep learning projects from AlexNet (2012) to AlphaZero (2017), and found a 300,000-fold increase in the amount of compute required, with a doubling-time trendline of 3.4 months.[160][161]\n",
        "\n",
        "Neuromorphic/Physical Neural Networks\n",
        "A physical neural network or Neuromorphic computer is a type of artificial neural network in which an electrically adjustable material is used to emulate the function of a neural synapse. \"Physical\" neural network is used to emphasize the reliance on physical hardware used to emulate neurons as opposed to software-based approaches. More generally the term is applicable to other artificial neural networks in which a memristor or other electrically adjustable resistance material is used to emulate a neural synapse.[162][163]\n",
        "\n",
        "Embedded Machine Learning\n",
        "Embedded Machine Learning is a sub-field of machine learning, where the machine learning model is run on embedded systems with limited computing resources such as wearable computers, edge devices and microcontrollers.[164][165][166] Running machine learning model in embedded devices removes the need for transferring and storing data on cloud servers for further processing, henceforth, reducing data breaches and privacy leaks happening because of transferring data, and also minimizes theft of intellectual properties, personal data and business secrets. Embedded Machine Learning could be applied through several techniques including hardware acceleration,[167][168] using approximate computing,[169] optimization of machine learning models and many more.[170][171] Pruning, Quantization, Knowledge Distillation, Low-Rank Factorization, Network Architecture Search (NAS) & Parameter Sharing are few of the techniques used for optimization of machine learning models.\n",
        "\n",
        "Software\n",
        "Software suites containing a variety of machine learning algorithms include the following:\n",
        "\n",
        "Free and open-source software\n",
        "Caffe\n",
        "Deeplearning4j\n",
        "DeepSpeed\n",
        "ELKI\n",
        "Google JAX\n",
        "Infer.NET\n",
        "Keras\n",
        "Kubeflow\n",
        "LightGBM\n",
        "Mahout\n",
        "Mallet\n",
        "Microsoft Cognitive Toolkit\n",
        "ML.NET\n",
        "mlpack\n",
        "MXNet\n",
        "OpenNN\n",
        "Orange\n",
        "pandas (software)\n",
        "ROOT (TMVA with ROOT)\n",
        "scikit-learn\n",
        "Shogun\n",
        "Spark MLlib\n",
        "SystemML\n",
        "TensorFlow\n",
        "Torch / PyTorch\n",
        "Weka / MOA\n",
        "XGBoost\n",
        "Yooreeka\n",
        "Proprietary software with free and open-source editions\n",
        "KNIME\n",
        "RapidMiner\n",
        "Proprietary software\n",
        "Amazon Machine Learning\n",
        "Angoss KnowledgeSTUDIO\n",
        "Azure Machine Learning\n",
        "IBM Watson Studio\n",
        "Google Cloud Vertex AI\n",
        "Google Prediction API\n",
        "IBM SPSS Modeler\n",
        "KXEN Modeler\n",
        "LIONsolver\n",
        "Mathematica\n",
        "MATLAB\n",
        "Neural Designer\n",
        "NeuroSolutions\n",
        "Oracle Data Mining\n",
        "Oracle AI Platform Cloud Service\n",
        "PolyAnalyst\n",
        "RCASE\n",
        "SAS Enterprise Miner\n",
        "SequenceL\n",
        "Splunk\n",
        "STATISTICA Data Miner\n",
        "Journals\n",
        "Journal of Machine Learning Research\n",
        "Machine Learning\n",
        "Nature Machine Intelligence\n",
        "Neural Computation\n",
        "IEEE Transactions on Pattern Analysis and Machine Intelligence\n",
        "Conferences\n",
        "AAAI Conference on Artificial Intelligence\n",
        "Association for Computational Linguistics (ACL)\n",
        "European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases (ECML PKDD)\n",
        "International Conference on Computational Intelligence Methods for Bioinformatics and Biostatistics (CIBB)\n",
        "International Conference on Machine Learning (ICML)\n",
        "International Conference on Learning Representations (ICLR)\n",
        "International Conference on Intelligent Robots and Systems (IROS)\n",
        "Conference on Knowledge Discovery and Data Mining (KDD)\n",
        "Conference on Neural Information Processing Systems (NeurIPS)\n",
        "See also\n",
        "Automated machine learning – Process of automating the application of machine learning\n",
        "Big data – Extremely large or complex datasets\n",
        "Differentiable programming – Programming paradigm\n",
        "Force control\n",
        "List of important publications in machine learning\n",
        "List of datasets for machine-learning research\n",
        "References\n",
        " The definition \"without being explicitly programmed\" is often attributed to Arthur Samuel, who coined the term \"machine learning\" in 1959, but the phrase is not found verbatim in this publication, and may be a paraphrase that appeared later. Confer \"Paraphrasing Arthur Samuel (1959), the question is: How can computers learn to solve problems without being explicitly programmed?\" in Koza, John R.; Bennett, Forrest H.; Andre, David; Keane, Martin A. (1996). \"Automated Design of Both the Topology and Sizing of Analog Electrical Circuits Using Genetic Programming\". Artificial Intelligence in Design '96. Artificial Intelligence in Design '96. Springer, Dordrecht. pp. 151–170. doi:10.1007/978-94-009-0279-4_9. ISBN 978-94-010-6610-5.\n",
        " \"What is Machine Learning?\". IBM. 22 September 2021. Archived from the original on 2023-12-27. Retrieved 2023-06-27.\n",
        " Hu, Junyan; Niu, Hanlin; Carrasco, Joaquin; Lennox, Barry; Arvin, Farshad (2020). \"Voronoi-Based Multi-Robot Autonomous Exploration in Unknown Environments via Deep Reinforcement Learning\". IEEE Transactions on Vehicular Technology. 69 (12): 14413–14423. doi:10.1109/tvt.2020.3034800. ISSN 0018-9545. S2CID 228989788.\n",
        " Yoosefzadeh-Najafabadi, Mohsen; Hugh, Earl; Tulpan, Dan; Sulik, John; Eskandari, Milad (2021). \"Application of Machine Learning Algorithms in Plant Breeding: Predicting Yield From Hyperspectral Reflectance in Soybean?\". Front. Plant Sci. 11: 624273. doi:10.3389/fpls.2020.624273. PMC 7835636. PMID 33510761.\n",
        " Bishop, C. M. (2006), Pattern Recognition and Machine Learning, Springer, ISBN 978-0-387-31073-2\n",
        " Machine learning and pattern recognition \"can be viewed as two facets of the same field\".[5]: vii\n",
        " Friedman, Jerome H. (1998). \"Data Mining and Statistics: What's the connection?\". Computing Science and Statistics. 29 (1): 3–9.\n",
        " Samuel, Arthur (1959). \"Some Studies in Machine Learning Using the Game of Checkers\". IBM Journal of Research and Development. 3 (3): 210–229. CiteSeerX 10.1.1.368.2254. doi:10.1147/rd.33.0210. S2CID 2126705.\n",
        " R. Kohavi and F. Provost, \"Glossary of terms\", Machine Learning, vol. 30, no. 2–3, pp. 271–274, 1998.\n",
        " Gerovitch, Slava (9 April 2015). \"How the Computer Got Its Revenge on the Soviet Union\". Nautilus. Archived from the original on 22 September 2021. Retrieved 19 September 2021.\n",
        " Lindsay, Richard P. (1 September 1964). \"The Impact of Automation On Public Administration\". Western Political Quarterly. 17 (3): 78–81. doi:10.1177/106591296401700364. ISSN 0043-4078. S2CID 154021253. Archived from the original on 6 October 2021. Retrieved 6 October 2021.\n",
        " \"History and Evolution of Machine Learning: A Timeline\". WhatIs. Archived from the original on 2023-12-08. Retrieved 2023-12-08.\n",
        " Milner, Peter M. (1993). \"The Mind and Donald O. Hebb\". Scientific American. 268 (1): 124–129. Bibcode:1993SciAm.268a.124M. doi:10.1038/scientificamerican0193-124. ISSN 0036-8733. JSTOR 24941344. PMID 8418480. Archived from the original on 2023-12-20. Retrieved 2023-12-09.\n",
        " \"Science: The Goof Button\", Time (magazine), 18 August 1961.\n",
        " Nilsson N. Learning Machines, McGraw Hill, 1965.\n",
        " Duda, R., Hart P. Pattern Recognition and Scene Analysis, Wiley Interscience, 1973\n",
        " S. Bozinovski \"Teaching space: A representation concept for adaptive pattern classification\" COINS Technical Report No. 81-28, Computer and Information Science Department, University of Massachusetts at Amherst, MA, 1981. https://web.cs.umass.edu/publication/docs/1981/UM-CS-1981-028.pdf Archived 2021-02-25 at the Wayback Machine\n",
        " Mitchell, T. (1997). Machine Learning. McGraw Hill. p. 2. ISBN 978-0-07-042807-2.\n",
        " Harnad, Stevan (2008), \"The Annotation Game: On Turing (1950) on Computing, Machinery, and Intelligence\", in Epstein, Robert; Peters, Grace (eds.), The Turing Test Sourcebook: Philosophical and Methodological Issues in the Quest for the Thinking Computer, Kluwer, pp. 23–66, ISBN 9781402067082, archived from the original on 2012-03-09, retrieved 2012-12-11\n",
        " \"Introduction to AI Part 1\". Edzion. 2020-12-08. Archived from the original on 2021-02-18. Retrieved 2020-12-09.\n",
        " Sindhu V, Nivedha S, Prakash M (February 2020). \"An Empirical Science Research on Bioinformatics in Machine Learning\". Journal of Mechanics of Continua and Mathematical Sciences (7). doi:10.26782/jmcms.spl.7/2020.02.00006.\n",
        " Sarle, Warren S. (1994). \"Neural Networks and statistical models\". SUGI 19: proceedings of the Nineteenth Annual SAS Users Group International Conference. SAS Institute. pp. 1538–50. ISBN 9781555446116. OCLC 35546178.\n",
        " Russell, Stuart; Norvig, Peter (2003) [1995]. Artificial Intelligence: A Modern Approach (2nd ed.). Prentice Hall. ISBN 978-0137903955.\n",
        " Langley, Pat (2011). \"The changing science of machine learning\". Machine Learning. 82 (3): 275–9. doi:10.1007/s10994-011-5242-y.\n",
        " Mahoney, Matt. \"Rationale for a Large Text Compression Benchmark\". Florida Institute of Technology. Retrieved 5 March 2013.\n",
        " Shmilovici A.; Kahiri Y.; Ben-Gal I.; Hauser S. (2009). \"Measuring the Efficiency of the Intraday Forex Market with a Universal Data Compression Algorithm\" (PDF). Computational Economics. 33 (2): 131–154. CiteSeerX 10.1.1.627.3751. doi:10.1007/s10614-008-9153-3. S2CID 17234503. Archived (PDF) from the original on 2009-07-09.\n",
        " I. Ben-Gal (2008). \"On the Use of Data Compression Measures to Analyze Robust Designs\" (PDF). IEEE Transactions on Reliability. 54 (3): 381–388. doi:10.1109/TR.2005.853280. S2CID 9376086.\n",
        " D. Scully; Carla E. Brodley (2006). \"Compression and Machine Learning: A New Perspective on Feature Space Vectors\". Data Compression Conference (DCC'06). p. 332. doi:10.1109/DCC.2006.13. ISBN 0-7695-2545-8. S2CID 12311412.\n",
        " Gary Adcock (January 5, 2023). \"What Is AI Video Compression?\". massive.io. Retrieved 6 April 2023.\n",
        " Mentzer, Fabian; Toderici, George; Tschannen, Michael; Agustsson, Eirikur (2020). \"High-Fidelity Generative Image Compression\". arXiv:2006.09965 [eess.IV].\n",
        " \"What is Unsupervised Learning? | IBM\". www.ibm.com. 23 September 2021. Retrieved 2024-02-05.\n",
        " \"Differentially private clustering for large-scale datasets\". blog.research.google. 2023-05-25. Retrieved 2024-03-16.\n",
        " Edwards, Benj (2023-09-28). \"AI language models can exceed PNG and FLAC in lossless compression, says study\". Ars Technica. Retrieved 2024-03-07.\n",
        " Le Roux, Nicolas; Bengio, Yoshua; Fitzgibbon, Andrew (2012). \"Improving First and Second-Order Methods by Modeling Uncertainty\". In Sra, Suvrit; Nowozin, Sebastian; Wright, Stephen J. (eds.). Optimization for Machine Learning. MIT Press. p. 404. ISBN 9780262016469. Archived from the original on 2023-01-17. Retrieved 2020-11-12.\n",
        " Bzdok, Danilo; Altman, Naomi; Krzywinski, Martin (2018). \"Statistics versus Machine Learning\". Nature Methods. 15 (4): 233–234. doi:10.1038/nmeth.4642. PMC 6082636. PMID 30100822.\n",
        " Michael I. Jordan (2014-09-10). \"statistics and machine learning\". reddit. Archived from the original on 2017-10-18. Retrieved 2014-10-01.\n",
        " Hung et al. Algorithms to Measure Surgeon Performance and Anticipate Clinical Outcomes in Robotic Surgery. JAMA Surg. 2018\n",
        " Cornell University Library (August 2001). \"Breiman: Statistical Modeling: The Two Cultures (with comments and a rejoinder by the author)\". Statistical Science. 16 (3). doi:10.1214/ss/1009213726. S2CID 62729017. Archived from the original on 26 June 2017. Retrieved 8 August 2015.\n",
        " Gareth James; Daniela Witten; Trevor Hastie; Robert Tibshirani (2013). An Introduction to Statistical Learning. Springer. p. vii. Archived from the original on 2019-06-23. Retrieved 2014-10-25.\n",
        " Ramezanpour, A.; Beam, A.L.; Chen, J.H.; Mashaghi, A. (17 November 2020). \"Statistical Physics for Medical Diagnostics: Learning, Inference, and Optimization Algorithms\". Diagnostics. 10 (11): 972. doi:10.3390/diagnostics10110972. PMC 7699346. PMID 33228143.\n",
        " Mashaghi, A.; Ramezanpour, A. (16 March 2018). \"Statistical physics of medical diagnostics: Study of a probabilistic model\". Physical Review E. 97 (3–1): 032118. arXiv:1803.10019. Bibcode:2018PhRvE..97c2118M. doi:10.1103/PhysRevE.97.032118. PMID 29776109. S2CID 4955393.\n",
        " Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. US, Massachusetts: MIT Press. ISBN 9780262018258.\n",
        " Alpaydin, Ethem (2010). Introduction to Machine Learning. London: The MIT Press. ISBN 978-0-262-01243-0. Retrieved 4 February 2017.\n",
        " Jordan, M. I.; Mitchell, T. M. (17 July 2015). \"Machine learning: Trends, perspectives, and prospects\". Science. 349 (6245): 255–260. Bibcode:2015Sci...349..255J. doi:10.1126/science.aaa8415. PMID 26185243. S2CID 677218.\n",
        " El Naqa, Issam; Murphy, Martin J. (2015). \"What is Machine Learning?\". Machine Learning in Radiation Oncology. pp. 3–11. doi:10.1007/978-3-319-18305-3_1. ISBN 978-3-319-18304-6. S2CID 178586107.\n",
        " Okolie, Jude A.; Savage, Shauna; Ogbaga, Chukwuma C.; Gunes, Burcu (June 2022). \"Assessing the potential of machine learning methods to study the removal of pharmaceuticals from wastewater using biochar or activated carbon\". Total Environment Research Themes. 1–2: 100001. doi:10.1016/j.totert.2022.100001. S2CID 249022386.\n",
        " Russell, Stuart J.; Norvig, Peter (2010). Artificial Intelligence: A Modern Approach (Third ed.). Prentice Hall. ISBN 9780136042594.\n",
        " Mohri, Mehryar; Rostamizadeh, Afshin; Talwalkar, Ameet (2012). Foundations of Machine Learning. The MIT Press. ISBN 9780262018258.\n",
        " Alpaydin, Ethem (2010). Introduction to Machine Learning. MIT Press. p. 9. ISBN 978-0-262-01243-0. Archived from the original on 2023-01-17. Retrieved 2018-11-25.\n",
        " \"Lecture 2 Notes: Supervised Learning\". www.cs.cornell.edu. Retrieved 2024-07-01.\n",
        " Jordan, Michael I.; Bishop, Christopher M. (2004). \"Neural Networks\". In Allen B. Tucker (ed.). Computer Science Handbook, Second Edition (Section VII: Intelligent Systems). Boca Raton, Florida: Chapman & Hall/CRC Press LLC. ISBN 978-1-58488-360-9.\n",
        " Zhang, Bosen; Huang, Haiyan; Tibbs-Cortes, Laura E.; Vanous, Adam; Zhang, Zhiwu; Sanguinet, Karen; Garland-Campbell, Kimberly A.; Yu, Jianming; Li, Xianran (2023). \"Streamline unsupervised machine learning to survey and graph indel-based haplotypes from pan-genomes\". Molecular Plant. 16 (6): 975–978. doi:10.1016/j.molp.2023.05.005. PMID 37202927.\n",
        " Zhang, Bosen; Huang, Haiyan; Tibbs-Cortes, Laura E.; Vanous, Adam; Zhang, Zhiwu; Sanguinet, Karen; Garland-Campbell, Kimberly A.; Yu, Jianming; Li, Xianran (2023-02-13). Streamline unsupervised machine learning to survey and graph indel-based haplotypes from pan-genomes (Report). doi:10.1101/2023.02.11.527743.\n",
        " Misra, Ishan; Maaten, Laurens van der (2020). \"Self-Supervised Learning of Pretext-Invariant Representations\": 6707–6717. {{cite journal}}: Cite journal requires |journal= (help)\n",
        " Jaiswal, Ashish; Babu, Ashwin Ramesh; Zadeh, Mohammad Zaki; Banerjee, Debapriya; Makedon, Fillia (March 2021). \"A Survey on Contrastive Self-Supervised Learning\". Technologies. 9 (1): 2. arXiv:2011.00362. doi:10.3390/technologies9010002. ISSN 2227-7080.\n",
        " Alex Ratner; Stephen Bach; Paroma Varma; Chris. \"Weak Supervision: The New Programming Paradigm for Machine Learning\". hazyresearch.github.io. referencing work by many other members of Hazy Research. Archived from the original on 2019-06-06. Retrieved 2019-06-06.\n",
        " van Otterlo, M.; Wiering, M. (2012). \"Reinforcement Learning and Markov Decision Processes\". Reinforcement Learning. Adaptation, Learning, and Optimization. Vol. 12. pp. 3–42. doi:10.1007/978-3-642-27645-3_1. ISBN 978-3-642-27644-6.\n",
        " Roweis, Sam T.; Saul, Lawrence K. (22 Dec 2000). \"Nonlinear Dimensionality Reduction by Locally Linear Embedding\". Science. 290 (5500): 2323–2326. Bibcode:2000Sci...290.2323R. doi:10.1126/science.290.5500.2323. PMID 11125150. S2CID 5987139. Archived from the original on 15 August 2021. Retrieved 17 July 2023.\n",
        " Pavel Brazdil; Christophe Giraud Carrier; Carlos Soares; Ricardo Vilalta (2009). Metalearning: Applications to Data Mining (Fourth ed.). Springer Science+Business Media. pp. 10–14, passim. ISBN 978-3540732624.\n",
        " Bozinovski, S. (1982). \"A self-learning system using secondary reinforcement\". In Trappl, Robert (ed.). Cybernetics and Systems Research: Proceedings of the Sixth European Meeting on Cybernetics and Systems Research. North-Holland. pp. 397–402. ISBN 978-0-444-86488-8.\n",
        " Bozinovski, Stevo (2014) \"Modeling mechanisms of cognition-emotion interaction in artificial neural networks, since 1981.\" Procedia Computer Science p. 255-263\n",
        " Bozinovski, S. (2001) \"Self-learning agents: A connectionist theory of emotion based on crossbar value judgment.\" Cybernetics and Systems 32(6) 637–667.\n",
        " Y. Bengio; A. Courville; P. Vincent (2013). \"Representation Learning: A Review and New Perspectives\". IEEE Transactions on Pattern Analysis and Machine Intelligence. 35 (8): 1798–1828. arXiv:1206.5538. doi:10.1109/tpami.2013.50. PMID 23787338. S2CID 393948.\n",
        " Nathan Srebro; Jason D. M. Rennie; Tommi S. Jaakkola (2004). Maximum-Margin Matrix Factorization. NIPS.\n",
        " Coates, Adam; Lee, Honglak; Ng, Andrew Y. (2011). An analysis of single-layer networks in unsupervised feature learning (PDF). Int'l Conf. on AI and Statistics (AISTATS). Archived from the original (PDF) on 2017-08-13. Retrieved 2018-11-25.\n",
        " Csurka, Gabriella; Dance, Christopher C.; Fan, Lixin; Willamowski, Jutta; Bray, Cédric (2004). Visual categorization with bags of keypoints (PDF). ECCV Workshop on Statistical Learning in Computer Vision. Archived (PDF) from the original on 2019-07-13. Retrieved 2019-08-29.\n",
        " Daniel Jurafsky; James H. Martin (2009). Speech and Language Processing. Pearson Education International. pp. 145–146.\n",
        " Lu, Haiping; Plataniotis, K.N.; Venetsanopoulos, A.N. (2011). \"A Survey of Multilinear Subspace Learning for Tensor Data\" (PDF). Pattern Recognition. 44 (7): 1540–1551. Bibcode:2011PatRe..44.1540L. doi:10.1016/j.patcog.2011.01.004. Archived (PDF) from the original on 2019-07-10. Retrieved 2015-09-04.\n",
        " Yoshua Bengio (2009). Learning Deep Architectures for AI. Now Publishers Inc. pp. 1–3. ISBN 978-1-60198-294-0. Archived from the original on 2023-01-17. Retrieved 2016-02-15.\n",
        " Tillmann, A. M. (2015). \"On the Computational Intractability of Exact and Approximate Dictionary Learning\". IEEE Signal Processing Letters. 22 (1): 45–49. arXiv:1405.6664. Bibcode:2015ISPL...22...45T. doi:10.1109/LSP.2014.2345761. S2CID 13342762.\n",
        " Aharon, M, M Elad, and A Bruckstein. 2006. \"K-SVD: An Algorithm for Designing Overcomplete Dictionaries for Sparse Representation Archived 2018-11-23 at the Wayback Machine.\" Signal Processing, IEEE Transactions on 54 (11): 4311–4322\n",
        " Zimek, Arthur; Schubert, Erich (2017), \"Outlier Detection\", Encyclopedia of Database Systems, Springer New York, pp. 1–5, doi:10.1007/978-1-4899-7993-3_80719-1, ISBN 9781489979933\n",
        " Hodge, V. J.; Austin, J. (2004). \"A Survey of Outlier Detection Methodologies\" (PDF). Artificial Intelligence Review. 22 (2): 85–126. CiteSeerX 10.1.1.318.4023. doi:10.1007/s10462-004-4304-y. S2CID 59941878. Archived (PDF) from the original on 2015-06-22. Retrieved 2018-11-25.\n",
        " Dokas, Paul; Ertoz, Levent; Kumar, Vipin; Lazarevic, Aleksandar; Srivastava, Jaideep; Tan, Pang-Ning (2002). \"Data mining for network intrusion detection\" (PDF). Proceedings NSF Workshop on Next Generation Data Mining. Archived (PDF) from the original on 2015-09-23. Retrieved 2023-03-26.\n",
        " Chandola, V.; Banerjee, A.; Kumar, V. (2009). \"Anomaly detection: A survey\". ACM Computing Surveys. 41 (3): 1–58. doi:10.1145/1541880.1541882. S2CID 207172599.\n",
        " Fleer, S.; Moringen, A.; Klatzky, R. L.; Ritter, H. (2020). \"Learning efficient haptic shape exploration with a rigid tactile sensor array, S. Fleer, A. Moringen, R. Klatzky, H. Ritter\". PLOS ONE. 15 (1): e0226880. arXiv:1902.07501. doi:10.1371/journal.pone.0226880. PMC 6940144. PMID 31896135.\n",
        " Moringen, Alexandra; Fleer, Sascha; Walck, Guillaume; Ritter, Helge (2020), Nisky, Ilana; Hartcher-O'Brien, Jess; Wiertlewski, Michaël; Smeets, Jeroen (eds.), \"Attention-Based Robot Learning of Haptic Interaction\", Haptics: Science, Technology, Applications, Lecture Notes in Computer Science, vol. 12272, Cham: Springer International Publishing, pp. 462–470, doi:10.1007/978-3-030-58147-3_51, ISBN 978-3-030-58146-6, S2CID 220069113\n",
        " Piatetsky-Shapiro, Gregory (1991), Discovery, analysis, and presentation of strong rules, in Piatetsky-Shapiro, Gregory; and Frawley, William J.; eds., Knowledge Discovery in Databases, AAAI/MIT Press, Cambridge, MA.\n",
        " Bassel, George W.; Glaab, Enrico; Marquez, Julietta; Holdsworth, Michael J.; Bacardit, Jaume (2011-09-01). \"Functional Network Construction in Arabidopsis Using Rule-Based Machine Learning on Large-Scale Data Sets\". The Plant Cell. 23 (9): 3101–3116. doi:10.1105/tpc.111.088153. ISSN 1532-298X. PMC 3203449. PMID 21896882.\n",
        " Agrawal, R.; Imieliński, T.; Swami, A. (1993). \"Mining association rules between sets of items in large databases\". Proceedings of the 1993 ACM SIGMOD international conference on Management of data - SIGMOD '93. p. 207. CiteSeerX 10.1.1.40.6984. doi:10.1145/170035.170072. ISBN 978-0897915922. S2CID 490415.\n",
        " Urbanowicz, Ryan J.; Moore, Jason H. (2009-09-22). \"Learning Classifier Systems: A Complete Introduction, Review, and Roadmap\". Journal of Artificial Evolution and Applications. 2009: 1–25. doi:10.1155/2009/736398. ISSN 1687-6229.\n",
        " Plotkin G.D. Automatic Methods of Inductive Inference Archived 2017-12-22 at the Wayback Machine, PhD thesis, University of Edinburgh, 1970.\n",
        " Shapiro, Ehud Y. Inductive inference of theories from facts Archived 2021-08-21 at the Wayback Machine, Research Report 192, Yale University, Department of Computer Science, 1981. Reprinted in J.-L. Lassez, G. Plotkin (Eds.), Computational Logic, The MIT Press, Cambridge, MA, 1991, pp. 199–254.\n",
        " Shapiro, Ehud Y. (1983). Algorithmic program debugging. Cambridge, Mass: MIT Press. ISBN 0-262-19218-7\n",
        " Shapiro, Ehud Y. \"The model inference system Archived 2023-04-06 at the Wayback Machine.\" Proceedings of the 7th international joint conference on Artificial intelligence-Volume 2. Morgan Kaufmann Publishers Inc., 1981.\n",
        " Burkov, Andriy (2019). The hundred-page machine learning book. Polen: Andriy Burkov. ISBN 978-1-9995795-0-0.\n",
        " Russell, Stuart J.; Norvig, Peter (2021). Artificial intelligence: a modern approach. Pearson series in artificial intelligence (Fourth ed.). Hoboken: Pearson. ISBN 978-0-13-461099-3.\n",
        " Honglak Lee, Roger Grosse, Rajesh Ranganath, Andrew Y. Ng. \"Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations Archived 2017-10-18 at the Wayback Machine\" Proceedings of the 26th Annual International Conference on Machine Learning, 2009.\n",
        " Cortes, Corinna; Vapnik, Vladimir N. (1995). \"Support-vector networks\". Machine Learning. 20 (3): 273–297. doi:10.1007/BF00994018.\n",
        " Stevenson, Christopher. \"Tutorial: Polynomial Regression in Excel\". facultystaff.richmond.edu. Archived from the original on 2 June 2013. Retrieved 22 January 2017.\n",
        " The documentation for scikit-learn also has similar examples Archived 2022-11-02 at the Wayback Machine.\n",
        " Goldberg, David E.; Holland, John H. (1988). \"Genetic algorithms and machine learning\" (PDF). Machine Learning. 3 (2): 95–99. doi:10.1007/bf00113892. S2CID 35506513. Archived (PDF) from the original on 2011-05-16. Retrieved 2019-09-03.\n",
        " Michie, D.; Spiegelhalter, D. J.; Taylor, C. C. (1994). \"Machine Learning, Neural and Statistical Classification\". Ellis Horwood Series in Artificial Intelligence. Bibcode:1994mlns.book.....M.\n",
        " Zhang, Jun; Zhan, Zhi-hui; Lin, Ying; Chen, Ni; Gong, Yue-jiao; Zhong, Jing-hui; Chung, Henry S.H.; Li, Yun; Shi, Yu-hui (2011). \"Evolutionary Computation Meets Machine Learning: A Survey\". Computational Intelligence Magazine. 6 (4): 68–75. doi:10.1109/mci.2011.942584. S2CID 6760276.\n",
        " \"Federated Learning: Collaborative Machine Learning without Centralized Training Data\". Google AI Blog. 6 April 2017. Archived from the original on 2019-06-07. Retrieved 2019-06-08.\n",
        " Machine learning is included in the CFA Curriculum (discussion is top-down); see: Kathleen DeRose and Christophe Le Lanno (2020). \"Machine Learning\" Archived 2020-01-13 at the Wayback Machine.\n",
        " Ivanenko, Mikhail; Smolik, Waldemar T.; Wanta, Damian; Midura, Mateusz; Wróblewski, Przemysław; Hou, Xiaohan; Yan, Xiaoheng (2023). \"Image Reconstruction Using Supervised Learning in Wearable Electrical Impedance Tomography of the Thorax\". Sensors. 23 (18): 7774. Bibcode:2023Senso..23.7774I. doi:10.3390/s23187774. PMC 10538128. PMID 37765831.\n",
        " \"BelKor Home Page\" research.att.com\n",
        " \"The Netflix Tech Blog: Netflix Recommendations: Beyond the 5 stars (Part 1)\". 2012-04-06. Archived from the original on 31 May 2016. Retrieved 8 August 2015.\n",
        " Scott Patterson (13 July 2010). \"Letting the Machines Decide\". The Wall Street Journal. Archived from the original on 24 June 2018. Retrieved 24 June 2018.\n",
        " Vinod Khosla (January 10, 2012). \"Do We Need Doctors or Algorithms?\". Tech Crunch. Archived from the original on June 18, 2018. Retrieved October 20, 2016.\n",
        " When A Machine Learning Algorithm Studied Fine Art Paintings, It Saw Things Art Historians Had Never Noticed Archived 2016-06-04 at the Wayback Machine, The Physics at ArXiv blog\n",
        " Vincent, James (2019-04-10). \"The first AI-generated textbook shows what robot writers are actually good at\". The Verge. Archived from the original on 2019-05-05. Retrieved 2019-05-05.\n",
        " Vaishya, Raju; Javaid, Mohd; Khan, Ibrahim Haleem; Haleem, Abid (July 1, 2020). \"Artificial Intelligence (AI) applications for COVID-19 pandemic\". Diabetes & Metabolic Syndrome: Clinical Research & Reviews. 14 (4): 337–339. doi:10.1016/j.dsx.2020.04.012. PMC 7195043. PMID 32305024.\n",
        " Rezapouraghdam, Hamed; Akhshik, Arash; Ramkissoon, Haywantee (March 10, 2021). \"Application of machine learning to predict visitors' green behavior in marine protected areas: evidence from Cyprus\". Journal of Sustainable Tourism. 31 (11): 2479–2505. doi:10.1080/09669582.2021.1887878. hdl:10037/24073.\n",
        " Dey, Somdip; Singh, Amit Kumar; Wang, Xiaohang; McDonald-Maier, Klaus (2020-06-15). \"User Interaction Aware Reinforcement Learning for Power and Thermal Efficiency of CPU-GPU Mobile MPSoCs\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE) (PDF). pp. 1728–1733. doi:10.23919/DATE48585.2020.9116294. ISBN 978-3-9819263-4-7. S2CID 219858480. Archived from the original on 2021-12-13. Retrieved 2022-01-20.\n",
        " Quested, Tony. \"Smartphones get smarter with Essex innovation\". Business Weekly. Archived from the original on 2021-06-24. Retrieved 2021-06-17.\n",
        " Williams, Rhiannon (2020-07-21). \"Future smartphones 'will prolong their own battery life by monitoring owners' behaviour'\". i. Archived from the original on 2021-06-24. Retrieved 2021-06-17.\n",
        " Rasekhschaffe, Keywan Christian; Jones, Robert C. (2019-07-01). \"Machine Learning for Stock Selection\". Financial Analysts Journal. 75 (3): 70–88. doi:10.1080/0015198X.2019.1596678. ISSN 0015-198X. S2CID 108312507. Archived from the original on 2023-11-26. Retrieved 2023-11-26.\n",
        " Chung, Yunsie; Green, William H. (2024). \"Machine learning from quantum chemistry to predict experimental solvent effects on reaction rates\". Chemical Science. 15 (7): 2410–2424. doi:10.1039/D3SC05353A. ISSN 2041-6520. PMC 10866337. PMID 38362410. Archived from the original on 2024-05-19. Retrieved 2024-04-21.\n",
        " Sun, Yuran; Huang, Shih-Kai; Zhao, Xilei (2024-02-01). \"Predicting Hurricane Evacuation Decisions with Interpretable Machine Learning Methods\". International Journal of Disaster Risk Science. 15 (1): 134–148. doi:10.1007/s13753-024-00541-1. ISSN 2192-6395.\n",
        " Sun, Yuran; Zhao, Xilei; Lovreglio, Ruggiero; Kuligowski, Erica (2024-01-01), Naser, M. Z. (ed.), \"8 - AI for large-scale evacuation modeling: promises and challenges\", Interpretable Machine Learning for the Analysis, Design, Assessment, and Informed Decision Making for Civil Infrastructure, Woodhead Publishing Series in Civil and Structural Engineering, Woodhead Publishing, pp. 185–204, ISBN 978-0-12-824073-1, archived from the original on 2024-05-19, retrieved 2024-05-19\n",
        " Xu, Ningzhe; Lovreglio, Ruggiero; Kuligowski, Erica D.; Cova, Thomas J.; Nilsson, Daniel; Zhao, Xilei (2023-03-01). \"Predicting and Assessing Wildfire Evacuation Decision-Making Using Machine Learning: Findings from the 2019 Kincade Fire\". Fire Technology. 59 (2): 793–825. doi:10.1007/s10694-023-01363-1. ISSN 1572-8099. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n",
        " Wang, Ke; Shi, Xiupeng; Goh, Algena Pei Xuan; Qian, Shunzhi (2019-06-01). \"A machine learning based study on pedestrian movement dynamics under emergency evacuation\". Fire Safety Journal. 106: 163–176. doi:10.1016/j.firesaf.2019.04.008. hdl:10356/143390. ISSN 0379-7112. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n",
        " Zhao, Xilei; Lovreglio, Ruggiero; Nilsson, Daniel (2020-05-01). \"Modelling and interpreting pre-evacuation decision-making using machine learning\". Automation in Construction. 113: 103140. doi:10.1016/j.autcon.2020.103140. ISSN 0926-5805. Archived from the original on 2024-05-19. Retrieved 2024-05-19.\n",
        " \"Why Machine Learning Models Often Fail to Learn: QuickTake Q&A\". Bloomberg.com. 2016-11-10. Archived from the original on 2017-03-20. Retrieved 2017-04-10.\n",
        " \"The First Wave of Corporate AI Is Doomed to Fail\". Harvard Business Review. 2017-04-18. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n",
        " \"Why the A.I. euphoria is doomed to fail\". VentureBeat. 2016-09-18. Archived from the original on 2018-08-19. Retrieved 2018-08-20.\n",
        " \"9 Reasons why your machine learning project will fail\". www.kdnuggets.com. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n",
        " Babuta, Alexander; Oswald, Marion; Rinik, Christine (2018). Transparency and Intelligibility (Report). Royal United Services Institute (RUSI). pp. 17–22. Archived from the original on 2023-12-09. Retrieved 2023-12-09.\n",
        " \"Why Uber's self-driving car killed a pedestrian\". The Economist. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n",
        " \"IBM's Watson recommended 'unsafe and incorrect' cancer treatments – STAT\". STAT. 2018-07-25. Archived from the original on 2018-08-21. Retrieved 2018-08-21.\n",
        " Hernandez, Daniela; Greenwald, Ted (2018-08-11). \"IBM Has a Watson Dilemma\". The Wall Street Journal. ISSN 0099-9660. Archived from the original on 2018-08-21. Retrieved 2018-08-21.\n",
        " Allyn, Bobby (Feb 27, 2023). \"How Microsoft's experiment in artificial intelligence tech backfired\". National Public Radio. Archived from the original on December 8, 2023. Retrieved Dec 8, 2023.\n",
        " Reddy, Shivani M.; Patel, Sheila; Weyrich, Meghan; Fenton, Joshua; Viswanathan, Meera (2020). \"Comparison of a traditional systematic review approach with review-of-reviews and semi-automation as strategies to update the evidence\". Systematic Reviews. 9 (1): 243. doi:10.1186/s13643-020-01450-2. ISSN 2046-4053. PMC 7574591. PMID 33076975.\n",
        " Garcia, Megan (2016). \"Racist in the Machine\". World Policy Journal. 33 (4): 111–117. doi:10.1215/07402775-3813015. ISSN 0740-2775. S2CID 151595343.\n",
        " Caliskan, Aylin; Bryson, Joanna J.; Narayanan, Arvind (2017-04-14). \"Semantics derived automatically from language corpora contain human-like biases\". Science. 356 (6334): 183–186. arXiv:1608.07187. Bibcode:2017Sci...356..183C. doi:10.1126/science.aal4230. ISSN 0036-8075. PMID 28408601. S2CID 23163324.\n",
        " Wang, Xinan; Dasgupta, Sanjoy (2016), Lee, D. D.; Sugiyama, M.; Luxburg, U. V.; Guyon, I. (eds.), \"An algorithm for L1 nearest neighbor search via monotonic embedding\" (PDF), Advances in Neural Information Processing Systems 29, Curran Associates, Inc., pp. 983–991, archived (PDF) from the original on 2017-04-07, retrieved 2018-08-20\n",
        " Silva, Selena; Kenney, Martin (2018). \"Algorithms, Platforms, and Ethnic Bias: An Integrative Essay\" (PDF). Phylon. 55 (1 & 2): 9–37. ISSN 0031-8906. JSTOR 26545017. Archived (PDF) from the original on Jan 27, 2024.\n",
        " Vincent, James (Jan 12, 2018). \"Google 'fixed' its racist algorithm by removing gorillas from its image-labeling tech\". The Verge. Archived from the original on 2018-08-21. Retrieved 2018-08-20.\n",
        " Crawford, Kate (25 June 2016). \"Opinion | Artificial Intelligence's White Guy Problem\". New York Times. Archived from the original on 2021-01-14. Retrieved 2018-08-20.\n",
        " Metz, Rachel (March 24, 2016). \"Why Microsoft Accidentally Unleashed a Neo-Nazi Sexbot\". MIT Technology Review. Archived from the original on 2018-11-09. Retrieved 2018-08-20.\n",
        " Simonite, Tom (March 30, 2017). \"Microsoft: AI Isn't Yet Adaptable Enough to Help Businesses\". MIT Technology Review. Archived from the original on 2018-11-09. Retrieved 2018-08-20.\n",
        " Hempel, Jessi (2018-11-13). \"Fei-Fei Li's Quest to Make Machines Better for Humanity\". Wired. ISSN 1059-1028. Archived from the original on 2020-12-14. Retrieved 2019-02-17.\n",
        " Rudin, Cynthia (2019). \"Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\". Nature Machine Intelligence. 1 (5): 206–215. doi:10.1038/s42256-019-0048-x. PMC 9122117. PMID 35603010.\n",
        " Hu, Tongxi; Zhang, Xuesong; Bohrer, Gil; Liu, Yanlan; Zhou, Yuyu; Martin, Jay; LI, Yang; Zhao, Kaiguang (2023). \"Crop yield prediction via explainable AI and interpretable machine learning: Dangers of black box models for evaluating climate change impacts on crop yield\". Agricultural and Forest Meteorology. 336: 109458. doi:10.1016/j.agrformet.2023.109458. S2CID 258552400.\n",
        " Domingos 2015, Chapter 6, Chapter 7.\n",
        " Domingos 2015, p. 286.\n",
        " \"Single pixel change fools AI programs\". BBC News. 3 November 2017. Archived from the original on 22 March 2018. Retrieved 12 March 2018.\n",
        " \"AI Has a Hallucination Problem That's Proving Tough to Fix\". WIRED. 2018. Archived from the original on 12 March 2018. Retrieved 12 March 2018.\n",
        " Madry, A.; Makelov, A.; Schmidt, L.; Tsipras, D.; Vladu, A. (4 September 2019). \"Towards deep learning models resistant to adversarial attacks\". arXiv:1706.06083 [stat.ML].\n",
        " \"Adversarial Machine Learning – CLTC UC Berkeley Center for Long-Term Cybersecurity\". CLTC. Archived from the original on 2022-05-17. Retrieved 2022-05-25.\n",
        " \"Machine-learning models vulnerable to undetectable backdoors\". The Register. Archived from the original on 13 May 2022. Retrieved 13 May 2022.\n",
        " \"Undetectable Backdoors Plantable In Any Machine-Learning Algorithm\". IEEE Spectrum. 10 May 2022. Archived from the original on 11 May 2022. Retrieved 13 May 2022.\n",
        " Goldwasser, Shafi; Kim, Michael P.; Vaikuntanathan, Vinod; Zamir, Or (14 April 2022). \"Planting Undetectable Backdoors in Machine Learning Models\". arXiv:2204.06974 [cs.LG].\n",
        " Kohavi, Ron (1995). \"A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection\" (PDF). International Joint Conference on Artificial Intelligence. Archived (PDF) from the original on 2018-07-12. Retrieved 2023-03-26.\n",
        " Pontius, Robert Gilmore; Si, Kangping (2014). \"The total operating characteristic to measure diagnostic ability for multiple thresholds\". International Journal of Geographical Information Science. 28 (3): 570–583. Bibcode:2014IJGIS..28..570P. doi:10.1080/13658816.2013.862623. S2CID 29204880.\n",
        " Bostrom, Nick (2011). \"The Ethics of Artificial Intelligence\" (PDF). Archived from the original (PDF) on 4 March 2016. Retrieved 11 April 2016.\n",
        " Edionwe, Tolulope. \"The fight against racist algorithms\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\n",
        " Jeffries, Adrianne. \"Machine learning is racist because the internet is racist\". The Outline. Archived from the original on 17 November 2017. Retrieved 17 November 2017.\n",
        " Wong, Carissa (2023-03-30). \"AI 'fairness' research held back by lack of diversity\". Nature. doi:10.1038/d41586-023-00935-z. PMID 36997714. S2CID 257857012. Archived from the original on 2023-04-12. Retrieved 2023-12-09.\n",
        " Zhang, Jack Clark. \"Artificial Intelligence Index Report 2021\" (PDF). Stanford Institute for Human-Centered Artificial Intelligence. Archived (PDF) from the original on 2024-05-19. Retrieved 2023-12-09.\n",
        " Bostrom, Nick; Yudkowsky, Eliezer (2011). \"THE ETHICS OF ARTIFICIAL INTELLIGENCE\" (PDF). Nick Bostrom. Archived (PDF) from the original on 2015-12-20. Retrieved 2020-11-18.\n",
        " M.O.R. Prates; P.H.C. Avelar; L.C. Lamb (11 Mar 2019). \"Assessing Gender Bias in Machine Translation – A Case Study with Google Translate\". arXiv:1809.02208 [cs.CY].\n",
        " Narayanan, Arvind (August 24, 2016). \"Language necessarily contains human biases, and so will machines trained on language corpora\". Freedom to Tinker. Archived from the original on June 25, 2018. Retrieved November 19, 2016.\n",
        " Char, Danton S.; Shah, Nigam H.; Magnus, David (2018-03-15). \"Implementing Machine Learning in Health Care — Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981–983. doi:10.1056/NEJMp1714229. ISSN 0028-4793. PMC 5962261. PMID 29539284.\n",
        " Char, D. S.; Shah, N. H.; Magnus, D. (2018). \"Implementing Machine Learning in Health Care—Addressing Ethical Challenges\". New England Journal of Medicine. 378 (11): 981–983. doi:10.1056/nejmp1714229. PMC 5962261. PMID 29539284.\n",
        " Research, AI (23 October 2015). \"Deep Neural Networks for Acoustic Modeling in Speech Recognition\". airesearch.com. Archived from the original on 1 February 2016. Retrieved 23 October 2015.\n",
        " \"GPUs Continue to Dominate the AI Accelerator Market for Now\". InformationWeek. December 2019. Archived from the original on 10 June 2020. Retrieved 11 June 2020.\n",
        " Ray, Tiernan (2019). \"AI is changing the entire nature of compute\". ZDNet. Archived from the original on 25 May 2020. Retrieved 11 June 2020.\n",
        " \"AI and Compute\". OpenAI. 16 May 2018. Archived from the original on 17 June 2020. Retrieved 11 June 2020.\n",
        " \"Cornell & NTT's Physical Neural Networks: A \"Radical Alternative for Implementing Deep Neural Networks\" That Enables Arbitrary Physical Systems Training | Synced\". 27 May 2021. Archived from the original on 27 October 2021. Retrieved 12 October 2021.\n",
        " \"Nano-spaghetti to solve neural network power consumption\". Archived from the original on 2021-10-06. Retrieved 2021-10-12.\n",
        " Fafoutis, Xenofon; Marchegiani, Letizia; Elsts, Atis; Pope, James; Piechocki, Robert; Craddock, Ian (2018-05-07). \"Extending the battery lifetime of wearable sensors with embedded machine learning\". 2018 IEEE 4th World Forum on Internet of Things (WF-IoT). pp. 269–274. doi:10.1109/WF-IoT.2018.8355116. hdl:1983/b8fdb58b-7114-45c6-82e4-4ab239c1327f. ISBN 978-1-4673-9944-9. S2CID 19192912. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n",
        " \"A Beginner's Guide To Machine learning For Embedded Systems\". Analytics India Magazine. 2021-06-02. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n",
        " Synced (2022-01-12). \"Google, Purdue & Harvard U's Open-Source Framework for TinyML Achieves up to 75x Speedups on FPGAs | Synced\". syncedreview.com. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n",
        " Giri, Davide; Chiu, Kuan-Lin; Di Guglielmo, Giuseppe; Mantovani, Paolo; Carloni, Luca P. (2020-06-15). \"ESP4ML: Platform-Based Design of Systems-on-Chip for Embedded Machine Learning\". 2020 Design, Automation & Test in Europe Conference & Exhibition (DATE). pp. 1049–1054. arXiv:2004.03640. doi:10.23919/DATE48585.2020.9116317. ISBN 978-3-9819263-4-7. S2CID 210928161. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n",
        " Louis, Marcia Sahaya; Azad, Zahra; Delshadtehrani, Leila; Gupta, Suyog; Warden, Pete; Reddi, Vijay Janapa; Joshi, Ajay (2019). \"Towards Deep Learning using TensorFlow Lite on RISC-V\". Harvard University. Archived from the original on 2022-01-17. Retrieved 2022-01-17.\n",
        " Ibrahim, Ali; Osta, Mario; Alameh, Mohamad; Saleh, Moustafa; Chible, Hussein; Valle, Maurizio (2019-01-21). \"Approximate Computing Methods for Embedded Machine Learning\". 2018 25th IEEE International Conference on Electronics, Circuits and Systems (ICECS). pp. 845–848. doi:10.1109/ICECS.2018.8617877. ISBN 978-1-5386-9562-3. S2CID 58670712. Archived from the original on 2022-01-17. Retrieved 2022-01-17.\n",
        " \"dblp: TensorFlow Eager: A Multi-Stage, Python-Embedded DSL for Machine Learning\". dblp.org. Archived from the original on 2022-01-18. Retrieved 2022-01-17.\n",
        " Branco, Sérgio; Ferreira, André G.; Cabral, Jorge (2019-11-05). \"Machine Learning in Resource-Scarce Embedded Systems, FPGAs, and End-Devices: A Survey\". Electronics. 8 (11): 1289. doi:10.3390/electronics8111289. hdl:1822/62521. ISSN 2079-9292.\n",
        "Sources\n",
        "Domingos, Pedro (September 22, 2015). The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World. Basic Books. ISBN 978-0465065707.\n",
        "Nilsson, Nils (1998). Artificial Intelligence: A New Synthesis. Morgan Kaufmann. ISBN 978-1-55860-467-4. Archived from the original on 26 July 2020. Retrieved 18 November 2019.\n",
        "Russell, Stuart J.; Norvig, Peter (2003), Artificial Intelligence: A Modern Approach (2nd ed.), Upper Saddle River, New Jersey: Prentice Hall, ISBN 0-13-790395-2.\n",
        "Poole, David; Mackworth, Alan; Goebel, Randy (1998). Computational Intelligence: A Logical Approach. New York: Oxford University Press. ISBN 978-0-19-510270-3. Archived from the original on 26 July 2020. Retrieved 22 August 2020.\n",
        "Further reading\n",
        "Nils J. Nilsson, Introduction to Machine Learning Archived 2019-08-16 at the Wayback Machine.\n",
        "Trevor Hastie, Robert Tibshirani and Jerome H. Friedman (2001). The Elements of Statistical Learning Archived 2013-10-27 at the Wayback Machine, Springer. ISBN 0-387-95284-5.\n",
        "Pedro Domingos (September 2015), The Master Algorithm, Basic Books, ISBN 978-0-465-06570-7\n",
        "Ian H. Witten and Eibe Frank (2011). Data Mining: Practical machine learning tools and techniques Morgan Kaufmann, 664pp., ISBN 978-0-12-374856-0.\n",
        "Ethem Alpaydin (2004). Introduction to Machine Learning, MIT Press, ISBN 978-0-262-01243-0.\n",
        "David J. C. MacKay. Information Theory, Inference, and Learning Algorithms Archived 2016-02-17 at the Wayback Machine Cambridge: Cambridge University Press, 2003. ISBN 0-521-64298-1\n",
        "Richard O. Duda, Peter E. Hart, David G. Stork (2001) Pattern classification (2nd edition), Wiley, New York, ISBN 0-471-05669-3.\n",
        "Christopher Bishop (1995). Neural Networks for Pattern Recognition, Oxford University Press. ISBN 0-19-853864-2.\n",
        "Stuart Russell & Peter Norvig, (2009). Artificial Intelligence – A Modern Approach Archived 2011-02-28 at the Wayback Machine. Pearson, ISBN 9789332543515.\n",
        "Ray Solomonoff, An Inductive Inference Machine, IRE Convention Record, Section on Information Theory, Part 2, pp., 56–62, 1957.\n",
        "Ray Solomonoff, An Inductive Inference Machine Archived 2011-04-26 at the Wayback Machine A privately circulated report from the 1956 Dartmouth Summer Research Conference on AI.\n",
        "Kevin P. Murphy (2021). Probabilistic Machine Learning: An Introduction Archived 2021-04-11 at the Wayback Machine, MIT Press.\n",
        "External links\n",
        "\n",
        "Wikimedia Commons has media related to Machine learning.\n",
        " Quotations related to Machine learning at Wikiquote\n",
        "International Machine Learning Society\n",
        "mloss is an academic database of open-source machine learning software.\"\"\"\n",
        "\n",
        "\n",
        "tokens = tokenize_context(context)\n",
        "chunks = chunk_context(context)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VpLNF5RP35On",
        "outputId": "a03b8fe6-1bc5-4f2f-af6b-4e1001986de5"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['journal', 'machine', 'learning', 'journal', 'statistical', 'learning', 'redirects', 'statistical', 'learning', 'linguistics', 'statistical', 'learning', 'language', 'acquisition', 'series', 'machine', 'learning', 'data', 'mining', 'paradigms', 'problems', 'supervised', 'learning', 'classification', 'regression', 'clustering', 'dimensionality', 'reduction', 'structured', 'prediction', 'anomaly', 'detection', 'artificial', 'neural', 'network', 'reinforcement', 'learning', 'learning', 'humans', 'model', 'diagnostics', 'mathematical', 'foundations', 'machine', 'learning', 'venues', 'related', 'articles', 'vte', 'series', 'artificial', 'intelligence', 'major', 'goals', 'artificial', 'general', 'intelligenceintelligent', 'agentrecursive', 'self', 'improvementplanningcomputer', 'visiongeneral', 'game', 'playingknowledge', 'reasoningnatural', 'language', 'processingroboticsai', 'safety', 'approaches', 'applications', 'philosophy', 'history', 'glossary', 'vte', 'machine', 'learning', 'ml', 'field', 'study', 'artificial', 'intelligence', 'concerned', 'development', 'study', 'statistical', 'algorithms', 'learn', 'data', 'generalize', 'unseen', 'data', 'perform', 'tasks', 'explicit', 'instructions.[1', 'recently', 'artificial', 'neural', 'networks', 'able', 'surpass', 'previous', 'approaches', 'performance.[2', 'ml', 'finds', 'application', 'fields', 'including', 'natural', 'language', 'processing', 'computer', 'vision', 'speech', 'recognition', 'email', 'filtering', 'agriculture', 'medicine.[3][4', 'applied', 'business', 'problems', 'known', 'predictive', 'analytics', 'machine', 'learning', 'statistically', 'based', 'computational', 'statistics', 'important', 'source', 'field', 'methods', 'mathematical', 'foundations', 'ml', 'provided', 'mathematical', 'optimization', 'mathematical', 'programming', 'methods', 'data', 'mining', 'related', 'parallel', 'field', 'study', 'focusing', 'exploratory', 'data', 'analysis', 'eda', 'unsupervised', 'learning.[6][7', 'theoretical', 'viewpoint', 'probably', 'approximately', 'correct', 'pac', 'learning', 'provides', 'framework', 'describing', 'machine', 'learning', 'history', 'timeline', 'machine', 'learning', 'term', 'machine', 'learning', 'coined', '1959', 'arthur', 'samuel', 'ibm', 'employee', 'pioneer', 'field', 'computer', 'gaming', 'artificial', 'intelligence.[8][9', 'synonym', 'self', 'teaching', 'computers', 'time', 'period.[10][11', 'earliest', 'machine', 'learning', 'model', 'introduced', '1950s', 'arthur', 'samuel', 'invented', 'program', 'calculated', 'winning', 'chance', 'checkers', 'history', 'machine', 'learning', 'roots', 'decades', 'human', 'desire', 'effort', 'study', 'human', 'cognitive', 'processes.[12', '1949', 'canadian', 'psychologist', 'donald', 'hebb', 'published', 'book', 'organization', 'behavior', 'introduced', 'theoretical', 'neural', 'structure', 'formed', 'certain', 'interactions', 'nerve', 'cells.[13', 'hebb', 'model', 'neurons', 'interacting', 'set', 'groundwork', 'ais', 'machine', 'learning', 'algorithms', 'work', 'nodes', 'artificial', 'neurons', 'computers', 'communicate', 'data.[12', 'researchers', 'studied', 'human', 'cognitive', 'systems', 'contributed', 'modern', 'machine', 'learning', 'technologies', 'including', 'logician', 'walter', 'pitts', 'warren', 'mcculloch', 'proposed', 'early', 'mathematical', 'models', 'neural', 'networks', 'come', 'algorithms', 'mirror', 'human', 'thought', 'processes.[12', 'early', '1960s', 'experimental', 'learning', 'machine', 'punched', 'tape', 'memory', 'called', 'cybertron', 'developed', 'raytheon', 'company', 'analyze', 'sonar', 'signals', 'electrocardiograms', 'speech', 'patterns', 'rudimentary', 'reinforcement', 'learning', 'repetitively', 'trained', 'human', 'operator', 'teacher', 'recognize', 'patterns', 'equipped', 'goof', 'button', 'cause', 'reevaluate', 'incorrect', 'decisions.[14', 'representative', 'book', 'research', 'machine', 'learning', '1960s', 'nilsson', 'book', 'learning', 'machines', 'dealing', 'machine', 'learning', 'pattern', 'classification.[15', 'interest', 'related', 'pattern', 'recognition', 'continued', '1970s', 'described', 'duda', 'hart', '1973.[16', '1981', 'report', 'given', 'teaching', 'strategies', 'artificial', 'neural', 'network', 'learns', 'recognize', '40', 'characters', '26', 'letters', '10', 'digits', '4', 'special', 'symbols', 'computer', 'terminal.[17', 'tom', 'm.', 'mitchell', 'provided', 'widely', 'quoted', 'formal', 'definition', 'algorithms', 'studied', 'machine', 'learning', 'field', 'computer', 'program', 'said', 'learn', 'experience', 'e', 'respect', 'class', 'tasks', 't', 'performance', 'measure', 'p', 'performance', 'tasks', 't', 'measured', 'p', 'improves', 'experience', 'e.\"[18', 'definition', 'tasks', 'machine', 'learning', 'concerned', 'offers', 'fundamentally', 'operational', 'definition', 'defining', 'field', 'cognitive', 'terms', 'follows', 'alan', 'turing', 'proposal', 'paper', 'computing', 'machinery', 'intelligence', 'question', 'machines', 'think', 'replaced', 'question', 'machines', 'thinking', 'entities', 'do?\".[19', 'modern', 'day', 'machine', 'learning', 'objectives', 'classify', 'data', 'based', 'models', 'developed', 'purpose', 'predictions', 'future', 'outcomes', 'based', 'models', 'hypothetical', 'algorithm', 'specific', 'classifying', 'data', 'use', 'computer', 'vision', 'moles', 'coupled', 'supervised', 'learning', 'order', 'train', 'classify', 'cancerous', 'moles', 'machine', 'learning', 'algorithm', 'stock', 'trading', 'inform', 'trader', 'future', 'potential', 'predictions.[20', 'relationships', 'fields', 'artificial', 'intelligence', 'machine', 'learning', 'subfield', 'ai[21', 'scientific', 'endeavor', 'machine', 'learning', 'grew', 'quest', 'artificial', 'intelligence', 'ai', 'early', 'days', 'ai', 'academic', 'discipline', 'researchers', 'interested', 'having', 'machines', 'learn', 'data', 'attempted', 'approach', 'problem', 'symbolic', 'methods', 'termed', 'neural', 'networks', 'perceptrons', 'models', 'later', 'found', 'reinventions', 'generalized', 'linear', 'models', 'statistics.[22', 'probabilistic', 'reasoning', 'employed', 'especially', 'automated', 'medical', 'diagnosis.[23', '488', 'increasing', 'emphasis', 'logical', 'knowledge', 'based', 'approach', 'caused', 'rift', 'ai', 'machine', 'learning', 'probabilistic', 'systems', 'plagued', 'theoretical', 'practical', 'problems', 'data', 'acquisition', 'representation.[23', '488', '1980', 'expert', 'systems', 'come', 'dominate', 'ai', 'statistics', 'favor.[24', 'work', 'symbolic', 'knowledge', 'based', 'learning', 'continue', 'ai', 'leading', 'inductive', 'logic', 'programming(ilp', 'statistical', 'line', 'research', 'outside', 'field', 'ai', 'proper', 'pattern', 'recognition', 'information', 'retrieval.[23', '708–710', '755', 'neural', 'networks', 'research', 'abandoned', 'ai', 'computer', 'science', 'time', 'line', 'continued', 'outside', 'ai', 'cs', 'field', 'connectionism', 'researchers', 'disciplines', 'including', 'hopfield', 'rumelhart', 'hinton', 'main', 'success', 'came', 'mid-1980s', 'reinvention', 'backpropagation.[23', '25', 'machine', 'learning', 'ml', 'reorganized', 'recognized', 'field', 'started', 'flourish', '1990s', 'field', 'changed', 'goal', 'achieving', 'artificial', 'intelligence', 'tackling', 'solvable', 'problems', 'practical', 'nature', 'shifted', 'focus', 'away', 'symbolic', 'approaches', 'inherited', 'ai', 'methods', 'models', 'borrowed', 'statistics', 'fuzzy', 'logic', 'probability', 'theory.[24', 'data', 'compression', 'section', 'excerpt', 'data', 'compression', 'machine', 'learning.[edit', 'close', 'connection', 'machine', 'learning', 'compression', 'system', 'predicts', 'posterior', 'probabilities', 'sequence', 'given', 'entire', 'history', 'optimal', 'data', 'compression', 'arithmetic', 'coding', 'output', 'distribution', 'conversely', 'optimal', 'compressor', 'prediction', 'finding', 'symbol', 'compresses', 'best', 'given', 'previous', 'history', 'equivalence', 'justification', 'data', 'compression', 'benchmark', 'general', 'intelligence\".[25][26][27', 'alternative', 'view', 'compression', 'algorithms', 'implicitly', 'map', 'strings', 'implicit', 'feature', 'space', 'vectors', 'compression', 'based', 'similarity', 'measures', 'compute', 'similarity', 'feature', 'spaces', 'compressor', 'c', 'define', 'associated', 'vector', 'space', 'ℵ', 'c', 'maps', 'input', 'string', 'x', 'corresponding', 'vector', 'norm', '||~x||', 'exhaustive', 'examination', 'feature', 'spaces', 'underlying', 'compression', 'algorithms', 'precluded', 'space', 'instead', 'feature', 'vectors', 'chooses', 'examine', 'representative', 'lossless', 'compression', 'methods', 'lzw', 'lz77', 'ppm.[28', 'according', 'aixi', 'theory', 'connection', 'directly', 'explained', 'hutter', 'prize', 'best', 'possible', 'compression', 'x', 'smallest', 'possible', 'software', 'generates', 'x.', 'example', 'model', 'zip', 'file', 'compressed', 'size', 'includes', 'zip', 'file', 'unzipping', 'software', 'unzip', 'smaller', 'combined', 'form', 'examples', 'ai', 'powered', 'audio', 'video', 'compression', 'software', 'include', 'nvidia', 'maxine', 'aivc.[29', 'examples', 'software', 'perform', 'ai', 'powered', 'image', 'compression', 'include', 'opencv', 'tensorflow', 'matlab', 'image', 'processing', 'toolbox', 'ipt', 'high', 'fidelity', 'generative', 'image', 'compression.[30', 'unsupervised', 'machine', 'learning', 'k', 'means', 'clustering', 'utilized', 'compress', 'data', 'grouping', 'similar', 'data', 'points', 'clusters', 'technique', 'simplifies', 'handling', 'extensive', 'datasets', 'lack', 'predefined', 'labels', 'finds', 'widespread', 'use', 'fields', 'image', 'compression.[31', 'data', 'compression', 'aims', 'reduce', 'size', 'data', 'files', 'enhancing', 'storage', 'efficiency', 'speeding', 'data', 'transmission', 'k', 'means', 'clustering', 'unsupervised', 'machine', 'learning', 'algorithm', 'employed', 'partition', 'dataset', 'specified', 'number', 'clusters', 'k', 'represented', 'centroid', 'points', 'process', 'condenses', 'extensive', 'datasets', 'compact', 'set', 'representative', 'points', 'particularly', 'beneficial', 'image', 'signal', 'processing', 'k', 'means', 'clustering', 'aids', 'data', 'reduction', 'replacing', 'groups', 'data', 'points', 'centroids', 'preserving', 'core', 'information', 'original', 'data', 'significantly', 'decreasing', 'required', 'storage', 'space.[32', 'large', 'language', 'models', 'llms', 'capable', 'lossless', 'data', 'compression', 'demonstrated', 'deepmind', 'research', 'chinchilla', '70b', 'model', 'developed', 'deepmind', 'chinchilla', '70b', 'effectively', 'compressed', 'data', 'outperforming', 'conventional', 'methods', 'portable', 'network', 'graphics', 'png', 'images', 'free', 'lossless', 'audio', 'codec', 'flac', 'audio', 'achieved', 'compression', 'image', 'audio', 'data', '43.4', '16.4', 'original', 'sizes', 'respectively.[33', 'data', 'mining', 'machine', 'learning', 'data', 'mining', 'employ', 'methods', 'overlap', 'significantly', 'machine', 'learning', 'focuses', 'prediction', 'based', 'known', 'properties', 'learned', 'training', 'data', 'data', 'mining', 'focuses', 'discovery', 'previously', 'unknown', 'properties', 'data', 'analysis', 'step', 'knowledge', 'discovery', 'databases', 'data', 'mining', 'uses', 'machine', 'learning', 'methods', 'different', 'goals', 'hand', 'machine', 'learning', 'employs', 'data', 'mining', 'methods', 'unsupervised', 'learning', 'preprocessing', 'step', 'improve', 'learner', 'accuracy', 'confusion', 'research', 'communities', 'separate', 'conferences', 'separate', 'journals', 'ecml', 'pkdd', 'major', 'exception', 'comes', 'basic', 'assumptions', 'work', 'machine', 'learning', 'performance', 'usually', 'evaluated', 'respect', 'ability', 'reproduce', 'known', 'knowledge', 'knowledge', 'discovery', 'data', 'mining', 'kdd', 'key', 'task', 'discovery', 'previously', 'unknown', 'knowledge', 'evaluated', 'respect', 'known', 'knowledge', 'uninformed', 'unsupervised', 'method', 'easily', 'outperformed', 'supervised', 'methods', 'typical', 'kdd', 'task', 'supervised', 'methods', 'unavailability', 'training', 'data', 'machine', 'learning', 'intimate', 'ties', 'optimization', 'learning', 'problems', 'formulated', 'minimization', 'loss', 'function', 'training', 'set', 'examples', 'loss', 'functions', 'express', 'discrepancy', 'predictions', 'model', 'trained', 'actual', 'problem', 'instances', 'example', 'classification', 'wants', 'assign', 'label', 'instances', 'models', 'trained', 'correctly', 'predict', 'preassigned', 'labels', 'set', 'examples).[34', 'generalization', 'difference', 'optimization', 'machine', 'learning', 'arises', 'goal', 'generalization', 'optimization', 'algorithms', 'minimize', 'loss', 'training', 'set', 'machine', 'learning', 'concerned', 'minimizing', 'loss', 'unseen', 'samples', 'characterizing', 'generalization', 'learning', 'algorithms', 'active', 'topic', 'current', 'research', 'especially', 'deep', 'learning', 'algorithms', 'statistics', 'machine', 'learning', 'statistics', 'closely', 'related', 'fields', 'terms', 'methods', 'distinct', 'principal', 'goal', 'statistics', 'draws', 'population', 'inferences', 'sample', 'machine', 'learning', 'finds', 'generalizable', 'predictive', 'patterns.[35', 'according', 'michael', 'i.', 'jordan', 'ideas', 'machine', 'learning', 'methodological', 'principles', 'theoretical', 'tools', 'long', 'pre', 'history', 'statistics.[36', 'suggested', 'term', 'data', 'science', 'placeholder', 'overall', 'field.[36', 'conventional', 'statistical', 'analyses', 'require', 'priori', 'selection', 'model', 'suitable', 'study', 'data', 'set', 'addition', 'significant', 'theoretically', 'relevant', 'variables', 'based', 'previous', 'experience', 'included', 'analysis', 'contrast', 'machine', 'learning', 'built', 'pre', 'structured', 'model', 'data', 'shape', 'model', 'detecting', 'underlying', 'patterns', 'variables', 'input', 'train', 'model', 'accurate', 'ultimate', 'model', 'be.[37', 'leo', 'breiman', 'distinguished', 'statistical', 'modeling', 'paradigms', 'data', 'model', 'algorithmic', 'model,[38', 'algorithmic', 'model', 'means', 'machine', 'learning', 'algorithms', 'like', 'random', 'forest', 'statisticians', 'adopted', 'methods', 'machine', 'learning', 'leading', 'combined', 'field', 'statistical', 'learning.[39', 'statistical', 'physics', 'analytical', 'computational', 'techniques', 'derived', 'deep', 'rooted', 'physics', 'disordered', 'systems', 'extended', 'large', 'scale', 'problems', 'including', 'machine', 'learning', 'e.g.', 'analyze', 'weight', 'space', 'deep', 'neural', 'networks.[40', 'statistical', 'physics', 'finding', 'applications', 'area', 'medical', 'diagnostics.[41', 'theory', 'main', 'articles', 'computational', 'learning', 'theory', 'statistical', 'learning', 'theory', 'core', 'objective', 'learner', 'generalize', 'experience.[5][42', 'generalization', 'context', 'ability', 'learning', 'machine', 'perform', 'accurately', 'new', 'unseen', 'examples', 'tasks', 'having', 'experienced', 'learning', 'data', 'set', 'training', 'examples', 'come', 'generally', 'unknown', 'probability', 'distribution', 'considered', 'representative', 'space', 'occurrences', 'learner', 'build', 'general', 'model', 'space', 'enables', 'produce', 'sufficiently', 'accurate', 'predictions', 'new', 'cases', 'computational', 'analysis', 'machine', 'learning', 'algorithms', 'performance', 'branch', 'theoretical', 'computer', 'science', 'known', 'computational', 'learning', 'theory', 'probably', 'approximately', 'correct', 'learning', 'pac', 'model', 'training', 'sets', 'finite', 'future', 'uncertain', 'learning', 'theory', 'usually', 'yield', 'guarantees', 'performance', 'algorithms', 'instead', 'probabilistic', 'bounds', 'performance', 'common', 'bias', 'variance', 'decomposition', 'way', 'quantify', 'generalization', 'error', 'best', 'performance', 'context', 'generalization', 'complexity', 'hypothesis', 'match', 'complexity', 'function', 'underlying', 'data', 'hypothesis', 'complex', 'function', 'model', 'fitted', 'data', 'complexity', 'model', 'increased', 'response', 'training', 'error', 'decreases', 'hypothesis', 'complex', 'model', 'subject', 'overfitting', 'generalization', 'poorer.[43', 'addition', 'performance', 'bounds', 'learning', 'theorists', 'study', 'time', 'complexity', 'feasibility', 'learning', 'computational', 'learning', 'theory', 'computation', 'considered', 'feasible', 'polynomial', 'time', 'kinds', 'time', 'complexity', 'results', 'positive', 'results', 'certain', 'class', 'functions', 'learned', 'polynomial', 'time', 'negative', 'results', 'certain', 'classes', 'learned', 'polynomial', 'time', 'approaches', 'machine', 'learning', 'approaches', 'traditionally', 'divided', 'broad', 'categories', 'correspond', 'learning', 'paradigms', 'depending', 'nature', 'signal', 'feedback', 'available', 'learning', 'system', 'supervised', 'learning', 'computer', 'presented', 'example', 'inputs', 'desired', 'outputs', 'given', 'teacher', 'goal', 'learn', 'general', 'rule', 'maps', 'inputs', 'outputs', 'unsupervised', 'learning', 'labels', 'given', 'learning', 'algorithm', 'leaving', 'find', 'structure', 'input', 'unsupervised', 'learning', 'goal', 'discovering', 'hidden', 'patterns', 'data', 'means', 'end', 'feature', 'learning', 'reinforcement', 'learning', 'computer', 'program', 'interacts', 'dynamic', 'environment', 'perform', 'certain', 'goal', 'driving', 'vehicle', 'playing', 'game', 'opponent', 'navigates', 'problem', 'space', 'program', 'provided', 'feedback', 'analogous', 'rewards', 'tries', 'maximize.[5', 'algorithm', 'advantages', 'limitations', 'single', 'algorithm', 'works', 'problems.[44][45][46', 'supervised', 'learning', 'main', 'article', 'supervised', 'learning', 'support', 'vector', 'machine', 'supervised', 'learning', 'model', 'divides', 'data', 'regions', 'separated', 'linear', 'boundary', 'linear', 'boundary', 'divides', 'black', 'circles', 'white', 'supervised', 'learning', 'algorithms', 'build', 'mathematical', 'model', 'set', 'data', 'contains', 'inputs', 'desired', 'outputs.[47', 'data', 'known', 'training', 'data', 'consists', 'set', 'training', 'examples', 'training', 'example', 'inputs', 'desired', 'output', 'known', 'supervisory', 'signal', 'mathematical', 'model', 'training', 'example', 'represented', 'array', 'vector', 'called', 'feature', 'vector', 'training', 'data', 'represented', 'matrix', 'iterative', 'optimization', 'objective', 'function', 'supervised', 'learning', 'algorithms', 'learn', 'function', 'predict', 'output', 'associated', 'new', 'inputs.[48', 'optimal', 'function', 'allows', 'algorithm', 'correctly', 'determine', 'output', 'inputs', 'training', 'data', 'algorithm', 'improves', 'accuracy', 'outputs', 'predictions', 'time', 'said', 'learned', 'perform', 'task.[18', 'types', 'supervised', 'learning', 'algorithms', 'include', 'active', 'learning', 'classification', 'regression.[49', 'classification', 'algorithms', 'outputs', 'restricted', 'limited', 'set', 'values', 'regression', 'algorithms', 'outputs', 'numerical', 'value', 'range', 'example', 'classification', 'algorithm', 'filters', 'emails', 'input', 'incoming', 'email', 'output', 'folder', 'file', 'email', 'examples', 'regression', 'predicting', 'height', 'person', 'future', 'temperature', '50', 'similarity', 'learning', 'area', 'supervised', 'machine', 'learning', 'closely', 'related', 'regression', 'classification', 'goal', 'learn', 'examples', 'similarity', 'function', 'measures', 'similar', 'related', 'objects', 'applications', 'ranking', 'recommendation', 'systems', 'visual', 'identity', 'tracking', 'face', 'verification', 'speaker', 'verification', 'unsupervised', 'learning', 'main', 'article', 'unsupervised', 'learning', 'cluster', 'analysis', 'unsupervised', 'learning', 'algorithms', 'find', 'structures', 'data', 'labeled', 'classified', 'categorized', 'instead', 'responding', 'feedback', 'unsupervised', 'learning', 'algorithms', 'identify', 'commonalities', 'data', 'react', 'based', 'presence', 'absence', 'commonalities', 'new', 'piece', 'data', 'central', 'applications', 'unsupervised', 'machine', 'learning', 'include', 'clustering', 'dimensionality', 'reduction,[7', 'density', 'estimation.[51', 'unsupervised', 'learning', 'algorithms', 'streamlined', 'process', 'identifying', 'large', 'indel', 'based', 'haplotypes', 'gene', 'interest', 'pan', 'genome.[52', 'clustering', 'large', 'indel', 'permuted', 'slopes', 'clips,[53', 'turns', 'alignment', 'image', 'learning', 'regression', 'problem', 'varied', 'slope', 'b', 'estimates', 'pair', 'dna', 'segments', 'enables', 'identify', 'segments', 'sharing', 'set', 'indels', 'cluster', 'analysis', 'assignment', 'set', 'observations', 'subsets', 'called', 'clusters', 'observations', 'cluster', 'similar', 'according', 'predesignated', 'criteria', 'observations', 'drawn', 'different', 'clusters', 'dissimilar', 'different', 'clustering', 'techniques', 'different', 'assumptions', 'structure', 'data', 'defined', 'similarity', 'metric', 'evaluated', 'example', 'internal', 'compactness', 'similarity', 'members', 'cluster', 'separation', 'difference', 'clusters', 'methods', 'based', 'estimated', 'density', 'graph', 'connectivity', 'special', 'type', 'unsupervised', 'learning', 'called', 'self', 'supervised', 'learning', 'involves', 'training', 'model', 'generating', 'supervisory', 'signal', 'data', 'itself.[54][55', 'semi', 'supervised', 'learning', 'main', 'article', 'semi', 'supervised', 'learning', 'semi', 'supervised', 'learning', 'falls', 'unsupervised', 'learning', 'labeled', 'training', 'data', 'supervised', 'learning', 'completely', 'labeled', 'training', 'data', 'training', 'examples', 'missing', 'training', 'labels', 'machine', 'learning', 'researchers', 'found', 'unlabeled', 'data', 'conjunction', 'small', 'labeled', 'data', 'produce', 'considerable', 'improvement', 'learning', 'accuracy', 'weakly', 'supervised', 'learning', 'training', 'labels', 'noisy', 'limited', 'imprecise', 'labels', 'cheaper', 'obtain', 'resulting', 'larger', 'effective', 'training', 'sets.[56', 'reinforcement', 'learning', 'main', 'article', 'reinforcement', 'learning', 'reinforcement', 'learning', 'area', 'machine', 'learning', 'concerned', 'software', 'agents', 'ought', 'actions', 'environment', 'maximize', 'notion', 'cumulative', 'reward', 'generality', 'field', 'studied', 'disciplines', 'game', 'theory', 'control', 'theory', 'operations', 'research', 'information', 'theory', 'simulation', 'based', 'optimization', 'multi', 'agent', 'systems', 'swarm', 'intelligence', 'statistics', 'genetic', 'algorithms', 'reinforcement', 'learning', 'environment', 'typically', 'represented', 'markov', 'decision', 'process', 'mdp', 'reinforcements', 'learning', 'algorithms', 'use', 'dynamic', 'programming', 'techniques.[57', 'reinforcement', 'learning', 'algorithms', 'assume', 'knowledge', 'exact', 'mathematical', 'model', 'mdp', 'exact', 'models', 'infeasible', 'reinforcement', 'learning', 'algorithms', 'autonomous', 'vehicles', 'learning', 'play', 'game', 'human', 'opponent', 'dimensionality', 'reduction', 'dimensionality', 'reduction', 'process', 'reducing', 'number', 'random', 'variables', 'consideration', 'obtaining', 'set', 'principal', 'variables.[58', 'words', 'process', 'reducing', 'dimension', 'feature', 'set', 'called', 'number', 'features', 'dimensionality', 'reduction', 'techniques', 'considered', 'feature', 'elimination', 'extraction', 'popular', 'methods', 'dimensionality', 'reduction', 'principal', 'component', 'analysis', 'pca', 'pca', 'involves', 'changing', 'higher', 'dimensional', 'data', 'e.g.', '3d', 'smaller', 'space', 'e.g.', '2d', 'manifold', 'hypothesis', 'proposes', 'high', 'dimensional', 'data', 'sets', 'lie', 'low', 'dimensional', 'manifolds', 'dimensionality', 'reduction', 'techniques', 'assumption', 'leading', 'area', 'manifold', 'learning', 'manifold', 'regularization', 'types', 'approaches', 'developed', 'fit', 'neatly', 'fold', 'categorization', 'machine', 'learning', 'system', 'example', 'topic', 'modeling', 'meta', 'learning.[59', 'self', 'learning', 'self', 'learning', 'machine', 'learning', 'paradigm', 'introduced', '1982', 'neural', 'network', 'capable', 'self', 'learning', 'named', 'crossbar', 'adaptive', 'array', 'caa).[60', 'learning', 'external', 'rewards', 'external', 'teacher', 'advice', 'caa', 'self', 'learning', 'algorithm', 'computes', 'crossbar', 'fashion', 'decisions', 'actions', 'emotions', 'feelings', 'consequence', 'situations', 'system', 'driven', 'interaction', 'cognition', 'emotion.[61', 'self', 'learning', 'algorithm', 'updates', 'memory', 'matrix', 'w', '=', '||w(a', 's)||', 'iteration', 'executes', 'following', 'machine', 'learning', 'routine', 'situation', 's', 'perform', 'action', 'receive', 'consequence', 'situation', 's', 'compute', 'emotion', 'consequence', 'situation', 'v(s', 'update', 'crossbar', 'memory', \"w'(a\", 's', '=', 'w(a', 's', '+', 'v(s', 'system', 'input', 'situation', 'output', 'action', 'behavior', 'a.', 'separate', 'reinforcement', 'input', 'advice', 'input', 'environment', 'backpropagated', 'value', 'secondary', 'reinforcement', 'emotion', 'consequence', 'situation', 'caa', 'exists', 'environments', 'behavioral', 'environment', 'behaves', 'genetic', 'environment', 'wherefrom', 'initially', 'receives', 'initial', 'emotions', 'situations', 'encountered', 'behavioral', 'environment', 'receiving', 'genome', 'species', 'vector', 'genetic', 'environment', 'caa', 'learns', 'goal', 'seeking', 'behavior', 'environment', 'contains', 'desirable', 'undesirable', 'situations.[62', 'feature', 'learning', 'main', 'article', 'feature', 'learning', 'learning', 'algorithms', 'aim', 'discovering', 'better', 'representations', 'inputs', 'provided', 'training.[63', 'classic', 'examples', 'include', 'principal', 'component', 'analysis', 'cluster', 'analysis', 'feature', 'learning', 'algorithms', 'called', 'representation', 'learning', 'algorithms', 'attempt', 'preserve', 'information', 'input', 'transform', 'way', 'makes', 'useful', 'pre', 'processing', 'step', 'performing', 'classification', 'predictions', 'technique', 'allows', 'reconstruction', 'inputs', 'coming', 'unknown', 'data', 'generating', 'distribution', 'necessarily', 'faithful', 'configurations', 'implausible', 'distribution', 'replaces', 'manual', 'feature', 'engineering', 'allows', 'machine', 'learn', 'features', 'use', 'perform', 'specific', 'task', 'feature', 'learning', 'supervised', 'unsupervised', 'supervised', 'feature', 'learning', 'features', 'learned', 'labeled', 'input', 'data', 'examples', 'include', 'artificial', 'neural', 'networks', 'multilayer', 'perceptrons', 'supervised', 'dictionary', 'learning', 'unsupervised', 'feature', 'learning', 'features', 'learned', 'unlabeled', 'input', 'data', 'examples', 'include', 'dictionary', 'learning', 'independent', 'component', 'analysis', 'autoencoders', 'matrix', 'factorization[64', 'forms', 'clustering.[65][66][67', 'manifold', 'learning', 'algorithms', 'attempt', 'constraint', 'learned', 'representation', 'low', 'dimensional', 'sparse', 'coding', 'algorithms', 'attempt', 'constraint', 'learned', 'representation', 'sparse', 'meaning', 'mathematical', 'model', 'zeros', 'multilinear', 'subspace', 'learning', 'algorithms', 'aim', 'learn', 'low', 'dimensional', 'representations', 'directly', 'tensor', 'representations', 'multidimensional', 'data', 'reshaping', 'higher', 'dimensional', 'vectors.[68', 'deep', 'learning', 'algorithms', 'discover', 'multiple', 'levels', 'representation', 'hierarchy', 'features', 'higher', 'level', 'abstract', 'features', 'defined', 'terms', 'generating', 'lower', 'level', 'features', 'argued', 'intelligent', 'machine', 'learns', 'representation', 'disentangles', 'underlying', 'factors', 'variation', 'explain', 'observed', 'data.[69', 'feature', 'learning', 'motivated', 'fact', 'machine', 'learning', 'tasks', 'classification', 'require', 'input', 'mathematically', 'computationally', 'convenient', 'process', 'real', 'world', 'data', 'images', 'video', 'sensory', 'data', 'yielded', 'attempts', 'algorithmically', 'define', 'specific', 'features', 'alternative', 'discover', 'features', 'representations', 'examination', 'relying', 'explicit', 'algorithms', 'sparse', 'dictionary', 'learning', 'main', 'article', 'sparse', 'dictionary', 'learning', 'sparse', 'dictionary', 'learning', 'feature', 'learning', 'method', 'training', 'example', 'represented', 'linear', 'combination', 'basis', 'functions', 'assumed', 'sparse', 'matrix', 'method', 'strongly', 'np', 'hard', 'difficult', 'solve', 'approximately.[70', 'popular', 'heuristic', 'method', 'sparse', 'dictionary', 'learning', 'k', 'svd', 'algorithm', 'sparse', 'dictionary', 'learning', 'applied', 'contexts', 'classification', 'problem', 'determine', 'class', 'previously', 'unseen', 'training', 'example', 'belongs', 'dictionary', 'class', 'built', 'new', 'training', 'example', 'associated', 'class', 'best', 'sparsely', 'represented', 'corresponding', 'dictionary', 'sparse', 'dictionary', 'learning', 'applied', 'image', 'de', 'noising', 'key', 'idea', 'clean', 'image', 'patch', 'sparsely', 'represented', 'image', 'dictionary', 'noise', 'cannot.[71', 'anomaly', 'detection', 'main', 'article', 'anomaly', 'detection', 'data', 'mining', 'anomaly', 'detection', 'known', 'outlier', 'detection', 'identification', 'rare', 'items', 'events', 'observations', 'raise', 'suspicions', 'differing', 'significantly', 'majority', 'data.[72', 'typically', 'anomalous', 'items', 'represent', 'issue', 'bank', 'fraud', 'structural', 'defect', 'medical', 'problems', 'errors', 'text', 'anomalies', 'referred', 'outliers', 'novelties', 'noise', 'deviations', 'exceptions.[73', 'particular', 'context', 'abuse', 'network', 'intrusion', 'detection', 'interesting', 'objects', 'rare', 'objects', 'unexpected', 'bursts', 'inactivity', 'pattern', 'adhere', 'common', 'statistical', 'definition', 'outlier', 'rare', 'object', 'outlier', 'detection', 'methods', 'particular', 'unsupervised', 'algorithms', 'fail', 'data', 'aggregated', 'appropriately', 'instead', 'cluster', 'analysis', 'algorithm', 'able', 'detect', 'micro', 'clusters', 'formed', 'patterns.[74', 'broad', 'categories', 'anomaly', 'detection', 'techniques', 'exist.[75', 'unsupervised', 'anomaly', 'detection', 'techniques', 'detect', 'anomalies', 'unlabeled', 'test', 'data', 'set', 'assumption', 'majority', 'instances', 'data', 'set', 'normal', 'looking', 'instances', 'fit', 'remainder', 'data', 'set', 'supervised', 'anomaly', 'detection', 'techniques', 'require', 'data', 'set', 'labeled', 'normal', 'abnormal', 'involves', 'training', 'classifier', 'key', 'difference', 'statistical', 'classification', 'problems', 'inherently', 'unbalanced', 'nature', 'outlier', 'detection', 'semi', 'supervised', 'anomaly', 'detection', 'techniques', 'construct', 'model', 'representing', 'normal', 'behavior', 'given', 'normal', 'training', 'data', 'set', 'test', 'likelihood', 'test', 'instance', 'generated', 'model', 'robot', 'learning', 'robot', 'learning', 'inspired', 'multitude', 'machine', 'learning', 'methods', 'starting', 'supervised', 'learning', 'reinforcement', 'learning,[76][77', 'finally', 'meta', 'learning', 'e.g.', 'maml', 'association', 'rules', 'main', 'article', 'association', 'rule', 'learning', 'inductive', 'logic', 'programming', 'association', 'rule', 'learning', 'rule', 'based', 'machine', 'learning', 'method', 'discovering', 'relationships', 'variables', 'large', 'databases', 'intended', 'identify', 'strong', 'rules', 'discovered', 'databases', 'measure', 'interestingness\".[78', 'rule', 'based', 'machine', 'learning', 'general', 'term', 'machine', 'learning', 'method', 'identifies', 'learns', 'evolves', 'rules', 'store', 'manipulate', 'apply', 'knowledge', 'defining', 'characteristic', 'rule', 'based', 'machine', 'learning', 'algorithm', 'identification', 'utilization', 'set', 'relational', 'rules', 'collectively', 'represent', 'knowledge', 'captured', 'system', 'contrast', 'machine', 'learning', 'algorithms', 'commonly', 'identify', 'singular', 'model', 'universally', 'applied', 'instance', 'order', 'prediction.[79', 'rule', 'based', 'machine', 'learning', 'approaches', 'include', 'learning', 'classifier', 'systems', 'association', 'rule', 'learning', 'artificial', 'immune', 'systems', 'based', 'concept', 'strong', 'rules', 'rakesh', 'agrawal', 'tomasz', 'imieliński', 'arun', 'swami', 'introduced', 'association', 'rules', 'discovering', 'regularities', 'products', 'large', 'scale', 'transaction', 'data', 'recorded', 'point', 'sale', 'pos', 'systems', 'supermarkets.[80', 'example', 'rule', 'o', 'n', 'o', 'n', 's', 'p', 'o', 't', 't', 'o', 'e', 's', '⇒', 'b', 'u', 'r', 'g', 'e', 'r', '\\\\displaystyle', '\\\\{\\\\mathrm', 'onions', 'potatoes', '\\\\}\\\\rightarrow', '\\\\{\\\\mathrm', 'burger', 'found', 'sales', 'data', 'supermarket', 'indicate', 'customer', 'buys', 'onions', 'potatoes', 'likely', 'buy', 'hamburger', 'meat', 'information', 'basis', 'decisions', 'marketing', 'activities', 'promotional', 'pricing', 'product', 'placements', 'addition', 'market', 'basket', 'analysis', 'association', 'rules', 'employed', 'today', 'application', 'areas', 'including', 'web', 'usage', 'mining', 'intrusion', 'detection', 'continuous', 'production', 'bioinformatics', 'contrast', 'sequence', 'mining', 'association', 'rule', 'learning', 'typically', 'consider', 'order', 'items', 'transaction', 'transactions', 'learning', 'classifier', 'systems', 'lcs', 'family', 'rule', 'based', 'machine', 'learning', 'algorithms', 'combine', 'discovery', 'component', 'typically', 'genetic', 'algorithm', 'learning', 'component', 'performing', 'supervised', 'learning', 'reinforcement', 'learning', 'unsupervised', 'learning', 'seek', 'identify', 'set', 'context', 'dependent', 'rules', 'collectively', 'store', 'apply', 'knowledge', 'piecewise', 'manner', 'order', 'predictions.[81', 'inductive', 'logic', 'programming', 'ilp', 'approach', 'rule', 'learning', 'logic', 'programming', 'uniform', 'representation', 'input', 'examples', 'background', 'knowledge', 'hypotheses', 'given', 'encoding', 'known', 'background', 'knowledge', 'set', 'examples', 'represented', 'logical', 'database', 'facts', 'ilp', 'system', 'derive', 'hypothesized', 'logic', 'program', 'entails', 'positive', 'negative', 'examples', 'inductive', 'programming', 'related', 'field', 'considers', 'kind', 'programming', 'language', 'representing', 'hypotheses', 'logic', 'programming', 'functional', 'programs', 'inductive', 'logic', 'programming', 'particularly', 'useful', 'bioinformatics', 'natural', 'language', 'processing', 'gordon', 'plotkin', 'ehud', 'shapiro', 'laid', 'initial', 'theoretical', 'foundation', 'inductive', 'machine', 'learning', 'logical', 'setting.[82][83][84', 'shapiro', 'built', 'implementation', 'model', 'inference', 'system', '1981', 'prolog', 'program', 'inductively', 'inferred', 'logic', 'programs', 'positive', 'negative', 'examples.[85', 'term', 'inductive', 'refers', 'philosophical', 'induction', 'suggesting', 'theory', 'explain', 'observed', 'facts', 'mathematical', 'induction', 'proving', 'property', 'members', 'ordered', 'set', 'models', 'machine', 'learning', 'model', 'type', 'mathematical', 'model', 'trained', 'given', 'dataset', 'predictions', 'classifications', 'new', 'data', 'training', 'learning', 'algorithm', 'iteratively', 'adjusts', 'model', 'internal', 'parameters', 'minimize', 'errors', 'predictions.[86', 'extension', 'term', 'model', 'refer', 'levels', 'specificity', 'general', 'class', 'models', 'associated', 'learning', 'algorithms', 'fully', 'trained', 'model', 'internal', 'parameters', 'tuned.[87', 'types', 'models', 'researched', 'machine', 'learning', 'systems', 'picking', 'best', 'model', 'task', 'called', 'model', 'selection', 'artificial', 'neural', 'networks', 'main', 'article', 'artificial', 'neural', 'network', 'deep', 'learning', 'artificial', 'neural', 'network', 'interconnected', 'group', 'nodes', 'akin', 'vast', 'network', 'neurons', 'brain', 'circular', 'node', 'represents', 'artificial', 'neuron', 'arrow', 'represents', 'connection', 'output', 'artificial', 'neuron', 'input', 'artificial', 'neural', 'networks', 'anns', 'connectionist', 'systems', 'computing', 'systems', 'vaguely', 'inspired', 'biological', 'neural', 'networks', 'constitute', 'animal', 'brains', 'systems', 'learn', 'perform', 'tasks', 'considering', 'examples', 'generally', 'programmed', 'task', 'specific', 'rules', 'ann', 'model', 'based', 'collection', 'connected', 'units', 'nodes', 'called', 'artificial', 'neurons', 'loosely', 'model', 'neurons', 'biological', 'brain', 'connection', 'like', 'synapses', 'biological', 'brain', 'transmit', 'information', 'signal', 'artificial', 'neuron', 'artificial', 'neuron', 'receives', 'signal', 'process', 'signal', 'additional', 'artificial', 'neurons', 'connected', 'common', 'ann', 'implementations', 'signal', 'connection', 'artificial', 'neurons', 'real', 'number', 'output', 'artificial', 'neuron', 'computed', 'non', 'linear', 'function', 'sum', 'inputs', 'connections', 'artificial', 'neurons', 'called', 'edges', 'artificial', 'neurons', 'edges', 'typically', 'weight', 'adjusts', 'learning', 'proceeds', 'weight', 'increases', 'decreases', 'strength', 'signal', 'connection', 'artificial', 'neurons', 'threshold', 'signal', 'sent', 'aggregate', 'signal', 'crosses', 'threshold', 'typically', 'artificial', 'neurons', 'aggregated', 'layers', 'different', 'layers', 'perform', 'different', 'kinds', 'transformations', 'inputs', 'signals', 'travel', 'layer', 'input', 'layer', 'layer', 'output', 'layer', 'possibly', 'traversing', 'layers', 'multiple', 'times', 'original', 'goal', 'ann', 'approach', 'solve', 'problems', 'way', 'human', 'brain', 'time', 'attention', 'moved', 'performing', 'specific', 'tasks', 'leading', 'deviations', 'biology', 'artificial', 'neural', 'networks', 'variety', 'tasks', 'including', 'computer', 'vision', 'speech', 'recognition', 'machine', 'translation', 'social', 'network', 'filtering', 'playing', 'board', 'video', 'games', 'medical', 'diagnosis', 'deep', 'learning', 'consists', 'multiple', 'hidden', 'layers', 'artificial', 'neural', 'network', 'approach', 'tries', 'model', 'way', 'human', 'brain', 'processes', 'light', 'sound', 'vision', 'hearing', 'successful', 'applications', 'deep', 'learning', 'computer', 'vision', 'speech', 'recognition.[88', 'decision', 'trees', 'main', 'article', 'decision', 'tree', 'learning', 'decision', 'tree', 'showing', 'survival', 'probability', 'passengers', 'titanic', 'decision', 'tree', 'learning', 'uses', 'decision', 'tree', 'predictive', 'model', 'observations', 'item', 'represented', 'branches', 'conclusions', 'item', 'target', 'value', 'represented', 'leaves', 'predictive', 'modeling', 'approaches', 'statistics', 'data', 'mining', 'machine', 'learning', 'tree', 'models', 'target', 'variable', 'discrete', 'set', 'values', 'called', 'classification', 'trees', 'tree', 'structures', 'leaves', 'represent', 'class', 'labels', 'branches', 'represent', 'conjunctions', 'features', 'lead', 'class', 'labels', 'decision', 'trees', 'target', 'variable', 'continuous', 'values', 'typically', 'real', 'numbers', 'called', 'regression', 'trees', 'decision', 'analysis', 'decision', 'tree', 'visually', 'explicitly', 'represent', 'decisions', 'decision', 'making', 'data', 'mining', 'decision', 'tree', 'describes', 'data', 'resulting', 'classification', 'tree', 'input', 'decision', 'making', 'support', 'vector', 'machines', 'main', 'article', 'support', 'vector', 'machine', 'support', 'vector', 'machines', 'svms', 'known', 'support', 'vector', 'networks', 'set', 'related', 'supervised', 'learning', 'methods', 'classification', 'regression', 'given', 'set', 'training', 'examples', 'marked', 'belonging', 'categories', 'svm', 'training', 'algorithm', 'builds', 'model', 'predicts', 'new', 'example', 'falls', 'category.[89', 'svm', 'training', 'algorithm', 'non', 'probabilistic', 'binary', 'linear', 'classifier', 'methods', 'platt', 'scaling', 'exist', 'use', 'svm', 'probabilistic', 'classification', 'setting', 'addition', 'performing', 'linear', 'classification', 'svms', 'efficiently', 'perform', 'non', 'linear', 'classification', 'called', 'kernel', 'trick', 'implicitly', 'mapping', 'inputs', 'high', 'dimensional', 'feature', 'spaces', 'regression', 'analysis', 'main', 'article', 'regression', 'analysis', 'illustration', 'linear', 'regression', 'data', 'set', 'regression', 'analysis', 'encompasses', 'large', 'variety', 'statistical', 'methods', 'estimate', 'relationship', 'input', 'variables', 'associated', 'features', 'common', 'form', 'linear', 'regression', 'single', 'line', 'drawn', 'best', 'fit', 'given', 'data', 'according', 'mathematical', 'criterion', 'ordinary', 'squares', 'extended', 'regularization', 'methods', 'mitigate', 'overfitting', 'bias', 'ridge', 'regression', 'dealing', 'non', 'linear', 'problems', 'models', 'include', 'polynomial', 'regression', 'example', 'trendline', 'fitting', 'microsoft', 'excel[90', 'logistic', 'regression', 'statistical', 'classification', 'kernel', 'regression', 'introduces', 'non', 'linearity', 'taking', 'advantage', 'kernel', 'trick', 'implicitly', 'map', 'input', 'variables', 'higher', 'dimensional', 'space', 'bayesian', 'networks', 'main', 'article', 'bayesian', 'network', 'simple', 'bayesian', 'network', 'rain', 'influences', 'sprinkler', 'activated', 'rain', 'sprinkler', 'influence', 'grass', 'wet', 'bayesian', 'network', 'belief', 'network', 'directed', 'acyclic', 'graphical', 'model', 'probabilistic', 'graphical', 'model', 'represents', 'set', 'random', 'variables', 'conditional', 'independence', 'directed', 'acyclic', 'graph', 'dag', 'example', 'bayesian', 'network', 'represent', 'probabilistic', 'relationships', 'diseases', 'symptoms', 'given', 'symptoms', 'network', 'compute', 'probabilities', 'presence', 'diseases', 'efficient', 'algorithms', 'exist', 'perform', 'inference', 'learning', 'bayesian', 'networks', 'model', 'sequences', 'variables', 'like', 'speech', 'signals', 'protein', 'sequences', 'called', 'dynamic', 'bayesian', 'networks', 'generalizations', 'bayesian', 'networks', 'represent', 'solve', 'decision', 'problems', 'uncertainty', 'called', 'influence', 'diagrams', 'gaussian', 'processes', 'main', 'article', 'gaussian', 'processes', 'example', 'gaussian', 'process', 'regression', 'prediction', 'compared', 'regression', 'models[91', 'gaussian', 'process', 'stochastic', 'process', 'finite', 'collection', 'random', 'variables', 'process', 'multivariate', 'normal', 'distribution', 'relies', 'pre', 'defined', 'covariance', 'function', 'kernel', 'models', 'pairs', 'points', 'relate', 'depending', 'locations', 'given', 'set', 'observed', 'points', 'input', 'output', 'examples', 'distribution', 'unobserved', 'output', 'new', 'point', 'function', 'input', 'data', 'directly', 'computed', 'looking', 'like', 'observed', 'points', 'covariances', 'points', 'new', 'unobserved', 'point', 'gaussian', 'processes', 'popular', 'surrogate', 'models', 'bayesian', 'optimization', 'hyperparameter', 'optimization', 'genetic', 'algorithms', 'main', 'article', 'genetic', 'algorithm', 'genetic', 'algorithm', 'ga', 'search', 'algorithm', 'heuristic', 'technique', 'mimics', 'process', 'natural', 'selection', 'methods', 'mutation', 'crossover', 'generate', 'new', 'genotypes', 'hope', 'finding', 'good', 'solutions', 'given', 'problem', 'machine', 'learning', 'genetic', 'algorithms', '1980s', '1990s.[92][93', 'conversely', 'machine', 'learning', 'techniques', 'improve', 'performance', 'genetic', 'evolutionary', 'algorithms.[94', 'belief', 'functions', 'main', 'article', 'dempster', 'shafer', 'theory', 'theory', 'belief', 'functions', 'referred', 'evidence', 'theory', 'dempster', 'shafer', 'theory', 'general', 'framework', 'reasoning', 'uncertainty', 'understood', 'connections', 'frameworks', 'probability', 'possibility', 'imprecise', 'probability', 'theories', 'theoretical', 'frameworks', 'thought', 'kind', 'learner', 'analogous', 'properties', 'evidence', 'combined', 'e.g.', 'dempster', 'rule', 'combination', 'like', 'pmf', 'based', 'bayesian', 'approach[clarification', 'needed', 'combine', 'probabilities', 'caveats', 'beliefs', 'functions', 'compared', 'bayesian', 'approaches', 'order', 'incorporate', 'ignorance', 'uncertainty', 'quantification', 'belief', 'function', 'approaches', 'implemented', 'machine', 'learning', 'domain', 'typically', 'leverage', 'fusion', 'approach', 'ensemble', 'methods', 'better', 'handle', 'learner', 'decision', 'boundary', 'low', 'samples', 'ambiguous', 'class', 'issues', 'standard', 'machine', 'learning', 'approach', 'tend', 'difficulty', 'resolving.[4][9', 'computational', 'complexity', 'algorithms', 'dependent', 'number', 'propositions', 'classes', 'lead', 'higher', 'computation', 'time', 'compared', 'machine', 'learning', 'approaches', 'training', 'models', 'typically', 'machine', 'learning', 'models', 'require', 'high', 'quantity', 'reliable', 'data', 'perform', 'accurate', 'predictions', 'training', 'machine', 'learning', 'model', 'machine', 'learning', 'engineers', 'need', 'target', 'collect', 'large', 'representative', 'sample', 'data', 'data', 'training', 'set', 'varied', 'corpus', 'text', 'collection', 'images', 'sensor', 'data', 'data', 'collected', 'individual', 'users', 'service', 'overfitting', 'watch', 'training', 'machine', 'learning', 'model', 'trained', 'models', 'derived', 'biased', 'non', 'evaluated', 'data', 'result', 'skewed', 'undesired', 'predictions', 'biased', 'models', 'result', 'detrimental', 'outcomes', 'furthering', 'negative', 'impacts', 'society', 'objectives', 'algorithmic', 'bias', 'potential', 'result', 'data', 'fully', 'prepared', 'training', 'machine', 'learning', 'ethics', 'field', 'study', 'notably', 'integrated', 'machine', 'learning', 'engineering', 'teams', 'federated', 'learning', 'main', 'article', 'federated', 'learning', 'federated', 'learning', 'adapted', 'form', 'distributed', 'artificial', 'intelligence', 'training', 'machine', 'learning', 'models', 'decentralizes', 'training', 'process', 'allowing', 'users', 'privacy', 'maintained', 'needing', 'send', 'data', 'centralized', 'server', 'increases', 'efficiency', 'decentralizing', 'training', 'process', 'devices', 'example', 'gboard', 'uses', 'federated', 'machine', 'learning', 'train', 'search', 'query', 'prediction', 'models', 'users', 'mobile', 'phones', 'having', 'send', 'individual', 'searches', 'google.[95', 'applications', 'applications', 'machine', 'learning', 'including', 'agriculture', 'anatomy', 'adaptive', 'website', 'affective', 'computing', 'astronomy', 'automated', 'decision', 'making', 'banking', 'behaviorism', 'bioinformatics', 'brain', 'machine', 'interfaces', 'cheminformatics', 'citizen', 'science', 'climate', 'science', 'computer', 'networks', 'computer', 'vision', 'credit', 'card', 'fraud', 'detection', 'data', 'quality', 'dna', 'sequence', 'classification', 'economics', 'financial', 'market', 'analysis[96', 'general', 'game', 'playing', 'handwriting', 'recognition', 'healthcare', 'information', 'retrieval', 'insurance', 'internet', 'fraud', 'detection', 'knowledge', 'graph', 'embedding', 'linguistics', 'machine', 'learning', 'control', 'machine', 'perception', 'machine', 'translation', 'marketing', 'medical', 'diagnosis', 'natural', 'language', 'processing', 'natural', 'language', 'understanding', 'online', 'advertising', 'optimization', 'recommender', 'systems', 'robot', 'locomotion', 'search', 'engines', 'sentiment', 'analysis', 'sequence', 'mining', 'software', 'engineering', 'speech', 'recognition', 'structural', 'health', 'monitoring', 'syntactic', 'pattern', 'recognition', 'telecommunication', 'theorem', 'proving', 'time', 'series', 'forecasting', 'tomographic', 'reconstruction[97', 'user', 'behavior', 'analytics', '2006', 'media', 'services', 'provider', 'netflix', 'held', 'netflix', 'prize', 'competition', 'find', 'program', 'better', 'predict', 'user', 'preferences', 'improve', 'accuracy', 'existing', 'cinematch', 'movie', 'recommendation', 'algorithm', '10', 'joint', 'team', 'researchers', 'at&t', 'labs', 'research', 'collaboration', 'teams', 'big', 'chaos', 'pragmatic', 'theory', 'built', 'ensemble', 'model', 'win', 'grand', 'prize', '2009', '$', '1', 'million.[98', 'shortly', 'prize', 'awarded', 'netflix', 'realized', 'viewers', 'ratings', 'best', 'indicators', 'viewing', 'patterns', 'recommendation', 'changed', 'recommendation', 'engine', 'accordingly.[99', '2010', 'wall', 'street', 'journal', 'wrote', 'firm', 'rebellion', 'research', 'use', 'machine', 'learning', 'predict', 'financial', 'crisis.[100', '2012', 'co', 'founder', 'sun', 'microsystems', 'vinod', 'khosla', 'predicted', '80', 'medical', 'doctors', 'jobs', 'lost', 'decades', 'automated', 'machine', 'learning', 'medical', 'diagnostic', 'software.[101', '2014', 'reported', 'machine', 'learning', 'algorithm', 'applied', 'field', 'art', 'history', 'study', 'fine', 'art', 'paintings', 'revealed', 'previously', 'unrecognized', 'influences', 'artists.[102', '2019', 'springer', 'nature', 'published', 'research', 'book', 'created', 'machine', 'learning.[103', '2020', 'machine', 'learning', 'technology', 'help', 'diagnoses', 'aid', 'researchers', 'developing', 'cure', 'covid-19.[104', 'machine', 'learning', 'recently', 'applied', 'predict', 'pro', 'environmental', 'behavior', 'travelers.[105', 'recently', 'machine', 'learning', 'technology', 'applied', 'optimize', 'smartphone', 'performance', 'thermal', 'behavior', 'based', 'user', 'interaction', 'phone.[106][107][108', 'applied', 'correctly', 'machine', 'learning', 'algorithms', 'mlas', 'utilize', 'wide', 'range', 'company', 'characteristics', 'predict', 'stock', 'returns', 'overfitting', 'employing', 'effective', 'feature', 'engineering', 'combining', 'forecasts', 'mlas', 'generate', 'results', 'far', 'surpass', 'obtained', 'basic', 'linear', 'techniques', 'like', 'ols.[109', 'recent', 'advancements', 'machine', 'learning', 'extended', 'field', 'quantum', 'chemistry', 'novel', 'algorithms', 'enable', 'prediction', 'solvent', 'effects', 'chemical', 'reactions', 'offering', 'new', 'tools', 'chemists', 'tailor', 'experimental', 'conditions', 'optimal', 'outcomes.[110', 'machine', 'learning', 'useful', 'tool', 'investigate', 'predict', 'evacuation', 'decision', 'making', 'large', 'scale', 'small', 'scale', 'disasters', 'different', 'solutions', 'tested', 'predict', 'householders', 'decide', 'evacuate', 'wildfires', 'hurricanes.[111][112][113', 'applications', 'focusing', 'pre', 'evacuation', 'decisions', 'building', 'fires.[114][115', 'limitations', 'machine', 'learning', 'transformative', 'fields', 'machine', 'learning', 'programs', 'fail', 'deliver', 'expected', 'results.[116][117][118', 'reasons', 'numerous', 'lack', 'suitable', 'data', 'lack', 'access', 'data', 'data', 'bias', 'privacy', 'problems', 'badly', 'chosen', 'tasks', 'algorithms', 'wrong', 'tools', 'people', 'lack', 'resources', 'evaluation', 'problems.[119', 'black', 'box', 'theory', 'poses', 'significant', 'challenge', 'black', 'box', 'refers', 'situation', 'algorithm', 'process', 'producing', 'output', 'entirely', 'opaque', 'meaning', 'coders', 'algorithm', 'audit', 'pattern', 'machine', 'extracted', 'data.[120', 'house', 'lords', 'select', 'committee', 'claimed', 'intelligence', 'system', 'substantial', 'impact', 'individual', 'life', 'considered', 'acceptable', 'provided', 'satisfactory', 'explanation', 'decisions', 'makes.[120', '2018', 'self', 'driving', 'car', 'uber', 'failed', 'detect', 'pedestrian', 'killed', 'collision.[121', 'attempts', 'use', 'machine', 'learning', 'healthcare', 'ibm', 'watson', 'system', 'failed', 'deliver', 'years', 'time', 'billions', 'dollars', 'invested.[122][123', 'microsoft', 'bing', 'chat', 'chatbot', 'reported', 'produce', 'hostile', 'offensive', 'response', 'users.[124', 'machine', 'learning', 'strategy', 'update', 'evidence', 'related', 'systematic', 'review', 'increased', 'reviewer', 'burden', 'related', 'growth', 'biomedical', 'literature', 'improved', 'training', 'sets', 'developed', 'sufficiently', 'reduce', 'workload', 'burden', 'limiting', 'necessary', 'sensitivity', 'findings', 'research', 'themselves.[125', 'bias', 'main', 'article', 'algorithmic', 'bias', 'different', 'machine', 'learning', 'approaches', 'suffer', 'different', 'data', 'biases', 'machine', 'learning', 'system', 'trained', 'specifically', 'current', 'customers', 'able', 'predict', 'needs', 'new', 'customer', 'groups', 'represented', 'training', 'data', 'trained', 'human', 'data', 'machine', 'learning', 'likely', 'pick', 'constitutional', 'unconscious', 'biases', 'present', 'society.[126', 'language', 'models', 'learned', 'data', 'shown', 'contain', 'human', 'like', 'biases.[127][128', 'experiment', 'carried', 'propublica', 'investigative', 'journalism', 'organization', 'machine', 'learning', 'algorithm', 'insight', 'recidivism', 'rates', 'prisoners', 'falsely', 'flagged', 'black', 'defendants', 'high', 'risk', 'twice', 'white', 'defendants', '\"[129', '2015', 'google', 'photos', 'tag', 'black', 'people', 'gorillas,[129', '2018', 'resolved', 'google', 'reportedly', 'workaround', 'remove', 'gorillas', 'training', 'data', 'able', 'recognize', 'real', 'gorillas', 'all.[130', 'similar', 'issues', 'recognizing', 'non', 'white', 'people', 'found', 'systems.[131', '2016', 'microsoft', 'tested', 'tay', 'chatbot', 'learned', 'twitter', 'quickly', 'picked', 'racist', 'sexist', 'language.[132', 'challenges', 'effective', 'use', 'machine', 'learning', 'longer', 'adopted', 'domains.[133', 'concern', 'fairness', 'machine', 'learning', 'reducing', 'bias', 'machine', 'learning', 'propelling', 'use', 'human', 'good', 'increasingly', 'expressed', 'artificial', 'intelligence', 'scientists', 'including', 'fei', 'fei', 'li', 'reminds', 'engineers', 't]here', 'artificial', 'ai', 'inspired', 'people', 'created', 'people', 'importantly', 'impacts', 'people', 'powerful', 'tool', 'beginning', 'understand', 'profound', 'responsibility', '\"[134', 'explainability', 'main', 'article', 'explainable', 'artificial', 'intelligence', 'explainable', 'ai', 'xai', 'interpretable', 'ai', 'explainable', 'machine', 'learning', 'xml', 'artificial', 'intelligence', 'ai', 'humans', 'understand', 'decisions', 'predictions', 'ai.[135', 'contrasts', 'black', 'box', 'concept', 'machine', 'learning', 'designers', 'explain', 'ai', 'arrived', 'specific', 'decision.[136', 'refining', 'mental', 'models', 'users', 'ai', 'powered', 'systems', 'dismantling', 'misconceptions', 'xai', 'promises', 'help', 'users', 'perform', 'effectively', 'xai', 'implementation', 'social', 'right', 'explanation', 'overfitting', 'main', 'article', 'overfitting', 'blue', 'line', 'example', 'overfitting', 'linear', 'function', 'random', 'noise', 'settling', 'bad', 'overly', 'complex', 'theory', 'gerrymandered', 'fit', 'past', 'training', 'data', 'known', 'overfitting', 'systems', 'attempt', 'reduce', 'overfitting', 'rewarding', 'theory', 'accordance', 'fits', 'data', 'penalizing', 'theory', 'accordance', 'complex', 'theory', 'is.[137', 'limitations', 'vulnerabilities', 'learners', 'disappoint', 'learning', 'wrong', 'lesson', 'toy', 'example', 'image', 'classifier', 'trained', 'pictures', 'brown', 'horses', 'black', 'cats', 'conclude', 'brown', 'patches', 'likely', 'horses.[138', 'real', 'world', 'example', 'unlike', 'humans', 'current', 'image', 'classifiers', 'primarily', 'judgments', 'spatial', 'relationship', 'components', 'picture', 'learn', 'relationships', 'pixels', 'humans', 'oblivious', 'correlate', 'images', 'certain', 'types', 'real', 'objects', 'modifying', 'patterns', 'legitimate', 'image', 'result', 'adversarial', 'images', 'system', 'misclassifies.[139][140', 'adversarial', 'vulnerabilities', 'result', 'nonlinear', 'systems', 'non', 'pattern', 'perturbations', 'systems', 'possible', 'change', 'output', 'changing', 'single', 'adversarially', 'chosen', 'pixel.[141', 'machine', 'learning', 'models', 'vulnerable', 'manipulation', 'and/or', 'evasion', 'adversarial', 'machine', 'learning.[142', 'researchers', 'demonstrated', 'backdoors', 'placed', 'undetectably', 'classifying', 'e.g.', 'categories', 'spam', 'visible', 'spam', 'posts', 'machine', 'learning', 'models', 'developed', 'and/or', 'trained', 'parties', 'parties', 'change', 'classification', 'input', 'including', 'cases', 'type', 'data', 'software', 'transparency', 'provided', 'possibly', 'including', 'white', 'box', 'access.[143][144][145', 'model', 'assessments', 'classification', 'machine', 'learning', 'models', 'validated', 'accuracy', 'estimation', 'techniques', 'like', 'holdout', 'method', 'splits', 'data', 'training', 'test', 'set', 'conventionally', '2/3', 'training', 'set', '1/3', 'test', 'set', 'designation', 'evaluates', 'performance', 'training', 'model', 'test', 'set', 'comparison', 'k', 'fold', 'cross', 'validation', 'method', 'randomly', 'partitions', 'data', 'k', 'subsets', 'k', 'experiments', 'performed', 'respectively', 'considering', '1', 'subset', 'evaluation', 'remaining', 'k-1', 'subsets', 'training', 'model', 'addition', 'holdout', 'cross', 'validation', 'methods', 'bootstrap', 'samples', 'n', 'instances', 'replacement', 'dataset', 'assess', 'model', 'accuracy.[146', 'addition', 'overall', 'accuracy', 'investigators', 'frequently', 'report', 'sensitivity', 'specificity', 'meaning', 'true', 'positive', 'rate', 'tpr', 'true', 'negative', 'rate', 'tnr', 'respectively', 'similarly', 'investigators', 'report', 'false', 'positive', 'rate', 'fpr', 'false', 'negative', 'rate', 'fnr', 'rates', 'ratios', 'fail', 'reveal', 'numerators', 'denominators', 'total', 'operating', 'characteristic', 'toc', 'effective', 'method', 'express', 'model', 'diagnostic', 'ability', 'toc', 'shows', 'numerators', 'denominators', 'previously', 'mentioned', 'rates', 'toc', 'provides', 'information', 'commonly', 'receiver', 'operating', 'characteristic', 'roc', 'roc', 'associated', 'area', 'curve', 'auc).[147', 'ethics', 'ai', 'control', 'problem', 'toronto', 'declaration', 'ethics', 'artificial', 'intelligence', 'machine', 'learning', 'poses', 'host', 'ethical', 'questions', 'systems', 'trained', 'datasets', 'collected', 'biases', 'exhibit', 'biases', 'use', 'algorithmic', 'bias', 'digitizing', 'cultural', 'prejudices.[148', 'example', '1988', 'uk', 'commission', 'racial', 'equality', 'found', 'st.', 'george', 'medical', 'school', 'computer', 'program', 'trained', 'data', 'previous', 'admissions', 'staff', 'program', 'denied', 'nearly', '60', 'candidates', 'found', 'women', 'non', 'european', 'sounding', 'names.[126', 'job', 'hiring', 'data', 'firm', 'racist', 'hiring', 'policies', 'lead', 'machine', 'learning', 'system', 'duplicating', 'bias', 'scoring', 'job', 'applicants', 'similarity', 'previous', 'successful', 'applicants.[149][150', 'example', 'includes', 'predictive', 'policing', 'company', 'geolitica', 'predictive', 'algorithm', 'resulted', 'disproportionately', 'high', 'levels', 'policing', 'low', 'income', 'minority', 'communities', 'trained', 'historical', 'crime', 'data.[129', 'responsible', 'collection', 'data', 'documentation', 'algorithmic', 'rules', 'system', 'considered', 'critical', 'machine', 'learning', 'researchers', 'blame', 'lack', 'participation', 'representation', 'minority', 'population', 'field', 'ai', 'machine', 'learning', 'vulnerability', 'biases.[151', 'fact', 'according', 'research', 'carried', 'computing', 'research', 'association', 'cra', '2021', 'female', 'faculty', 'merely', '16.1', 'faculty', 'members', 'focus', 'ai', 'universities', 'world.[152', 'furthermore', 'group', 'new', 'u.s.', 'resident', 'ai', 'phd', 'graduates', '45', 'identified', 'white', '22.4', 'asian', '3.2', 'hispanic', '2.4', 'african', 'american', 'demonstrates', 'lack', 'diversity', 'field', 'ai.[152', 'ai', 'equipped', 'decisions', 'technical', 'fields', 'rely', 'heavily', 'data', 'historical', 'information', 'decisions', 'rely', 'objectivity', 'logical', 'reasoning.[153', 'human', 'languages', 'contain', 'biases', 'machines', 'trained', 'language', 'corpora', 'necessarily', 'learn', 'biases.[154][155', 'forms', 'ethical', 'challenges', 'related', 'personal', 'biases', 'seen', 'health', 'care', 'concerns', 'health', 'care', 'professionals', 'systems', 'designed', 'public', 'interest', 'income', 'generating', 'machines.[156', 'especially', 'true', 'united', 'states', 'long', 'standing', 'ethical', 'dilemma', 'improving', 'health', 'care', 'increasing', 'profits', 'example', 'algorithms', 'designed', 'provide', 'patients', 'unnecessary', 'tests', 'medication', 'algorithm', 'proprietary', 'owners', 'hold', 'stakes', 'potential', 'machine', 'learning', 'health', 'care', 'provide', 'professionals', 'additional', 'tool', 'diagnose', 'medicate', 'plan', 'recovery', 'paths', 'patients', 'requires', 'biases', 'mitigated.[157', 'hardware', '2010s', 'advances', 'machine', 'learning', 'algorithms', 'computer', 'hardware', 'led', 'efficient', 'methods', 'training', 'deep', 'neural', 'networks', 'particular', 'narrow', 'subdomain', 'machine', 'learning', 'contain', 'layers', 'nonlinear', 'hidden', 'units.[158', '2019', 'graphic', 'processing', 'units', 'gpus', 'ai', 'specific', 'enhancements', 'displaced', 'cpus', 'dominant', 'method', 'training', 'large', 'scale', 'commercial', 'cloud', 'ai.[159', 'openai', 'estimated', 'hardware', 'computing', 'largest', 'deep', 'learning', 'projects', 'alexnet', '2012', 'alphazero', '2017', 'found', '300,000', 'fold', 'increase', 'compute', 'required', 'doubling', 'time', 'trendline', '3.4', 'months.[160][161', 'neuromorphic', 'physical', 'neural', 'networks', 'physical', 'neural', 'network', 'neuromorphic', 'computer', 'type', 'artificial', 'neural', 'network', 'electrically', 'adjustable', 'material', 'emulate', 'function', 'neural', 'synapse', 'physical', 'neural', 'network', 'emphasize', 'reliance', 'physical', 'hardware', 'emulate', 'neurons', 'opposed', 'software', 'based', 'approaches', 'generally', 'term', 'applicable', 'artificial', 'neural', 'networks', 'memristor', 'electrically', 'adjustable', 'resistance', 'material', 'emulate', 'neural', 'synapse.[162][163', 'embedded', 'machine', 'learning', 'embedded', 'machine', 'learning', 'sub', 'field', 'machine', 'learning', 'machine', 'learning', 'model', 'run', 'embedded', 'systems', 'limited', 'computing', 'resources', 'wearable', 'computers', 'edge', 'devices', 'microcontrollers.[164][165][166', 'running', 'machine', 'learning', 'model', 'embedded', 'devices', 'removes', 'need', 'transferring', 'storing', 'data', 'cloud', 'servers', 'processing', 'henceforth', 'reducing', 'data', 'breaches', 'privacy', 'leaks', 'happening', 'transferring', 'data', 'minimizes', 'theft', 'intellectual', 'properties', 'personal', 'data', 'business', 'secrets', 'embedded', 'machine', 'learning', 'applied', 'techniques', 'including', 'hardware', 'acceleration,[167][168', 'approximate', 'computing,[169', 'optimization', 'machine', 'learning', 'models', 'more.[170][171', 'pruning', 'quantization', 'knowledge', 'distillation', 'low', 'rank', 'factorization', 'network', 'architecture', 'search', 'nas', 'parameter', 'sharing', 'techniques', 'optimization', 'machine', 'learning', 'models', 'software', 'software', 'suites', 'containing', 'variety', 'machine', 'learning', 'algorithms', 'include', 'following', 'free', 'open', 'source', 'software', 'caffe', 'deeplearning4j', 'deepspeed', 'elki', 'google', 'jax', 'infer', 'net', 'keras', 'kubeflow', 'lightgbm', 'mahout', 'mallet', 'microsoft', 'cognitive', 'toolkit', 'ml.net', 'mlpack', 'mxnet', 'opennn', 'orange', 'pandas', 'software', 'root', 'tmva', 'root', 'scikit', 'learn', 'shogun', 'spark', 'mllib', 'systemml', 'tensorflow', 'torch', 'pytorch', 'weka', 'moa', 'xgboost', 'yooreeka', 'proprietary', 'software', 'free', 'open', 'source', 'editions', 'knime', 'rapidminer', 'proprietary', 'software', 'amazon', 'machine', 'learning', 'angoss', 'knowledgestudio', 'azure', 'machine', 'learning', 'ibm', 'watson', 'studio', 'google', 'cloud', 'vertex', 'ai', 'google', 'prediction', 'api', 'ibm', 'spss', 'modeler', 'kxen', 'modeler', 'lionsolver', 'mathematica', 'matlab', 'neural', 'designer', 'neurosolutions', 'oracle', 'data', 'mining', 'oracle', 'ai', 'platform', 'cloud', 'service', 'polyanalyst', 'rcase', 'sas', 'enterprise', 'miner', 'sequencel', 'splunk', 'statistica', 'data', 'miner', 'journals', 'journal', 'machine', 'learning', 'research', 'machine', 'learning', 'nature', 'machine', 'intelligence', 'neural', 'computation', 'ieee', 'transactions', 'pattern', 'analysis', 'machine', 'intelligence', 'conferences', 'aaai', 'conference', 'artificial', 'intelligence', 'association', 'computational', 'linguistics', 'acl', 'european', 'conference', 'machine', 'learning', 'principles', 'practice', 'knowledge', 'discovery', 'databases', 'ecml', 'pkdd', 'international', 'conference', 'computational', 'intelligence', 'methods', 'bioinformatics', 'biostatistics', 'cibb', 'international', 'conference', 'machine', 'learning', 'icml', 'international', 'conference', 'learning', 'representations', 'iclr', 'international', 'conference', 'intelligent', 'robots', 'systems', 'iros', 'conference', 'knowledge', 'discovery', 'data', 'mining', 'kdd', 'conference', 'neural', 'information', 'processing', 'systems', 'neurips', 'automated', 'machine', 'learning', 'process', 'automating', 'application', 'machine', 'learning', 'big', 'data', 'extremely', 'large', 'complex', 'datasets', 'differentiable', 'programming', 'programming', 'paradigm', 'force', 'control', 'list', 'important', 'publications', 'machine', 'learning', 'list', 'datasets', 'machine', 'learning', 'research', 'references', 'definition', 'explicitly', 'programmed', 'attributed', 'arthur', 'samuel', 'coined', 'term', 'machine', 'learning', '1959', 'phrase', 'found', 'verbatim', 'publication', 'paraphrase', 'appeared', 'later', 'confer', 'paraphrasing', 'arthur', 'samuel', '1959', 'question', 'computers', 'learn', 'solve', 'problems', 'explicitly', 'programmed', 'koza', 'john', 'r.', 'bennett', 'forrest', 'h.', 'andre', 'david', 'keane', 'martin', 'a.', '1996', 'automated', 'design', 'topology', 'sizing', 'analog', 'electrical', 'circuits', 'genetic', 'programming', 'artificial', 'intelligence', 'design', '96', 'artificial', 'intelligence', 'design', '96', 'springer', 'dordrecht', 'pp', '151–170', 'doi:10.1007/978', '94', '009', '0279', '4_9', 'isbn', '978', '94', '010', '6610', '5', 'machine', 'learning', 'ibm', '22', 'september', '2021', 'archived', 'original', '2023', '12', '27', 'retrieved', '2023', '06', '27', 'hu', 'junyan', 'niu', 'hanlin', 'carrasco', 'joaquin', 'lennox', 'barry', 'arvin', 'farshad', '2020', 'voronoi', 'based', 'multi', 'robot', 'autonomous', 'exploration', 'unknown', 'environments', 'deep', 'reinforcement', 'learning', 'ieee', 'transactions', 'vehicular', 'technology', '69', '12', '14413–14423', 'doi:10.1109', 'tvt.2020.3034800', 'issn', '0018', '9545', 's2cid', '228989788', 'yoosefzadeh', 'najafabadi', 'mohsen', 'hugh', 'earl', 'tulpan', 'dan', 'sulik', 'john', 'eskandari', 'milad', '2021', 'application', 'machine', 'learning', 'algorithms', 'plant', 'breeding', 'predicting', 'yield', 'hyperspectral', 'reflectance', 'soybean', 'plant', 'sci', '11', '624273', 'doi:10.3389', 'fpls.2020.624273', 'pmc', '7835636', 'pmid', '33510761', 'bishop', 'c.', 'm.', '2006', 'pattern', 'recognition', 'machine', 'learning', 'springer', 'isbn', '978', '0', '387', '31073', '2', 'machine', 'learning', 'pattern', 'recognition', 'viewed', 'facets', 'field\".[5', 'vii', 'friedman', 'jerome', 'h.', '1998', 'data', 'mining', 'statistics', 'connection', 'computing', 'science', 'statistics', '29', '1', '3–9', 'samuel', 'arthur', '1959', 'studies', 'machine', 'learning', 'game', 'checkers', 'ibm', 'journal', 'research', 'development', '3', '3', '210–229', 'citeseerx', '10.1.1.368.2254', 'doi:10.1147', 'rd.33.0210', 's2cid', '2126705', 'r.', 'kohavi', 'f.', 'provost', 'glossary', 'terms', 'machine', 'learning', 'vol', '30', '2–3', 'pp', '271–274', '1998', 'gerovitch', 'slava', '9', 'april', '2015', 'computer', 'got', 'revenge', 'soviet', 'union', 'nautilus', 'archived', 'original', '22', 'september', '2021', 'retrieved', '19', 'september', '2021', 'lindsay', 'richard', 'p.', '1', 'september', '1964', 'impact', 'automation', 'public', 'administration', 'western', 'political', 'quarterly', '17', '3', '78–81', 'doi:10.1177/106591296401700364', 'issn', '0043', '4078', 's2cid', '154021253', 'archived', 'original', '6', 'october', '2021', 'retrieved', '6', 'october', '2021', 'history', 'evolution', 'machine', 'learning', 'timeline', 'whatis', 'archived', 'original', '2023', '12', '08', 'retrieved', '2023', '12', '08', 'milner', 'peter', 'm.', '1993', 'mind', 'donald', 'o.', 'hebb', 'scientific', 'american', '268', '1', '124–129', 'bibcode:1993sciam.268a.124m.', 'doi:10.1038', 'scientificamerican0193', '124', 'issn', '0036', '8733', 'jstor', '24941344', 'pmid', '8418480', 'archived', 'original', '2023', '12', '20', 'retrieved', '2023', '12', '09', 'science', 'goof', 'button', 'time', 'magazine', '18', 'august', '1961', 'nilsson', 'n.', 'learning', 'machines', 'mcgraw', 'hill', '1965', 'duda', 'r.', 'hart', 'p.', 'pattern', 'recognition', 'scene', 'analysis', 'wiley', 'interscience', '1973', 's.', 'bozinovski', 'teaching', 'space', 'representation', 'concept', 'adaptive', 'pattern', 'classification', 'coins', 'technical', 'report', '81', '28', 'computer', 'information', 'science', 'department', 'university', 'massachusetts', 'amherst', 'ma', '1981', 'https://web.cs.umass.edu/publication/docs/1981/um-cs-1981-028.pdf', 'archived', '2021', '02', '25', 'wayback', 'machine', 'mitchell', 't.', '1997', 'machine', 'learning', 'mcgraw', 'hill', 'p.', '2', 'isbn', '978', '0', '07', '042807', '2', 'harnad', 'stevan', '2008', 'annotation', 'game', 'turing', '1950', 'computing', 'machinery', 'intelligence', 'epstein', 'robert', 'peters', 'grace', 'eds', 'turing', 'test', 'sourcebook', 'philosophical', 'methodological', 'issues', 'quest', 'thinking', 'computer', 'kluwer', 'pp', '23–66', 'isbn', '9781402067082', 'archived', 'original', '2012', '03', '09', 'retrieved', '2012', '12', '11', 'introduction', 'ai', '1', 'edzion', '2020', '12', '08', 'archived', 'original', '2021', '02', '18', 'retrieved', '2020', '12', '09', 'sindhu', 'v', 'nivedha', 's', 'prakash', 'm', 'february', '2020', 'empirical', 'science', 'research', 'bioinformatics', 'machine', 'learning', 'journal', 'mechanics', 'continua', 'mathematical', 'sciences', '7', 'doi:10.26782', 'jmcms.spl.7/2020.02.00006', 'sarle', 'warren', 's.', '1994', 'neural', 'networks', 'statistical', 'models', 'sugi', '19', 'proceedings', 'nineteenth', 'annual', 'sas', 'users', 'group', 'international', 'conference', 'sas', 'institute', 'pp', '1538–50', 'isbn', '9781555446116', 'oclc', '35546178', 'russell', 'stuart', 'norvig', 'peter', '2003', '1995', 'artificial', 'intelligence', 'modern', 'approach', '2nd', 'ed', 'prentice', 'hall', 'isbn', '978', '0137903955', 'langley', 'pat', '2011', 'changing', 'science', 'machine', 'learning', 'machine', 'learning', '82', '3', '275–9', 'doi:10.1007', 's10994', '011', '5242', 'y.', 'mahoney', 'matt', 'rationale', 'large', 'text', 'compression', 'benchmark', 'florida', 'institute', 'technology', 'retrieved', '5', 'march', '2013', 'shmilovici', 'a.', 'kahiri', 'y.', 'ben', 'gal', 'i.', 'hauser', 's.', '2009', 'measuring', 'efficiency', 'intraday', 'forex', 'market', 'universal', 'data', 'compression', 'algorithm', 'pdf', 'computational', 'economics', '33', '2', '131–154', 'citeseerx', '10.1.1.627.3751', 'doi:10.1007', 's10614', '008', '9153', '3', 's2cid', '17234503', 'archived', 'pdf', 'original', '2009', '07', '09', 'i.', 'ben', 'gal', '2008', 'use', 'data', 'compression', 'measures', 'analyze', 'robust', 'designs', 'pdf', 'ieee', 'transactions', 'reliability', '54', '3', '381–388', 'doi:10.1109', 'tr.2005.853280', 's2cid', '9376086', 'd.', 'scully', 'carla', 'e.', 'brodley', '2006', 'compression', 'machine', 'learning', 'new', 'perspective', 'feature', 'space', 'vectors', 'data', 'compression', 'conference', \"dcc'06\", 'p.', '332', 'doi:10.1109', 'dcc.2006.13', 'isbn', '0', '7695', '2545', '8', 's2cid', '12311412', 'gary', 'adcock', 'january', '5', '2023', 'ai', 'video', 'compression', 'massive.io', 'retrieved', '6', 'april', '2023', 'mentzer', 'fabian', 'toderici', 'george', 'tschannen', 'michael', 'agustsson', 'eirikur', '2020', 'high', 'fidelity', 'generative', 'image', 'compression', 'arxiv:2006.09965', 'eess', 'iv', 'unsupervised', 'learning', '|', 'ibm', 'www.ibm.com', '23', 'september', '2021', 'retrieved', '2024', '02', '05', 'differentially', 'private', 'clustering', 'large', 'scale', 'datasets', 'blog.research.google', '2023', '05', '25', 'retrieved', '2024', '03', '16', 'edwards', 'benj', '2023', '09', '28', 'ai', 'language', 'models', 'exceed', 'png', 'flac', 'lossless', 'compression', 'says', 'study', 'ars', 'technica', 'retrieved', '2024', '03', '07', 'le', 'roux', 'nicolas', 'bengio', 'yoshua', 'fitzgibbon', 'andrew', '2012', 'improving', 'second', 'order', 'methods', 'modeling', 'uncertainty', 'sra', 'suvrit', 'nowozin', 'sebastian', 'wright', 'stephen', 'j.', 'eds', 'optimization', 'machine', 'learning', 'mit', 'press', 'p.', '404', 'isbn', '9780262016469', 'archived', 'original', '2023', '01', '17', 'retrieved', '2020', '11', '12', 'bzdok', 'danilo', 'altman', 'naomi', 'krzywinski', 'martin', '2018', 'statistics', 'versus', 'machine', 'learning', 'nature', 'methods', '15', '4', '233–234', 'doi:10.1038', 'nmeth.4642', 'pmc', '6082636', 'pmid', '30100822', 'michael', 'i.', 'jordan', '2014', '09', '10', 'statistics', 'machine', 'learning', 'reddit', 'archived', 'original', '2017', '10', '18', 'retrieved', '2014', '10', '01', 'hung', 'et', 'al', 'algorithms', 'measure', 'surgeon', 'performance', 'anticipate', 'clinical', 'outcomes', 'robotic', 'surgery', 'jama', 'surg', '2018', 'cornell', 'university', 'library', 'august', '2001', 'breiman', 'statistical', 'modeling', 'cultures', 'comments', 'rejoinder', 'author', 'statistical', 'science', '16', '3', 'doi:10.1214', 'ss/1009213726', 's2cid', '62729017', 'archived', 'original', '26', 'june', '2017', 'retrieved', '8', 'august', '2015', 'gareth', 'james', 'daniela', 'witten', 'trevor', 'hastie', 'robert', 'tibshirani', '2013', 'introduction', 'statistical', 'learning', 'springer', 'p.', 'vii', 'archived', 'original', '2019', '06', '23', 'retrieved', '2014', '10', '25', 'ramezanpour', 'a.', 'beam', 'a.l.', 'chen', 'j.h.', 'mashaghi', 'a.', '17', 'november', '2020', 'statistical', 'physics', 'medical', 'diagnostics', 'learning', 'inference', 'optimization', 'algorithms', 'diagnostics', '10', '11', '972', 'doi:10.3390', 'diagnostics10110972', 'pmc', '7699346', 'pmid', '33228143', 'mashaghi', 'a.', 'ramezanpour', 'a.', '16', 'march', '2018', 'statistical', 'physics', 'medical', 'diagnostics', 'study', 'probabilistic', 'model', 'physical', 'review', 'e.', '97', '3–1', '032118', 'arxiv:1803.10019', 'bibcode:2018phrve', '97c2118m.', 'doi:10.1103', 'physreve.97.032118', 'pmid', '29776109', 's2cid', '4955393', 'mohri', 'mehryar', 'rostamizadeh', 'afshin', 'talwalkar', 'ameet', '2012', 'foundations', 'machine', 'learning', 'massachusetts', 'mit', 'press', 'isbn', '9780262018258', 'alpaydin', 'ethem', '2010', 'introduction', 'machine', 'learning', 'london', 'mit', 'press', 'isbn', '978', '0', '262', '01243', '0', 'retrieved', '4', 'february', '2017', 'jordan', 'm.', 'i.', 'mitchell', 't.', 'm.', '17', 'july', '2015', 'machine', 'learning', 'trends', 'perspectives', 'prospects', 'science', '349', '6245', '255–260', 'bibcode:2015sci', '349', '255j.', 'doi:10.1126', 'science.aaa8415', 'pmid', '26185243', 's2cid', '677218', 'el', 'naqa', 'issam', 'murphy', 'martin', 'j.', '2015', 'machine', 'learning', 'machine', 'learning', 'radiation', 'oncology', 'pp', '3–11', 'doi:10.1007/978', '3', '319', '18305', '3_1', 'isbn', '978', '3', '319', '18304', '6', 's2cid', '178586107', 'okolie', 'jude', 'a.', 'savage', 'shauna', 'ogbaga', 'chukwuma', 'c.', 'gunes', 'burcu', 'june', '2022', 'assessing', 'potential', 'machine', 'learning', 'methods', 'study', 'removal', 'pharmaceuticals', 'wastewater', 'biochar', 'activated', 'carbon', 'total', 'environment', 'research', 'themes', '1–2', '100001', 'doi:10.1016', 'j.totert.2022.100001', 's2cid', '249022386', 'russell', 'stuart', 'j.', 'norvig', 'peter', '2010', 'artificial', 'intelligence', 'modern', 'approach', 'ed', 'prentice', 'hall', 'isbn', '9780136042594', 'mohri', 'mehryar', 'rostamizadeh', 'afshin', 'talwalkar', 'ameet', '2012', 'foundations', 'machine', 'learning', 'mit', 'press', 'isbn', '9780262018258', 'alpaydin', 'ethem', '2010', 'introduction', 'machine', 'learning', 'mit', 'press', 'p.', '9', 'isbn', '978', '0', '262', '01243', '0', 'archived', 'original', '2023', '01', '17', 'retrieved', '2018', '11', '25', 'lecture', '2', 'notes', 'supervised', 'learning', 'www.cs.cornell.edu', 'retrieved', '2024', '07', '01', 'jordan', 'michael', 'i.', 'bishop', 'christopher', 'm.', '2004', 'neural', 'networks', 'allen', 'b.', 'tucker', 'ed', 'computer', 'science', 'handbook', 'second', 'edition', 'section', 'vii', 'intelligent', 'systems', 'boca', 'raton', 'florida', 'chapman', 'hall', 'crc', 'press', 'llc', 'isbn', '978', '1', '58488', '360', '9', 'zhang', 'bosen', 'huang', 'haiyan', 'tibbs', 'cortes', 'laura', 'e.', 'vanous', 'adam', 'zhang', 'zhiwu', 'sanguinet', 'karen', 'garland', 'campbell', 'kimberly', 'a.', 'yu', 'jianming', 'li', 'xianran', '2023', 'streamline', 'unsupervised', 'machine', 'learning', 'survey', 'graph', 'indel', 'based', 'haplotypes', 'pan', 'genomes', 'molecular', 'plant', '16', '6', '975–978', 'doi:10.1016', 'j.molp.2023.05.005', 'pmid', '37202927', 'zhang', 'bosen', 'huang', 'haiyan', 'tibbs', 'cortes', 'laura', 'e.', 'vanous', 'adam', 'zhang', 'zhiwu', 'sanguinet', 'karen', 'garland', 'campbell', 'kimberly', 'a.', 'yu', 'jianming', 'li', 'xianran', '2023', '02', '13', 'streamline', 'unsupervised', 'machine', 'learning', 'survey', 'graph', 'indel', 'based', 'haplotypes', 'pan', 'genomes', 'report', 'doi:10.1101/2023.02.11.527743', 'misra', 'ishan', 'maaten', 'laurens', 'van', 'der', '2020', 'self', 'supervised', 'learning', 'pretext', 'invariant', 'representations', '6707–6717', 'cite', 'journal', 'cite', 'journal', 'requires', '|journal=', 'help', 'jaiswal', 'ashish', 'babu', 'ashwin', 'ramesh', 'zadeh', 'mohammad', 'zaki', 'banerjee', 'debapriya', 'makedon', 'fillia', 'march', '2021', 'survey', 'contrastive', 'self', 'supervised', 'learning', 'technologies', '9', '1', '2', 'arxiv:2011.00362', 'doi:10.3390', 'technologies9010002', 'issn', '2227', '7080', 'alex', 'ratner', 'stephen', 'bach', 'paroma', 'varma', 'chris', 'weak', 'supervision', 'new', 'programming', 'paradigm', 'machine', 'learning', 'hazyresearch.github.io', 'referencing', 'work', 'members', 'hazy', 'research', 'archived', 'original', '2019', '06', '06', 'retrieved', '2019', '06', '06', 'van', 'otterlo', 'm.', 'wiering', 'm.', '2012', 'reinforcement', 'learning', 'markov', 'decision', 'processes', 'reinforcement', 'learning', 'adaptation', 'learning', 'optimization', 'vol', '12', 'pp', '3–42', 'doi:10.1007/978', '3', '642', '27645', '3_1', 'isbn', '978', '3', '642', '27644', '6', 'roweis', 'sam', 't.', 'saul', 'lawrence', 'k.', '22', 'dec', '2000', 'nonlinear', 'dimensionality', 'reduction', 'locally', 'linear', 'embedding', 'science', '290', '5500', '2323–2326', 'bibcode:2000sci', '290.2323r.', 'doi:10.1126', 'science.290.5500.2323', 'pmid', '11125150', 's2cid', '5987139', 'archived', 'original', '15', 'august', '2021', 'retrieved', '17', 'july', '2023', 'pavel', 'brazdil', 'christophe', 'giraud', 'carrier', 'carlos', 'soares', 'ricardo', 'vilalta', '2009', 'metalearning', 'applications', 'data', 'mining', 'fourth', 'ed', 'springer', 'science+business', 'media', 'pp', '10–14', 'passim', 'isbn', '978', '3540732624', 'bozinovski', 's.', '1982', 'self', 'learning', 'system', 'secondary', 'reinforcement', 'trappl', 'robert', 'ed', 'cybernetics', 'systems', 'research', 'proceedings', 'sixth', 'european', 'meeting', 'cybernetics', 'systems', 'research', 'north', 'holland', 'pp', '397–402', 'isbn', '978', '0', '444', '86488', '8', 'bozinovski', 'stevo', '2014', 'modeling', 'mechanisms', 'cognition', 'emotion', 'interaction', 'artificial', 'neural', 'networks', '1981', 'procedia', 'computer', 'science', 'p.', '255', '263', 'bozinovski', 's.', '2001', 'self', 'learning', 'agents', 'connectionist', 'theory', 'emotion', 'based', 'crossbar', 'value', 'judgment', 'cybernetics', 'systems', '32(6', '637–667', 'y.', 'bengio', 'a.', 'courville', 'p.', 'vincent', '2013', 'representation', 'learning', 'review', 'new', 'perspectives', 'ieee', 'transactions', 'pattern', 'analysis', 'machine', 'intelligence', '35', '8)', '1798–1828', 'arxiv:1206.5538', 'doi:10.1109', 'tpami.2013.50', 'pmid', '23787338', 's2cid', '393948', 'nathan', 'srebro', 'jason', 'd.', 'm.', 'rennie', 'tommi', 's.', 'jaakkola', '2004', 'maximum', 'margin', 'matrix', 'factorization', 'nips', 'coates', 'adam', 'lee', 'honglak', 'ng', 'andrew', 'y.', '2011', 'analysis', 'single', 'layer', 'networks', 'unsupervised', 'feature', 'learning', 'pdf', \"int'l\", 'conf', 'ai', 'statistics', 'aistats', 'archived', 'original', 'pdf', '2017', '08', '13', 'retrieved', '2018', '11', '25', 'csurka', 'gabriella', 'dance', 'christopher', 'c.', 'fan', 'lixin', 'willamowski', 'jutta', 'bray', 'cédric', '2004', 'visual', 'categorization', 'bags', 'keypoints', 'pdf', 'eccv', 'workshop', 'statistical', 'learning', 'computer', 'vision', 'archived', 'pdf', 'original', '2019', '07', '13', 'retrieved', '2019', '08', '29', 'daniel', 'jurafsky', 'james', 'h.', 'martin', '2009', 'speech', 'language', 'processing', 'pearson', 'education', 'international', 'pp', '145–146', 'lu', 'haiping', 'plataniotis', 'k.n.', 'venetsanopoulos', 'a.n.', '2011', 'survey', 'multilinear', 'subspace', 'learning', 'tensor', 'data', 'pdf', 'pattern', 'recognition', '44', '7', '1540–1551', 'bibcode:2011patre', '44.1540l.', 'doi:10.1016', 'j.patcog.2011.01.004', 'archived', 'pdf', 'original', '2019', '07', '10', 'retrieved', '2015', '09', '04', 'yoshua', 'bengio', '2009', 'learning', 'deep', 'architectures', 'ai', 'publishers', 'inc.', 'pp', '1–3', 'isbn', '978', '1', '60198', '294', '0', 'archived', 'original', '2023', '01', '17', 'retrieved', '2016', '02', '15', 'tillmann', 'a.', 'm.', '2015', 'computational', 'intractability', 'exact', 'approximate', 'dictionary', 'learning', 'ieee', 'signal', 'processing', 'letters', '22', '1', '45–49', 'arxiv:1405.6664', 'bibcode:2015ispl', '22', '45t.', 'doi:10.1109', 'lsp.2014.2345761', 's2cid', '13342762', 'aharon', 'm', 'm', 'elad', 'bruckstein', '2006', 'k', 'svd', 'algorithm', 'designing', 'overcomplete', 'dictionaries', 'sparse', 'representation', 'archived', '2018', '11', '23', 'wayback', 'machine', 'signal', 'processing', 'ieee', 'transactions', '54', '11', '4311–4322', 'zimek', 'arthur', 'schubert', 'erich', '2017', 'outlier', 'detection', 'encyclopedia', 'database', 'systems', 'springer', 'new', 'york', 'pp', '1–5', 'doi:10.1007/978', '1', '4899', '7993', '3_80719', '1', 'isbn', '9781489979933', 'hodge', 'v.', 'j.', 'austin', 'j.', '2004', 'survey', 'outlier', 'detection', 'methodologies', 'pdf', 'artificial', 'intelligence', 'review', '22', '2', '85–126', 'citeseerx', '10.1.1.318.4023', 'doi:10.1007', 's10462', '004', '4304', 'y.', 's2cid', '59941878', 'archived', 'pdf', 'original', '2015', '06', '22', 'retrieved', '2018', '11', '25', 'dokas', 'paul', 'ertoz', 'levent', 'kumar', 'vipin', 'lazarevic', 'aleksandar', 'srivastava', 'jaideep', 'tan', 'pang', 'ning', '2002', 'data', 'mining', 'network', 'intrusion', 'detection', 'pdf', 'proceedings', 'nsf', 'workshop', 'generation', 'data', 'mining', 'archived', 'pdf', 'original', '2015', '09', '23', 'retrieved', '2023', '03', '26', 'chandola', 'v.', 'banerjee', 'a.', 'kumar', 'v.', '2009', 'anomaly', 'detection', 'survey', 'acm', 'computing', 'surveys', '41', '3', '1–58', 'doi:10.1145/1541880.1541882', 's2cid', '207172599', 'fleer', 's.', 'moringen', 'a.', 'klatzky', 'r.', 'l.', 'ritter', 'h.', '2020', 'learning', 'efficient', 'haptic', 'shape', 'exploration', 'rigid', 'tactile', 'sensor', 'array', 's.', 'fleer', 'a.', 'moringen', 'r.', 'klatzky', 'h.', 'ritter', 'plos', '15', '1', 'e0226880', 'arxiv:1902.07501', 'doi:10.1371', 'journal.pone.0226880', 'pmc', '6940144', 'pmid', '31896135', 'moringen', 'alexandra', 'fleer', 'sascha', 'walck', 'guillaume', 'ritter', 'helge', '2020', 'nisky', 'ilana', 'hartcher', \"o'brien\", 'jess', 'wiertlewski', 'michaël', 'smeets', 'jeroen', 'eds', 'attention', 'based', 'robot', 'learning', 'haptic', 'interaction', 'haptics', 'science', 'technology', 'applications', 'lecture', 'notes', 'computer', 'science', 'vol', '12272', 'cham', 'springer', 'international', 'publishing', 'pp', '462–470', 'doi:10.1007/978', '3', '030', '58147', '3_51', 'isbn', '978', '3', '030', '58146', '6', 's2cid', '220069113', 'piatetsky', 'shapiro', 'gregory', '1991', 'discovery', 'analysis', 'presentation', 'strong', 'rules', 'piatetsky', 'shapiro', 'gregory', 'frawley', 'william', 'j.', 'eds', 'knowledge', 'discovery', 'databases', 'aaai', 'mit', 'press', 'cambridge', 'ma', 'bassel', 'george', 'w.', 'glaab', 'enrico', 'marquez', 'julietta', 'holdsworth', 'michael', 'j.', 'bacardit', 'jaume', '2011', '09', '01', 'functional', 'network', 'construction', 'arabidopsis', 'rule', 'based', 'machine', 'learning', 'large', 'scale', 'data', 'sets', 'plant', 'cell', '23', '9', '3101–3116', 'doi:10.1105', 'tpc.111.088153', 'issn', '1532', '298x.', 'pmc', '3203449', 'pmid', '21896882', 'agrawal', 'r.', 'imieliński', 't.', 'swami', 'a.', '1993', 'mining', 'association', 'rules', 'sets', 'items', 'large', 'databases', 'proceedings', '1993', 'acm', 'sigmod', 'international', 'conference', 'management', 'data', 'sigmod', '93', 'p.', '207', 'citeseerx', '10.1.1.40.6984', 'doi:10.1145/170035.170072', 'isbn', '978', '0897915922', 's2cid', '490415', 'urbanowicz', 'ryan', 'j.', 'moore', 'jason', 'h.', '2009', '09', '22', 'learning', 'classifier', 'systems', 'complete', 'introduction', 'review', 'roadmap', 'journal', 'artificial', 'evolution', 'applications', '2009', '1–25', 'doi:10.1155/2009/736398', 'issn', '1687', '6229', 'plotkin', 'g.d.', 'automatic', 'methods', 'inductive', 'inference', 'archived', '2017', '12', '22', 'wayback', 'machine', 'phd', 'thesis', 'university', 'edinburgh', '1970', 'shapiro', 'ehud', 'y.', 'inductive', 'inference', 'theories', 'facts', 'archived', '2021', '08', '21', 'wayback', 'machine', 'research', 'report', '192', 'yale', 'university', 'department', 'computer', 'science', '1981', 'reprinted', 'j.-l.', 'lassez', 'g.', 'plotkin', 'eds', 'computational', 'logic', 'mit', 'press', 'cambridge', 'ma', '1991', 'pp', '199–254', 'shapiro', 'ehud', 'y.', '1983', 'algorithmic', 'program', 'debugging', 'cambridge', 'mass', 'mit', 'press', 'isbn', '0', '262', '19218', '7', 'shapiro', 'ehud', 'y.', 'model', 'inference', 'system', 'archived', '2023', '04', '06', 'wayback', 'machine', 'proceedings', '7th', 'international', 'joint', 'conference', 'artificial', 'intelligence', 'volume', '2', 'morgan', 'kaufmann', 'publishers', 'inc.', '1981', 'burkov', 'andriy', '2019', 'page', 'machine', 'learning', 'book', 'polen', 'andriy', 'burkov', 'isbn', '978', '1', '9995795', '0', '0', 'russell', 'stuart', 'j.', 'norvig', 'peter', '2021', 'artificial', 'intelligence', 'modern', 'approach', 'pearson', 'series', 'artificial', 'intelligence', 'fourth', 'ed', 'hoboken', 'pearson', 'isbn', '978', '0', '13', '461099', '3', 'honglak', 'lee', 'roger', 'grosse', 'rajesh', 'ranganath', 'andrew', 'y.', 'ng', 'convolutional', 'deep', 'belief', 'networks', 'scalable', 'unsupervised', 'learning', 'hierarchical', 'representations', 'archived', '2017', '10', '18', 'wayback', 'machine', 'proceedings', '26th', 'annual', 'international', 'conference', 'machine', 'learning', '2009', 'cortes', 'corinna', 'vapnik', 'vladimir', 'n.', '1995', 'support', 'vector', 'networks', 'machine', 'learning', '20', '3', '273–297', 'doi:10.1007', 'bf00994018', 'stevenson', 'christopher', 'tutorial', 'polynomial', 'regression', 'excel', 'facultystaff.richmond.edu', 'archived', 'original', '2', 'june', '2013', 'retrieved', '22', 'january', '2017', 'documentation', 'scikit', 'learn', 'similar', 'examples', 'archived', '2022', '11', '02', 'wayback', 'machine', 'goldberg', 'david', 'e.', 'holland', 'john', 'h.', '1988', 'genetic', 'algorithms', 'machine', 'learning', 'pdf', 'machine', 'learning', '3', '2', '95–99', 'doi:10.1007', 'bf00113892', 's2cid', '35506513', 'archived', 'pdf', 'original', '2011', '05', '16', 'retrieved', '2019', '09', '03', 'michie', 'd.', 'spiegelhalter', 'd.', 'j.', 'taylor', 'c.', 'c.', '1994', 'machine', 'learning', 'neural', 'statistical', 'classification', 'ellis', 'horwood', 'series', 'artificial', 'intelligence', 'bibcode:1994mlns.book', 'm.', 'zhang', 'jun', 'zhan', 'zhi', 'hui', 'lin', 'ying', 'chen', 'ni', 'gong', 'yue', 'jiao', 'zhong', 'jing', 'hui', 'chung', 'henry', 's.h.', 'li', 'yun', 'shi', 'yu', 'hui', '2011', 'evolutionary', 'computation', 'meets', 'machine', 'learning', 'survey', 'computational', 'intelligence', 'magazine', '6', '4', '68–75', 'doi:10.1109', 'mci.2011.942584', 's2cid', '6760276', 'federated', 'learning', 'collaborative', 'machine', 'learning', 'centralized', 'training', 'data', 'google', 'ai', 'blog', '6', 'april', '2017', 'archived', 'original', '2019', '06', '07', 'retrieved', '2019', '06', '08', 'machine', 'learning', 'included', 'cfa', 'curriculum', 'discussion', 'kathleen', 'derose', 'christophe', 'le', 'lanno', '2020', 'machine', 'learning', 'archived', '2020', '01', '13', 'wayback', 'machine', 'ivanenko', 'mikhail', 'smolik', 'waldemar', 't.', 'wanta', 'damian', 'midura', 'mateusz', 'wróblewski', 'przemysław', 'hou', 'xiaohan', 'yan', 'xiaoheng', '2023', 'image', 'reconstruction', 'supervised', 'learning', 'wearable', 'electrical', 'impedance', 'tomography', 'thorax', 'sensors', '23', '18', '7774', 'bibcode:2023senso', '23.7774i.', 'doi:10.3390', 's23187774', 'pmc', '10538128', 'pmid', '37765831', 'belkor', 'home', 'page', 'research.att.com', 'netflix', 'tech', 'blog', 'netflix', 'recommendations', '5', 'stars', '1', '2012', '04', '06', 'archived', 'original', '31', '2016', 'retrieved', '8', 'august', '2015', 'scott', 'patterson', '13', 'july', '2010', 'letting', 'machines', 'decide', 'wall', 'street', 'journal', 'archived', 'original', '24', 'june', '2018', 'retrieved', '24', 'june', '2018', 'vinod', 'khosla', 'january', '10', '2012', 'need', 'doctors', 'algorithms', 'tech', 'crunch', 'archived', 'original', 'june', '18', '2018', 'retrieved', 'october', '20', '2016', 'machine', 'learning', 'algorithm', 'studied', 'fine', 'art', 'paintings', 'saw', 'things', 'art', 'historians', 'noticed', 'archived', '2016', '06', '04', 'wayback', 'machine', 'physics', 'arxiv', 'blog', 'vincent', 'james', '2019', '04', '10', 'ai', 'generated', 'textbook', 'shows', 'robot', 'writers', 'actually', 'good', 'verge', 'archived', 'original', '2019', '05', '05', 'retrieved', '2019', '05', '05', 'vaishya', 'raju', 'javaid', 'mohd', 'khan', 'ibrahim', 'haleem', 'haleem', 'abid', 'july', '1', '2020', 'artificial', 'intelligence', 'ai', 'applications', 'covid-19', 'pandemic', 'diabetes', 'metabolic', 'syndrome', 'clinical', 'research', 'reviews', '14', '4', '337–339', 'doi:10.1016', 'j.dsx.2020.04.012', 'pmc', '7195043', 'pmid', '32305024', 'rezapouraghdam', 'hamed', 'akhshik', 'arash', 'ramkissoon', 'haywantee', 'march', '10', '2021', 'application', 'machine', 'learning', 'predict', 'visitors', 'green', 'behavior', 'marine', 'protected', 'areas', 'evidence', 'cyprus', 'journal', 'sustainable', 'tourism', '31', '11', '2479–2505', 'doi:10.1080/09669582.2021.1887878', 'hdl:10037/24073', 'dey', 'somdip', 'singh', 'amit', 'kumar', 'wang', 'xiaohang', 'mcdonald', 'maier', 'klaus', '2020', '06', '15', 'user', 'interaction', 'aware', 'reinforcement', 'learning', 'power', 'thermal', 'efficiency', 'cpu', 'gpu', 'mobile', 'mpsocs', '2020', 'design', 'automation', 'test', 'europe', 'conference', 'exhibition', 'date', 'pdf', 'pp', '1728–1733', 'doi:10.23919', 'date48585.2020.9116294', 'isbn', '978', '3', '9819263', '4', '7', 's2cid', '219858480', 'archived', 'original', '2021', '12', '13', 'retrieved', '2022', '01', '20', 'quested', 'tony', 'smartphones', 'smarter', 'essex', 'innovation', 'business', 'weekly', 'archived', 'original', '2021', '06', '24', 'retrieved', '2021', '06', '17', 'williams', 'rhiannon', '2020', '07', '21', 'future', 'smartphones', 'prolong', 'battery', 'life', 'monitoring', 'owners', 'behaviour', 'i.', 'archived', 'original', '2021', '06', '24', 'retrieved', '2021', '06', '17', 'rasekhschaffe', 'keywan', 'christian', 'jones', 'robert', 'c.', '2019', '07', '01', 'machine', 'learning', 'stock', 'selection', 'financial', 'analysts', 'journal', '75', '3', '70–88', 'doi:10.1080/0015198x.2019.1596678', 'issn', '0015', '198x.', 's2cid', '108312507', 'archived', 'original', '2023', '11', '26', 'retrieved', '2023', '11', '26', 'chung', 'yunsie', 'green', 'william', 'h.', '2024', 'machine', 'learning', 'quantum', 'chemistry', 'predict', 'experimental', 'solvent', 'effects', 'reaction', 'rates', 'chemical', 'science', '15', '7', '2410–2424', 'doi:10.1039', 'd3sc05353a.', 'issn', '2041', '6520', 'pmc', '10866337', 'pmid', '38362410', 'archived', 'original', '2024', '05', '19', 'retrieved', '2024', '04', '21', 'sun', 'yuran', 'huang', 'shih', 'kai', 'zhao', 'xilei', '2024', '02', '01', 'predicting', 'hurricane', 'evacuation', 'decisions', 'interpretable', 'machine', 'learning', 'methods', 'international', 'journal', 'disaster', 'risk', 'science', '15', '1', '134–148', 'doi:10.1007', 's13753', '024', '00541', '1', 'issn', '2192', '6395', 'sun', 'yuran', 'zhao', 'xilei', 'lovreglio', 'ruggiero', 'kuligowski', 'erica', '2024', '01', '01', 'naser', 'm.', 'z.', 'ed', '8', 'ai', 'large', 'scale', 'evacuation', 'modeling', 'promises', 'challenges', 'interpretable', 'machine', 'learning', 'analysis', 'design', 'assessment', 'informed', 'decision', 'making', 'civil', 'infrastructure', 'woodhead', 'publishing', 'series', 'civil', 'structural', 'engineering', 'woodhead', 'publishing', 'pp', '185–204', 'isbn', '978', '0', '12', '824073', '1', 'archived', 'original', '2024', '05', '19', 'retrieved', '2024', '05', '19', 'xu', 'ningzhe', 'lovreglio', 'ruggiero', 'kuligowski', 'erica', 'd.', 'cova', 'thomas', 'j.', 'nilsson', 'daniel', 'zhao', 'xilei', '2023', '03', '01', 'predicting', 'assessing', 'wildfire', 'evacuation', 'decision', 'making', 'machine', 'learning', 'findings', '2019', 'kincade', 'fire', 'fire', 'technology', '59', '2', '793–825', 'doi:10.1007', 's10694', '023', '01363', '1', 'issn', '1572', '8099', 'archived', 'original', '2024', '05', '19', 'retrieved', '2024', '05', '19', 'wang', 'ke', 'shi', 'xiupeng', 'goh', 'algena', 'pei', 'xuan', 'qian', 'shunzhi', '2019', '06', '01', 'machine', 'learning', 'based', 'study', 'pedestrian', 'movement', 'dynamics', 'emergency', 'evacuation', 'fire', 'safety', 'journal', '106', '163–176', 'doi:10.1016', 'j.firesaf.2019.04.008', 'hdl:10356/143390', 'issn', '0379', '7112', 'archived', 'original', '2024', '05', '19', 'retrieved', '2024', '05', '19', 'zhao', 'xilei', 'lovreglio', 'ruggiero', 'nilsson', 'daniel', '2020', '05', '01', 'modelling', 'interpreting', 'pre', 'evacuation', 'decision', 'making', 'machine', 'learning', 'automation', 'construction', '113', '103140', 'doi:10.1016', 'j.autcon.2020.103140', 'issn', '0926', '5805', 'archived', 'original', '2024', '05', '19', 'retrieved', '2024', '05', '19', 'machine', 'learning', 'models', 'fail', 'learn', 'quicktake', 'q&a', 'bloomberg.com', '2016', '11', '10', 'archived', 'original', '2017', '03', '20', 'retrieved', '2017', '04', '10', 'wave', 'corporate', 'ai', 'doomed', 'fail', 'harvard', 'business', 'review', '2017', '04', '18', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '20', 'a.i.', 'euphoria', 'doomed', 'fail', 'venturebeat', '2016', '09', '18', 'archived', 'original', '2018', '08', '19', 'retrieved', '2018', '08', '20', '9', 'reasons', 'machine', 'learning', 'project', 'fail', 'www.kdnuggets.com', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '20', 'babuta', 'alexander', 'oswald', 'marion', 'rinik', 'christine', '2018', 'transparency', 'intelligibility', 'report', 'royal', 'united', 'services', 'institute', 'rusi', 'pp', '17–22', 'archived', 'original', '2023', '12', '09', 'retrieved', '2023', '12', '09', 'uber', 'self', 'driving', 'car', 'killed', 'pedestrian', 'economist', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '20', 'ibm', 'watson', 'recommended', 'unsafe', 'incorrect', 'cancer', 'treatments', 'stat', 'stat', '2018', '07', '25', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '21', 'hernandez', 'daniela', 'greenwald', 'ted', '2018', '08', '11', 'ibm', 'watson', 'dilemma', 'wall', 'street', 'journal', 'issn', '0099', '9660', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '21', 'allyn', 'bobby', 'feb', '27', '2023', 'microsoft', 'experiment', 'artificial', 'intelligence', 'tech', 'backfired', 'national', 'public', 'radio', 'archived', 'original', 'december', '8', '2023', 'retrieved', 'dec', '8', '2023', 'reddy', 'shivani', 'm.', 'patel', 'sheila', 'weyrich', 'meghan', 'fenton', 'joshua', 'viswanathan', 'meera', '2020', 'comparison', 'traditional', 'systematic', 'review', 'approach', 'review', 'reviews', 'semi', 'automation', 'strategies', 'update', 'evidence', 'systematic', 'reviews', '9', '1', '243', 'doi:10.1186', 's13643', '020', '01450', '2', 'issn', '2046', '4053', 'pmc', '7574591', 'pmid', '33076975', 'garcia', 'megan', '2016', 'racist', 'machine', 'world', 'policy', 'journal', '33', '4', '111–117', 'doi:10.1215/07402775', '3813015', 'issn', '0740', '2775', 's2cid', '151595343', 'caliskan', 'aylin', 'bryson', 'joanna', 'j.', 'narayanan', 'arvind', '2017', '04', '14', 'semantics', 'derived', 'automatically', 'language', 'corpora', 'contain', 'human', 'like', 'biases', 'science', '356', '6334', '183–186', 'arxiv:1608.07187', 'bibcode:2017sci', '356', '183c.', 'doi:10.1126', 'science.aal4230', 'issn', '0036', '8075', 'pmid', '28408601', 's2cid', '23163324', 'wang', 'xinan', 'dasgupta', 'sanjoy', '2016', 'lee', 'd.', 'd.', 'sugiyama', 'm.', 'luxburg', 'u.', 'v.', 'guyon', 'i.', 'eds', 'algorithm', 'l1', 'nearest', 'neighbor', 'search', 'monotonic', 'embedding', 'pdf', 'advances', 'neural', 'information', 'processing', 'systems', '29', 'curran', 'associates', 'inc.', 'pp', '983–991', 'archived', 'pdf', 'original', '2017', '04', '07', 'retrieved', '2018', '08', '20', 'silva', 'selena', 'kenney', 'martin', '2018', 'algorithms', 'platforms', 'ethnic', 'bias', 'integrative', 'essay', 'pdf', 'phylon', '55', '1', '2', '9–37', 'issn', '0031', '8906', 'jstor', '26545017', 'archived', 'pdf', 'original', 'jan', '27', '2024', 'vincent', 'james', 'jan', '12', '2018', 'google', 'fixed', 'racist', 'algorithm', 'removing', 'gorillas', 'image', 'labeling', 'tech', 'verge', 'archived', 'original', '2018', '08', '21', 'retrieved', '2018', '08', '20', 'crawford', 'kate', '25', 'june', '2016', 'opinion', '|', 'artificial', 'intelligence', 'white', 'guy', 'problem', 'new', 'york', 'times', 'archived', 'original', '2021', '01', '14', 'retrieved', '2018', '08', '20', 'metz', 'rachel', 'march', '24', '2016', 'microsoft', 'accidentally', 'unleashed', 'neo', 'nazi', 'sexbot', 'mit', 'technology', 'review', 'archived', 'original', '2018', '11', '09', 'retrieved', '2018', '08', '20', 'simonite', 'tom', 'march', '30', '2017', 'microsoft', 'ai', 'adaptable', 'help', 'businesses', 'mit', 'technology', 'review', 'archived', 'original', '2018', '11', '09', 'retrieved', '2018', '08', '20', 'hempel', 'jessi', '2018', '11', '13', 'fei', 'fei', 'li', 'quest', 'machines', 'better', 'humanity', 'wired', 'issn', '1059', '1028', 'archived', 'original', '2020', '12', '14', 'retrieved', '2019', '02', '17', 'rudin', 'cynthia', '2019', 'stop', 'explaining', 'black', 'box', 'machine', 'learning', 'models', 'high', 'stakes', 'decisions', 'use', 'interpretable', 'models', 'instead', 'nature', 'machine', 'intelligence', '1', '5', '206–215', 'doi:10.1038', 's42256', '019', '0048', 'x.', 'pmc', '9122117', 'pmid', '35603010', 'hu', 'tongxi', 'zhang', 'xuesong', 'bohrer', 'gil', 'liu', 'yanlan', 'zhou', 'yuyu', 'martin', 'jay', 'li', 'yang', 'zhao', 'kaiguang', '2023', 'crop', 'yield', 'prediction', 'explainable', 'ai', 'interpretable', 'machine', 'learning', 'dangers', 'black', 'box', 'models', 'evaluating', 'climate', 'change', 'impacts', 'crop', 'yield', 'agricultural', 'forest', 'meteorology', '336', '109458', 'doi:10.1016', 'j.agrformet.2023.109458', 's2cid', '258552400', 'domingos', '2015', 'chapter', '6', 'chapter', '7', 'domingos', '2015', 'p.', '286', 'single', 'pixel', 'change', 'fools', 'ai', 'programs', 'bbc', 'news', '3', 'november', '2017', 'archived', 'original', '22', 'march', '2018', 'retrieved', '12', 'march', '2018', 'ai', 'hallucination', 'problem', 'proving', 'tough', 'fix', 'wired', '2018', 'archived', 'original', '12', 'march', '2018', 'retrieved', '12', 'march', '2018', 'madry', 'a.', 'makelov', 'a.', 'schmidt', 'l.', 'tsipras', 'd.', 'vladu', 'a.', '4', 'september', '2019', 'deep', 'learning', 'models', 'resistant', 'adversarial', 'attacks', 'arxiv:1706.06083', 'stat', 'ml', 'adversarial', 'machine', 'learning', 'cltc', 'uc', 'berkeley', 'center', 'long', 'term', 'cybersecurity', 'cltc', 'archived', 'original', '2022', '05', '17', 'retrieved', '2022', '05', '25', 'machine', 'learning', 'models', 'vulnerable', 'undetectable', 'backdoors', 'register', 'archived', 'original', '13', '2022', 'retrieved', '13', '2022', 'undetectable', 'backdoors', 'plantable', 'machine', 'learning', 'algorithm', 'ieee', 'spectrum', '10', '2022', 'archived', 'original', '11', '2022', 'retrieved', '13', '2022', 'goldwasser', 'shafi', 'kim', 'michael', 'p.', 'vaikuntanathan', 'vinod', 'zamir', '14', 'april', '2022', 'planting', 'undetectable', 'backdoors', 'machine', 'learning', 'models', 'arxiv:2204.06974', 'cs', 'lg', 'kohavi', 'ron', '1995', 'study', 'cross', 'validation', 'bootstrap', 'accuracy', 'estimation', 'model', 'selection', 'pdf', 'international', 'joint', 'conference', 'artificial', 'intelligence', 'archived', 'pdf', 'original', '2018', '07', '12', 'retrieved', '2023', '03', '26', 'pontius', 'robert', 'gilmore', 'si', 'kangping', '2014', 'total', 'operating', 'characteristic', 'measure', 'diagnostic', 'ability', 'multiple', 'thresholds', 'international', 'journal', 'geographical', 'information', 'science', '28', '3', '570–583', 'bibcode:2014ijgis', '28', '570p.', 'doi:10.1080/13658816.2013.862623', 's2cid', '29204880', 'bostrom', 'nick', '2011', 'ethics', 'artificial', 'intelligence', 'pdf', 'archived', 'original', 'pdf', '4', 'march', '2016', 'retrieved', '11', 'april', '2016', 'edionwe', 'tolulope', 'fight', 'racist', 'algorithms', 'outline', 'archived', 'original', '17', 'november', '2017', 'retrieved', '17', 'november', '2017', 'jeffries', 'adrianne', 'machine', 'learning', 'racist', 'internet', 'racist', 'outline', 'archived', 'original', '17', 'november', '2017', 'retrieved', '17', 'november', '2017', 'wong', 'carissa', '2023', '03', '30', 'ai', 'fairness', 'research', 'held', 'lack', 'diversity', 'nature', 'doi:10.1038', 'd41586', '023', '00935', 'z.', 'pmid', '36997714', 's2cid', '257857012', 'archived', 'original', '2023', '04', '12', 'retrieved', '2023', '12', '09', 'zhang', 'jack', 'clark', 'artificial', 'intelligence', 'index', 'report', '2021', 'pdf', 'stanford', 'institute', 'human', 'centered', 'artificial', 'intelligence', 'archived', 'pdf', 'original', '2024', '05', '19', 'retrieved', '2023', '12', '09', 'bostrom', 'nick', 'yudkowsky', 'eliezer', '2011', 'ethics', 'artificial', 'intelligence', 'pdf', 'nick', 'bostrom', 'archived', 'pdf', 'original', '2015', '12', '20', 'retrieved', '2020', '11', '18', 'm.o.r.', 'prates', 'p.h.c.', 'avelar', 'l.c.', 'lamb', '11', 'mar', '2019', 'assessing', 'gender', 'bias', 'machine', 'translation', 'case', 'study', 'google', 'translate', 'arxiv:1809.02208', 'cs', 'cy', 'narayanan', 'arvind', 'august', '24', '2016', 'language', 'necessarily', 'contains', 'human', 'biases', 'machines', 'trained', 'language', 'corpora', 'freedom', 'tinker', 'archived', 'original', 'june', '25', '2018', 'retrieved', 'november', '19', '2016', 'char', 'danton', 's.', 'shah', 'nigam', 'h.', 'magnus', 'david', '2018', '03', '15', 'implementing', 'machine', 'learning', 'health', 'care', 'addressing', 'ethical', 'challenges', 'new', 'england', 'journal', 'medicine', '378', '11', '981–983', 'doi:10.1056', 'nejmp1714229', 'issn', '0028', '4793', 'pmc', '5962261', 'pmid', '29539284', 'char', 'd.', 's.', 'shah', 'n.', 'h.', 'magnus', 'd.', '2018', 'implementing', 'machine', 'learning', 'health', 'care', 'addressing', 'ethical', 'challenges', 'new', 'england', 'journal', 'medicine', '378', '11', '981–983', 'doi:10.1056', 'nejmp1714229', 'pmc', '5962261', 'pmid', '29539284', 'research', 'ai', '23', 'october', '2015', 'deep', 'neural', 'networks', 'acoustic', 'modeling', 'speech', 'recognition', 'airesearch.com', 'archived', 'original', '1', 'february', '2016', 'retrieved', '23', 'october', '2015', 'gpus', 'continue', 'dominate', 'ai', 'accelerator', 'market', 'informationweek', 'december', '2019', 'archived', 'original', '10', 'june', '2020', 'retrieved', '11', 'june', '2020', 'ray', 'tiernan', '2019', 'ai', 'changing', 'entire', 'nature', 'compute', 'zdnet', 'archived', 'original', '25', '2020', 'retrieved', '11', 'june', '2020', 'ai', 'compute', 'openai', '16', '2018', 'archived', 'original', '17', 'june', '2020', 'retrieved', '11', 'june', '2020', 'cornell', 'ntt', 'physical', 'neural', 'networks', 'radical', 'alternative', 'implementing', 'deep', 'neural', 'networks', 'enables', 'arbitrary', 'physical', 'systems', 'training', '|', 'synced', '27', '2021', 'archived', 'original', '27', 'october', '2021', 'retrieved', '12', 'october', '2021', 'nano', 'spaghetti', 'solve', 'neural', 'network', 'power', 'consumption', 'archived', 'original', '2021', '10', '06', 'retrieved', '2021', '10', '12', 'fafoutis', 'xenofon', 'marchegiani', 'letizia', 'elsts', 'atis', 'pope', 'james', 'piechocki', 'robert', 'craddock', 'ian', '2018', '05', '07', 'extending', 'battery', 'lifetime', 'wearable', 'sensors', 'embedded', 'machine', 'learning', '2018', 'ieee', '4th', 'world', 'forum', 'internet', 'things', 'wf', 'iot', 'pp', '269–274', 'doi:10.1109', 'wf', 'iot.2018.8355116', 'hdl:1983', 'b8fdb58b-7114', '45c6', '82e4', '4ab239c1327f', 'isbn', '978', '1', '4673', '9944', '9', 's2cid', '19192912', 'archived', 'original', '2022', '01', '18', 'retrieved', '2022', '01', '17', 'beginner', 'guide', 'machine', 'learning', 'embedded', 'systems', 'analytics', 'india', 'magazine', '2021', '06', '02', 'archived', 'original', '2022', '01', '18', 'retrieved', '2022', '01', '17', 'synced', '2022', '01', '12', 'google', 'purdue', 'harvard', 'u', 'open', 'source', 'framework', 'tinyml', 'achieves', '75x', 'speedups', 'fpgas', '|', 'synced', 'syncedreview.com', 'archived', 'original', '2022', '01', '18', 'retrieved', '2022', '01', '17', 'giri', 'davide', 'chiu', 'kuan', 'lin', 'di', 'guglielmo', 'giuseppe', 'mantovani', 'paolo', 'carloni', 'luca', 'p.', '2020', '06', '15', 'esp4ml', 'platform', 'based', 'design', 'systems', 'chip', 'embedded', 'machine', 'learning', '2020', 'design', 'automation', 'test', 'europe', 'conference', 'exhibition', 'date', 'pp', '1049–1054', 'arxiv:2004.03640', 'doi:10.23919', 'date48585.2020.9116317', 'isbn', '978', '3', '9819263', '4', '7', 's2cid', '210928161', 'archived', 'original', '2022', '01', '18', 'retrieved', '2022', '01', '17', 'louis', 'marcia', 'sahaya', 'azad', 'zahra', 'delshadtehrani', 'leila', 'gupta', 'suyog', 'warden', 'pete', 'reddi', 'vijay', 'janapa', 'joshi', 'ajay', '2019', 'deep', 'learning', 'tensorflow', 'lite', 'risc', 'v', 'harvard', 'university', 'archived', 'original', '2022', '01', '17', 'retrieved', '2022', '01', '17', 'ibrahim', 'ali', 'osta', 'mario', 'alameh', 'mohamad', 'saleh', 'moustafa', 'chible', 'hussein', 'valle', 'maurizio', '2019', '01', '21', 'approximate', 'computing', 'methods', 'embedded', 'machine', 'learning', '2018', '25th', 'ieee', 'international', 'conference', 'electronics', 'circuits', 'systems', 'icecs', 'pp', '845–848', 'doi:10.1109', 'icecs.2018.8617877', 'isbn', '978', '1', '5386', '9562', '3', 's2cid', '58670712', 'archived', 'original', '2022', '01', '17', 'retrieved', '2022', '01', '17', 'dblp', 'tensorflow', 'eager', 'multi', 'stage', 'python', 'embedded', 'dsl', 'machine', 'learning', 'dblp.org', 'archived', 'original', '2022', '01', '18', 'retrieved', '2022', '01', '17', 'branco', 'sérgio', 'ferreira', 'andré', 'g.', 'cabral', 'jorge', '2019', '11', '05', 'machine', 'learning', 'resource', 'scarce', 'embedded', 'systems', 'fpgas', 'end', 'devices', 'survey', 'electronics', '8', '11', '1289', 'doi:10.3390', 'electronics8111289', 'hdl:1822/62521', 'issn', '2079', '9292', 'sources', 'domingos', 'pedro', 'september', '22', '2015', 'master', 'algorithm', 'quest', 'ultimate', 'learning', 'machine', 'remake', 'world', 'basic', 'books', 'isbn', '978', '0465065707', 'nilsson', 'nils', '1998', 'artificial', 'intelligence', 'new', 'synthesis', 'morgan', 'kaufmann', 'isbn', '978', '1', '55860', '467', '4', 'archived', 'original', '26', 'july', '2020', 'retrieved', '18', 'november', '2019', 'russell', 'stuart', 'j.', 'norvig', 'peter', '2003', 'artificial', 'intelligence', 'modern', 'approach', '2nd', 'ed', 'upper', 'saddle', 'river', 'new', 'jersey', 'prentice', 'hall', 'isbn', '0', '13', '790395', '2', 'poole', 'david', 'mackworth', 'alan', 'goebel', 'randy', '1998', 'computational', 'intelligence', 'logical', 'approach', 'new', 'york', 'oxford', 'university', 'press', 'isbn', '978', '0', '19', '510270', '3', 'archived', 'original', '26', 'july', '2020', 'retrieved', '22', 'august', '2020', 'reading', 'nils', 'j.', 'nilsson', 'introduction', 'machine', 'learning', 'archived', '2019', '08', '16', 'wayback', 'machine', 'trevor', 'hastie', 'robert', 'tibshirani', 'jerome', 'h.', 'friedman', '2001', 'elements', 'statistical', 'learning', 'archived', '2013', '10', '27', 'wayback', 'machine', 'springer', 'isbn', '0', '387', '95284', '5', 'pedro', 'domingos', 'september', '2015', 'master', 'algorithm', 'basic', 'books', 'isbn', '978', '0', '465', '06570', '7', 'ian', 'h.', 'witten', 'eibe', 'frank', '2011', 'data', 'mining', 'practical', 'machine', 'learning', 'tools', 'techniques', 'morgan', 'kaufmann', '664pp', 'isbn', '978', '0', '12', '374856', '0', 'ethem', 'alpaydin', '2004', 'introduction', 'machine', 'learning', 'mit', 'press', 'isbn', '978', '0', '262', '01243', '0', 'david', 'j.', 'c.', 'mackay', 'information', 'theory', 'inference', 'learning', 'algorithms', 'archived', '2016', '02', '17', 'wayback', 'machine', 'cambridge', 'cambridge', 'university', 'press', '2003', 'isbn', '0', '521', '64298', '1', 'richard', 'o.', 'duda', 'peter', 'e.', 'hart', 'david', 'g.', 'stork', '2001', 'pattern', 'classification', '2nd', 'edition', 'wiley', 'new', 'york', 'isbn', '0', '471', '05669', '3', 'christopher', 'bishop', '1995', 'neural', 'networks', 'pattern', 'recognition', 'oxford', 'university', 'press', 'isbn', '0', '19', '853864', '2', 'stuart', 'russell', 'peter', 'norvig', '2009', 'artificial', 'intelligence', 'modern', 'approach', 'archived', '2011', '02', '28', 'wayback', 'machine', 'pearson', 'isbn', '9789332543515', 'ray', 'solomonoff', 'inductive', 'inference', 'machine', 'ire', 'convention', 'record', 'section', 'information', 'theory', '2', 'pp', '56–62', '1957', 'ray', 'solomonoff', 'inductive', 'inference', 'machine', 'archived', '2011', '04', '26', 'wayback', 'machine', 'privately', 'circulated', 'report', '1956', 'dartmouth', 'summer', 'research', 'conference', 'ai', 'kevin', 'p.', 'murphy', '2021', 'probabilistic', 'machine', 'learning', 'introduction', 'archived', '2021', '04', '11', 'wayback', 'machine', 'mit', 'press', 'external', 'links', 'wikimedia', 'commons', 'media', 'related', 'machine', 'learning', 'quotations', 'related', 'machine', 'learning', 'wikiquote', 'international', 'machine', 'learning', 'society', 'mloss', 'academic', 'database', 'open', 'source', 'machine', 'learning', 'software']\n",
            "['journal machine learning journal statistical learning redirects statistical learning linguistics statistical learning language acquisition series machine learning data mining paradigms problems supervised learning classification regression clustering dimensionality reduction structured prediction anomaly detection artificial neural network reinforcement learning learning humans model diagnostics mathematical foundations machine learning venues related articles vte series artificial intelligence major goals artificial general intelligenceintelligent agentrecursive self improvementplanningcomputer visiongeneral game playingknowledge reasoningnatural language processingroboticsai safety approaches applications philosophy history glossary vte machine learning ml field study artificial intelligence concerned development study statistical algorithms learn data generalize unseen data perform tasks explicit instructions.[1 recently artificial neural networks able surpass previous approaches performance.[2 ml finds application fields including natural language processing computer vision speech recognition email filtering agriculture medicine.[3][4 applied business problems known predictive analytics machine learning statistically based computational statistics important source field methods mathematical foundations ml provided mathematical optimization mathematical programming methods data mining related parallel field study focusing exploratory data analysis eda unsupervised learning.[6][7 theoretical viewpoint probably approximately correct pac learning provides framework describing machine learning history timeline machine learning term machine learning coined 1959 arthur samuel ibm employee pioneer field computer gaming artificial intelligence.[8][9 synonym self teaching computers time period.[10][11 earliest machine learning model introduced 1950s arthur samuel invented program calculated winning chance checkers history machine learning roots decades human desire effort study human cognitive processes.[12 1949 canadian psychologist donald hebb published book organization behavior introduced theoretical neural structure formed certain interactions nerve cells.[13 hebb model neurons interacting set groundwork ais machine learning algorithms work nodes artificial neurons computers communicate data.[12 researchers studied human cognitive systems contributed modern machine learning technologies including logician walter pitts warren mcculloch proposed', 'early mathematical models neural networks come algorithms mirror human thought processes.[12 early 1960s experimental learning machine punched tape memory called cybertron developed raytheon company analyze sonar signals electrocardiograms speech patterns rudimentary reinforcement learning repetitively trained human operator teacher recognize patterns equipped goof button cause reevaluate incorrect decisions.[14 representative book research machine learning 1960s nilsson book learning machines dealing machine learning pattern classification.[15 interest related pattern recognition continued 1970s described duda hart 1973.[16 1981 report given teaching strategies artificial neural network learns recognize 40 characters 26 letters 10 digits 4 special symbols computer terminal.[17 tom m. mitchell provided widely quoted formal definition algorithms studied machine learning field computer program said learn experience e respect class tasks t performance measure p performance tasks t measured p improves experience e.\"[18 definition tasks machine learning concerned offers fundamentally operational definition defining field cognitive terms follows alan turing proposal paper computing machinery intelligence question machines think replaced question machines thinking entities do?\".[19 modern day machine learning objectives classify data based models developed purpose predictions future outcomes based models hypothetical algorithm specific classifying data use computer vision moles coupled supervised learning order train classify cancerous moles machine learning algorithm stock trading inform trader future potential predictions.[20 relationships fields artificial intelligence machine learning subfield ai[21 scientific endeavor machine learning grew quest artificial intelligence ai early days ai academic discipline researchers interested having machines learn data attempted approach problem symbolic methods termed neural networks perceptrons models later found reinventions generalized linear models statistics.[22 probabilistic reasoning employed especially automated medical diagnosis.[23 488 increasing emphasis', 'logical knowledge based approach caused rift ai machine learning probabilistic systems plagued theoretical practical problems data acquisition representation.[23 488 1980 expert systems come dominate ai statistics favor.[24 work symbolic knowledge based learning continue ai leading inductive logic programming(ilp statistical line research outside field ai proper pattern recognition information retrieval.[23 708–710 755 neural networks research abandoned ai computer science time line continued outside ai cs field connectionism researchers disciplines including hopfield rumelhart hinton main success came mid-1980s reinvention backpropagation.[23 25 machine learning ml reorganized recognized field started flourish 1990s field changed goal achieving artificial intelligence tackling solvable problems practical nature shifted focus away symbolic approaches inherited ai methods models borrowed statistics fuzzy logic probability theory.[24 data compression section excerpt data compression machine learning.[edit close connection machine learning compression system predicts posterior probabilities sequence given entire history optimal data compression arithmetic coding output distribution conversely optimal compressor prediction finding symbol compresses best given previous history equivalence justification data compression benchmark general intelligence\".[25][26][27 alternative view compression algorithms implicitly map strings implicit feature space vectors compression based similarity measures compute similarity feature spaces compressor c define associated vector space ℵ c maps input string x corresponding vector norm ||~x|| exhaustive examination feature spaces underlying compression algorithms precluded space instead feature vectors chooses examine representative lossless compression methods lzw lz77 ppm.[28 according aixi theory connection directly explained hutter prize best possible compression x smallest possible software generates x. example model zip file compressed size includes zip file unzipping software unzip smaller combined', 'form examples ai powered audio video compression software include nvidia maxine aivc.[29 examples software perform ai powered image compression include opencv tensorflow matlab image processing toolbox ipt high fidelity generative image compression.[30 unsupervised machine learning k means clustering utilized compress data grouping similar data points clusters technique simplifies handling extensive datasets lack predefined labels finds widespread use fields image compression.[31 data compression aims reduce size data files enhancing storage efficiency speeding data transmission k means clustering unsupervised machine learning algorithm employed partition dataset specified number clusters k represented centroid points process condenses extensive datasets compact set representative points particularly beneficial image signal processing k means clustering aids data reduction replacing groups data points centroids preserving core information original data significantly decreasing required storage space.[32 large language models llms capable lossless data compression demonstrated deepmind research chinchilla 70b model developed deepmind chinchilla 70b effectively compressed data outperforming conventional methods portable network graphics png images free lossless audio codec flac audio achieved compression image audio data 43.4 16.4 original sizes respectively.[33 data mining machine learning data mining employ methods overlap significantly machine learning focuses prediction based known properties learned training data data mining focuses discovery previously unknown properties data analysis step knowledge discovery databases data mining uses machine learning methods different goals hand machine learning employs data mining methods unsupervised learning preprocessing step improve learner accuracy confusion research communities separate conferences separate journals ecml pkdd major exception comes basic assumptions work machine learning performance usually evaluated respect ability reproduce known knowledge knowledge discovery data mining kdd key task discovery previously unknown knowledge evaluated respect known knowledge uninformed unsupervised method easily outperformed supervised methods typical kdd task supervised methods unavailability training data', 'machine learning intimate ties optimization learning problems formulated minimization loss function training set examples loss functions express discrepancy predictions model trained actual problem instances example classification wants assign label instances models trained correctly predict preassigned labels set examples).[34 generalization difference optimization machine learning arises goal generalization optimization algorithms minimize loss training set machine learning concerned minimizing loss unseen samples characterizing generalization learning algorithms active topic current research especially deep learning algorithms statistics machine learning statistics closely related fields terms methods distinct principal goal statistics draws population inferences sample machine learning finds generalizable predictive patterns.[35 according michael i. jordan ideas machine learning methodological principles theoretical tools long pre history statistics.[36 suggested term data science placeholder overall field.[36 conventional statistical analyses require priori selection model suitable study data set addition significant theoretically relevant variables based previous experience included analysis contrast machine learning built pre structured model data shape model detecting underlying patterns variables input train model accurate ultimate model be.[37 leo breiman distinguished statistical modeling paradigms data model algorithmic model,[38 algorithmic model means machine learning algorithms like random forest statisticians adopted methods machine learning leading combined field statistical learning.[39 statistical physics analytical computational techniques derived deep rooted physics disordered systems extended large scale problems including machine learning e.g. analyze weight space deep neural networks.[40 statistical physics finding applications area medical diagnostics.[41 theory main articles computational learning theory statistical learning theory core objective learner generalize experience.[5][42 generalization context ability learning machine perform accurately new unseen examples tasks having experienced learning data set training examples come generally unknown probability distribution considered representative space occurrences learner build general model space enables produce sufficiently', 'accurate predictions new cases computational analysis machine learning algorithms performance branch theoretical computer science known computational learning theory probably approximately correct learning pac model training sets finite future uncertain learning theory usually yield guarantees performance algorithms instead probabilistic bounds performance common bias variance decomposition way quantify generalization error best performance context generalization complexity hypothesis match complexity function underlying data hypothesis complex function model fitted data complexity model increased response training error decreases hypothesis complex model subject overfitting generalization poorer.[43 addition performance bounds learning theorists study time complexity feasibility learning computational learning theory computation considered feasible polynomial time kinds time complexity results positive results certain class functions learned polynomial time negative results certain classes learned polynomial time approaches machine learning approaches traditionally divided broad categories correspond learning paradigms depending nature signal feedback available learning system supervised learning computer presented example inputs desired outputs given teacher goal learn general rule maps inputs outputs unsupervised learning labels given learning algorithm leaving find structure input unsupervised learning goal discovering hidden patterns data means end feature learning reinforcement learning computer program interacts dynamic environment perform certain goal driving vehicle playing game opponent navigates problem space program provided feedback analogous rewards tries maximize.[5 algorithm advantages limitations single algorithm works problems.[44][45][46 supervised learning main article supervised learning support vector machine supervised learning model divides data regions separated linear boundary linear boundary divides black circles white supervised learning algorithms build mathematical model set data contains', 'inputs desired outputs.[47 data known training data consists set training examples training example inputs desired output known supervisory signal mathematical model training example represented array vector called feature vector training data represented matrix iterative optimization objective function supervised learning algorithms learn function predict output associated new inputs.[48 optimal function allows algorithm correctly determine output inputs training data algorithm improves accuracy outputs predictions time said learned perform task.[18 types supervised learning algorithms include active learning classification regression.[49 classification algorithms outputs restricted limited set values regression algorithms outputs numerical value range example classification algorithm filters emails input incoming email output folder file email examples regression predicting height person future temperature 50 similarity learning area supervised machine learning closely related regression classification goal learn examples similarity function measures similar related objects applications ranking recommendation systems visual identity tracking face verification speaker verification unsupervised learning main article unsupervised learning cluster analysis unsupervised learning algorithms find structures data labeled classified categorized instead responding feedback unsupervised learning algorithms identify commonalities data react based presence absence commonalities new piece data central applications unsupervised machine learning include clustering dimensionality reduction,[7 density estimation.[51 unsupervised learning algorithms streamlined process identifying large indel based haplotypes gene interest pan genome.[52 clustering large indel permuted slopes clips,[53 turns alignment image learning regression problem varied slope b estimates pair dna segments enables identify segments sharing set indels cluster analysis assignment set observations subsets called clusters observations cluster similar according predesignated criteria observations drawn different clusters dissimilar different clustering techniques different assumptions', 'structure data defined similarity metric evaluated example internal compactness similarity members cluster separation difference clusters methods based estimated density graph connectivity special type unsupervised learning called self supervised learning involves training model generating supervisory signal data itself.[54][55 semi supervised learning main article semi supervised learning semi supervised learning falls unsupervised learning labeled training data supervised learning completely labeled training data training examples missing training labels machine learning researchers found unlabeled data conjunction small labeled data produce considerable improvement learning accuracy weakly supervised learning training labels noisy limited imprecise labels cheaper obtain resulting larger effective training sets.[56 reinforcement learning main article reinforcement learning reinforcement learning area machine learning concerned software agents ought actions environment maximize notion cumulative reward generality field studied disciplines game theory control theory operations research information theory simulation based optimization multi agent systems swarm intelligence statistics genetic algorithms reinforcement learning environment typically represented markov decision process mdp reinforcements learning algorithms use dynamic programming techniques.[57 reinforcement learning algorithms assume knowledge exact mathematical model mdp exact models infeasible reinforcement learning algorithms autonomous vehicles learning play game human opponent dimensionality reduction dimensionality reduction process reducing number random variables consideration obtaining set principal variables.[58 words process reducing dimension feature set called number features dimensionality reduction techniques considered feature elimination extraction popular methods dimensionality reduction principal component analysis pca pca involves changing higher dimensional data e.g. 3d smaller space e.g. 2d manifold hypothesis proposes high dimensional data sets lie low dimensional manifolds dimensionality reduction techniques assumption leading area manifold learning manifold regularization types approaches developed fit neatly', \"fold categorization machine learning system example topic modeling meta learning.[59 self learning self learning machine learning paradigm introduced 1982 neural network capable self learning named crossbar adaptive array caa).[60 learning external rewards external teacher advice caa self learning algorithm computes crossbar fashion decisions actions emotions feelings consequence situations system driven interaction cognition emotion.[61 self learning algorithm updates memory matrix w = ||w(a s)|| iteration executes following machine learning routine situation s perform action receive consequence situation s compute emotion consequence situation v(s update crossbar memory w'(a s = w(a s + v(s system input situation output action behavior a. separate reinforcement input advice input environment backpropagated value secondary reinforcement emotion consequence situation caa exists environments behavioral environment behaves genetic environment wherefrom initially receives initial emotions situations encountered behavioral environment receiving genome species vector genetic environment caa learns goal seeking behavior environment contains desirable undesirable situations.[62 feature learning main article feature learning learning algorithms aim discovering better representations inputs provided training.[63 classic examples include principal component analysis cluster analysis feature learning algorithms called representation learning algorithms attempt preserve information input transform way makes useful pre processing step performing classification predictions technique allows reconstruction inputs coming unknown data generating distribution necessarily faithful configurations implausible distribution replaces manual feature engineering allows machine learn features use perform specific task feature learning supervised unsupervised supervised feature learning features learned labeled input data examples include artificial neural networks multilayer perceptrons supervised dictionary learning unsupervised feature learning features learned unlabeled input data examples include dictionary learning independent component analysis autoencoders matrix factorization[64 forms\", 'clustering.[65][66][67 manifold learning algorithms attempt constraint learned representation low dimensional sparse coding algorithms attempt constraint learned representation sparse meaning mathematical model zeros multilinear subspace learning algorithms aim learn low dimensional representations directly tensor representations multidimensional data reshaping higher dimensional vectors.[68 deep learning algorithms discover multiple levels representation hierarchy features higher level abstract features defined terms generating lower level features argued intelligent machine learns representation disentangles underlying factors variation explain observed data.[69 feature learning motivated fact machine learning tasks classification require input mathematically computationally convenient process real world data images video sensory data yielded attempts algorithmically define specific features alternative discover features representations examination relying explicit algorithms sparse dictionary learning main article sparse dictionary learning sparse dictionary learning feature learning method training example represented linear combination basis functions assumed sparse matrix method strongly np hard difficult solve approximately.[70 popular heuristic method sparse dictionary learning k svd algorithm sparse dictionary learning applied contexts classification problem determine class previously unseen training example belongs dictionary class built new training example associated class best sparsely represented corresponding dictionary sparse dictionary learning applied image de noising key idea clean image patch sparsely represented image dictionary noise cannot.[71 anomaly detection main article anomaly detection data mining anomaly detection known outlier detection identification rare items events observations raise suspicions differing significantly majority data.[72 typically anomalous items represent issue bank fraud structural defect medical problems errors text anomalies referred outliers novelties noise deviations exceptions.[73 particular context abuse network intrusion detection interesting objects rare objects unexpected bursts inactivity pattern adhere common statistical definition outlier rare object outlier detection methods', 'particular unsupervised algorithms fail data aggregated appropriately instead cluster analysis algorithm able detect micro clusters formed patterns.[74 broad categories anomaly detection techniques exist.[75 unsupervised anomaly detection techniques detect anomalies unlabeled test data set assumption majority instances data set normal looking instances fit remainder data set supervised anomaly detection techniques require data set labeled normal abnormal involves training classifier key difference statistical classification problems inherently unbalanced nature outlier detection semi supervised anomaly detection techniques construct model representing normal behavior given normal training data set test likelihood test instance generated model robot learning robot learning inspired multitude machine learning methods starting supervised learning reinforcement learning,[76][77 finally meta learning e.g. maml association rules main article association rule learning inductive logic programming association rule learning rule based machine learning method discovering relationships variables large databases intended identify strong rules discovered databases measure interestingness\".[78 rule based machine learning general term machine learning method identifies learns evolves rules store manipulate apply knowledge defining characteristic rule based machine learning algorithm identification utilization set relational rules collectively represent knowledge captured system contrast machine learning algorithms commonly identify singular model universally applied instance order prediction.[79 rule based machine learning approaches include learning classifier systems association rule learning artificial immune systems based concept strong rules rakesh agrawal tomasz imieliński arun swami introduced association rules discovering regularities products large scale transaction data recorded point sale pos systems supermarkets.[80 example rule o n o n s p o t t o e s ⇒ b u r g e r \\\\displaystyle \\\\{\\\\mathrm onions potatoes \\\\}\\\\rightarrow \\\\{\\\\mathrm burger found sales data supermarket indicate customer buys onions potatoes', 'likely buy hamburger meat information basis decisions marketing activities promotional pricing product placements addition market basket analysis association rules employed today application areas including web usage mining intrusion detection continuous production bioinformatics contrast sequence mining association rule learning typically consider order items transaction transactions learning classifier systems lcs family rule based machine learning algorithms combine discovery component typically genetic algorithm learning component performing supervised learning reinforcement learning unsupervised learning seek identify set context dependent rules collectively store apply knowledge piecewise manner order predictions.[81 inductive logic programming ilp approach rule learning logic programming uniform representation input examples background knowledge hypotheses given encoding known background knowledge set examples represented logical database facts ilp system derive hypothesized logic program entails positive negative examples inductive programming related field considers kind programming language representing hypotheses logic programming functional programs inductive logic programming particularly useful bioinformatics natural language processing gordon plotkin ehud shapiro laid initial theoretical foundation inductive machine learning logical setting.[82][83][84 shapiro built implementation model inference system 1981 prolog program inductively inferred logic programs positive negative examples.[85 term inductive refers philosophical induction suggesting theory explain observed facts mathematical induction proving property members ordered set models machine learning model type mathematical model trained given dataset predictions classifications new data training learning algorithm iteratively adjusts model internal parameters minimize errors predictions.[86 extension term model refer levels specificity general class models associated learning algorithms fully trained model internal parameters tuned.[87 types models researched machine learning systems picking best model task called model selection artificial neural networks main article artificial neural network deep learning artificial neural network interconnected group nodes akin vast network neurons', 'brain circular node represents artificial neuron arrow represents connection output artificial neuron input artificial neural networks anns connectionist systems computing systems vaguely inspired biological neural networks constitute animal brains systems learn perform tasks considering examples generally programmed task specific rules ann model based collection connected units nodes called artificial neurons loosely model neurons biological brain connection like synapses biological brain transmit information signal artificial neuron artificial neuron receives signal process signal additional artificial neurons connected common ann implementations signal connection artificial neurons real number output artificial neuron computed non linear function sum inputs connections artificial neurons called edges artificial neurons edges typically weight adjusts learning proceeds weight increases decreases strength signal connection artificial neurons threshold signal sent aggregate signal crosses threshold typically artificial neurons aggregated layers different layers perform different kinds transformations inputs signals travel layer input layer layer output layer possibly traversing layers multiple times original goal ann approach solve problems way human brain time attention moved performing specific tasks leading deviations biology artificial neural networks variety tasks including computer vision speech recognition machine translation social network filtering playing board video games medical diagnosis deep learning consists multiple hidden layers artificial neural network approach tries model way human brain processes light sound vision hearing successful applications deep learning computer vision speech recognition.[88 decision trees main article decision tree learning decision tree showing survival probability passengers titanic decision tree learning uses decision tree predictive model observations item represented branches conclusions item target value represented leaves predictive modeling approaches statistics data mining machine learning tree models', 'target variable discrete set values called classification trees tree structures leaves represent class labels branches represent conjunctions features lead class labels decision trees target variable continuous values typically real numbers called regression trees decision analysis decision tree visually explicitly represent decisions decision making data mining decision tree describes data resulting classification tree input decision making support vector machines main article support vector machine support vector machines svms known support vector networks set related supervised learning methods classification regression given set training examples marked belonging categories svm training algorithm builds model predicts new example falls category.[89 svm training algorithm non probabilistic binary linear classifier methods platt scaling exist use svm probabilistic classification setting addition performing linear classification svms efficiently perform non linear classification called kernel trick implicitly mapping inputs high dimensional feature spaces regression analysis main article regression analysis illustration linear regression data set regression analysis encompasses large variety statistical methods estimate relationship input variables associated features common form linear regression single line drawn best fit given data according mathematical criterion ordinary squares extended regularization methods mitigate overfitting bias ridge regression dealing non linear problems models include polynomial regression example trendline fitting microsoft excel[90 logistic regression statistical classification kernel regression introduces non linearity taking advantage kernel trick implicitly map input variables higher dimensional space bayesian networks main article bayesian network simple bayesian network rain influences sprinkler activated rain sprinkler influence grass wet bayesian network belief network directed acyclic graphical model probabilistic graphical model represents set random variables conditional independence directed acyclic graph dag example bayesian network represent probabilistic relationships diseases symptoms given symptoms network compute probabilities presence diseases', 'efficient algorithms exist perform inference learning bayesian networks model sequences variables like speech signals protein sequences called dynamic bayesian networks generalizations bayesian networks represent solve decision problems uncertainty called influence diagrams gaussian processes main article gaussian processes example gaussian process regression prediction compared regression models[91 gaussian process stochastic process finite collection random variables process multivariate normal distribution relies pre defined covariance function kernel models pairs points relate depending locations given set observed points input output examples distribution unobserved output new point function input data directly computed looking like observed points covariances points new unobserved point gaussian processes popular surrogate models bayesian optimization hyperparameter optimization genetic algorithms main article genetic algorithm genetic algorithm ga search algorithm heuristic technique mimics process natural selection methods mutation crossover generate new genotypes hope finding good solutions given problem machine learning genetic algorithms 1980s 1990s.[92][93 conversely machine learning techniques improve performance genetic evolutionary algorithms.[94 belief functions main article dempster shafer theory theory belief functions referred evidence theory dempster shafer theory general framework reasoning uncertainty understood connections frameworks probability possibility imprecise probability theories theoretical frameworks thought kind learner analogous properties evidence combined e.g. dempster rule combination like pmf based bayesian approach[clarification needed combine probabilities caveats beliefs functions compared bayesian approaches order incorporate ignorance uncertainty quantification belief function approaches implemented machine learning domain typically leverage fusion approach ensemble methods better handle learner decision boundary low samples ambiguous class issues standard machine learning approach tend difficulty resolving.[4][9 computational complexity algorithms dependent number propositions classes lead higher computation time compared machine learning approaches training models typically machine learning models require high quantity reliable', 'data perform accurate predictions training machine learning model machine learning engineers need target collect large representative sample data data training set varied corpus text collection images sensor data data collected individual users service overfitting watch training machine learning model trained models derived biased non evaluated data result skewed undesired predictions biased models result detrimental outcomes furthering negative impacts society objectives algorithmic bias potential result data fully prepared training machine learning ethics field study notably integrated machine learning engineering teams federated learning main article federated learning federated learning adapted form distributed artificial intelligence training machine learning models decentralizes training process allowing users privacy maintained needing send data centralized server increases efficiency decentralizing training process devices example gboard uses federated machine learning train search query prediction models users mobile phones having send individual searches google.[95 applications applications machine learning including agriculture anatomy adaptive website affective computing astronomy automated decision making banking behaviorism bioinformatics brain machine interfaces cheminformatics citizen science climate science computer networks computer vision credit card fraud detection data quality dna sequence classification economics financial market analysis[96 general game playing handwriting recognition healthcare information retrieval insurance internet fraud detection knowledge graph embedding linguistics machine learning control machine perception machine translation marketing medical diagnosis natural language processing natural language understanding online advertising optimization recommender systems robot locomotion search engines sentiment analysis sequence mining software engineering speech recognition structural health monitoring syntactic pattern recognition telecommunication theorem proving time series forecasting tomographic reconstruction[97 user behavior analytics 2006 media services provider netflix held netflix prize competition find program better predict user preferences improve accuracy existing cinematch movie recommendation algorithm 10 joint team researchers at&t labs research collaboration teams big chaos pragmatic theory built ensemble model win grand prize 2009 $ 1 million.[98 shortly prize awarded netflix realized viewers ratings', 'best indicators viewing patterns recommendation changed recommendation engine accordingly.[99 2010 wall street journal wrote firm rebellion research use machine learning predict financial crisis.[100 2012 co founder sun microsystems vinod khosla predicted 80 medical doctors jobs lost decades automated machine learning medical diagnostic software.[101 2014 reported machine learning algorithm applied field art history study fine art paintings revealed previously unrecognized influences artists.[102 2019 springer nature published research book created machine learning.[103 2020 machine learning technology help diagnoses aid researchers developing cure covid-19.[104 machine learning recently applied predict pro environmental behavior travelers.[105 recently machine learning technology applied optimize smartphone performance thermal behavior based user interaction phone.[106][107][108 applied correctly machine learning algorithms mlas utilize wide range company characteristics predict stock returns overfitting employing effective feature engineering combining forecasts mlas generate results far surpass obtained basic linear techniques like ols.[109 recent advancements machine learning extended field quantum chemistry novel algorithms enable prediction solvent effects chemical reactions offering new tools chemists tailor experimental conditions optimal outcomes.[110 machine learning useful tool investigate predict evacuation decision making large scale small scale disasters different solutions tested predict householders decide evacuate wildfires hurricanes.[111][112][113 applications focusing pre evacuation decisions building fires.[114][115 limitations machine learning transformative fields machine learning programs fail deliver expected results.[116][117][118 reasons numerous lack suitable data lack access data data bias privacy problems badly chosen tasks algorithms wrong tools people lack resources evaluation problems.[119 black box theory poses significant challenge black box refers situation algorithm process producing output entirely opaque meaning coders algorithm audit pattern machine extracted data.[120 house lords select committee claimed intelligence system substantial impact individual life considered acceptable provided satisfactory explanation', 'decisions makes.[120 2018 self driving car uber failed detect pedestrian killed collision.[121 attempts use machine learning healthcare ibm watson system failed deliver years time billions dollars invested.[122][123 microsoft bing chat chatbot reported produce hostile offensive response users.[124 machine learning strategy update evidence related systematic review increased reviewer burden related growth biomedical literature improved training sets developed sufficiently reduce workload burden limiting necessary sensitivity findings research themselves.[125 bias main article algorithmic bias different machine learning approaches suffer different data biases machine learning system trained specifically current customers able predict needs new customer groups represented training data trained human data machine learning likely pick constitutional unconscious biases present society.[126 language models learned data shown contain human like biases.[127][128 experiment carried propublica investigative journalism organization machine learning algorithm insight recidivism rates prisoners falsely flagged black defendants high risk twice white defendants \"[129 2015 google photos tag black people gorillas,[129 2018 resolved google reportedly workaround remove gorillas training data able recognize real gorillas all.[130 similar issues recognizing non white people found systems.[131 2016 microsoft tested tay chatbot learned twitter quickly picked racist sexist language.[132 challenges effective use machine learning longer adopted domains.[133 concern fairness machine learning reducing bias machine learning propelling use human good increasingly expressed artificial intelligence scientists including fei fei li reminds engineers t]here artificial ai inspired people created people importantly impacts people powerful tool beginning understand profound responsibility \"[134 explainability main article explainable artificial intelligence explainable ai xai interpretable ai explainable machine learning xml artificial intelligence ai humans', 'understand decisions predictions ai.[135 contrasts black box concept machine learning designers explain ai arrived specific decision.[136 refining mental models users ai powered systems dismantling misconceptions xai promises help users perform effectively xai implementation social right explanation overfitting main article overfitting blue line example overfitting linear function random noise settling bad overly complex theory gerrymandered fit past training data known overfitting systems attempt reduce overfitting rewarding theory accordance fits data penalizing theory accordance complex theory is.[137 limitations vulnerabilities learners disappoint learning wrong lesson toy example image classifier trained pictures brown horses black cats conclude brown patches likely horses.[138 real world example unlike humans current image classifiers primarily judgments spatial relationship components picture learn relationships pixels humans oblivious correlate images certain types real objects modifying patterns legitimate image result adversarial images system misclassifies.[139][140 adversarial vulnerabilities result nonlinear systems non pattern perturbations systems possible change output changing single adversarially chosen pixel.[141 machine learning models vulnerable manipulation and/or evasion adversarial machine learning.[142 researchers demonstrated backdoors placed undetectably classifying e.g. categories spam visible spam posts machine learning models developed and/or trained parties parties change classification input including cases type data software transparency provided possibly including white box access.[143][144][145 model assessments classification machine learning models validated accuracy estimation techniques like holdout method splits data training test set conventionally 2/3 training set 1/3 test set designation evaluates performance training model test set comparison k fold cross validation method randomly partitions data k subsets k experiments performed respectively considering 1 subset evaluation remaining k-1 subsets training model addition holdout cross validation methods', 'bootstrap samples n instances replacement dataset assess model accuracy.[146 addition overall accuracy investigators frequently report sensitivity specificity meaning true positive rate tpr true negative rate tnr respectively similarly investigators report false positive rate fpr false negative rate fnr rates ratios fail reveal numerators denominators total operating characteristic toc effective method express model diagnostic ability toc shows numerators denominators previously mentioned rates toc provides information commonly receiver operating characteristic roc roc associated area curve auc).[147 ethics ai control problem toronto declaration ethics artificial intelligence machine learning poses host ethical questions systems trained datasets collected biases exhibit biases use algorithmic bias digitizing cultural prejudices.[148 example 1988 uk commission racial equality found st. george medical school computer program trained data previous admissions staff program denied nearly 60 candidates found women non european sounding names.[126 job hiring data firm racist hiring policies lead machine learning system duplicating bias scoring job applicants similarity previous successful applicants.[149][150 example includes predictive policing company geolitica predictive algorithm resulted disproportionately high levels policing low income minority communities trained historical crime data.[129 responsible collection data documentation algorithmic rules system considered critical machine learning researchers blame lack participation representation minority population field ai machine learning vulnerability biases.[151 fact according research carried computing research association cra 2021 female faculty merely 16.1 faculty members focus ai universities world.[152 furthermore group new u.s. resident ai phd graduates 45 identified white 22.4 asian 3.2 hispanic 2.4 african american demonstrates lack diversity field ai.[152 ai equipped decisions technical fields rely heavily data historical information decisions rely objectivity logical reasoning.[153 human languages contain biases machines trained language corpora necessarily learn', 'biases.[154][155 forms ethical challenges related personal biases seen health care concerns health care professionals systems designed public interest income generating machines.[156 especially true united states long standing ethical dilemma improving health care increasing profits example algorithms designed provide patients unnecessary tests medication algorithm proprietary owners hold stakes potential machine learning health care provide professionals additional tool diagnose medicate plan recovery paths patients requires biases mitigated.[157 hardware 2010s advances machine learning algorithms computer hardware led efficient methods training deep neural networks particular narrow subdomain machine learning contain layers nonlinear hidden units.[158 2019 graphic processing units gpus ai specific enhancements displaced cpus dominant method training large scale commercial cloud ai.[159 openai estimated hardware computing largest deep learning projects alexnet 2012 alphazero 2017 found 300,000 fold increase compute required doubling time trendline 3.4 months.[160][161 neuromorphic physical neural networks physical neural network neuromorphic computer type artificial neural network electrically adjustable material emulate function neural synapse physical neural network emphasize reliance physical hardware emulate neurons opposed software based approaches generally term applicable artificial neural networks memristor electrically adjustable resistance material emulate neural synapse.[162][163 embedded machine learning embedded machine learning sub field machine learning machine learning model run embedded systems limited computing resources wearable computers edge devices microcontrollers.[164][165][166 running machine learning model embedded devices removes need transferring storing data cloud servers processing henceforth reducing data breaches privacy leaks happening transferring data minimizes theft intellectual properties personal data business secrets embedded machine learning applied techniques including hardware acceleration,[167][168 approximate computing,[169 optimization machine learning models more.[170][171 pruning quantization knowledge distillation low rank factorization network architecture search nas parameter sharing techniques optimization machine learning models software software suites containing', 'variety machine learning algorithms include following free open source software caffe deeplearning4j deepspeed elki google jax infer net keras kubeflow lightgbm mahout mallet microsoft cognitive toolkit ml.net mlpack mxnet opennn orange pandas software root tmva root scikit learn shogun spark mllib systemml tensorflow torch pytorch weka moa xgboost yooreeka proprietary software free open source editions knime rapidminer proprietary software amazon machine learning angoss knowledgestudio azure machine learning ibm watson studio google cloud vertex ai google prediction api ibm spss modeler kxen modeler lionsolver mathematica matlab neural designer neurosolutions oracle data mining oracle ai platform cloud service polyanalyst rcase sas enterprise miner sequencel splunk statistica data miner journals journal machine learning research machine learning nature machine intelligence neural computation ieee transactions pattern analysis machine intelligence conferences aaai conference artificial intelligence association computational linguistics acl european conference machine learning principles practice knowledge discovery databases ecml pkdd international conference computational intelligence methods bioinformatics biostatistics cibb international conference machine learning icml international conference learning representations iclr international conference intelligent robots systems iros conference knowledge discovery data mining kdd conference neural information processing systems neurips automated machine learning process automating application machine learning big data extremely large complex datasets differentiable programming programming paradigm force control list important publications machine learning list datasets machine learning research references definition explicitly programmed attributed arthur samuel coined term machine learning 1959 phrase found verbatim publication paraphrase appeared later confer paraphrasing arthur samuel 1959 question computers learn solve problems explicitly programmed koza john r. bennett forrest h. andre david keane martin a. 1996 automated design topology sizing analog electrical circuits genetic programming artificial intelligence design 96 artificial intelligence design 96 springer dordrecht pp 151–170 doi:10.1007/978 94 009 0279 4_9 isbn 978 94 010 6610', '5 machine learning ibm 22 september 2021 archived original 2023 12 27 retrieved 2023 06 27 hu junyan niu hanlin carrasco joaquin lennox barry arvin farshad 2020 voronoi based multi robot autonomous exploration unknown environments deep reinforcement learning ieee transactions vehicular technology 69 12 14413–14423 doi:10.1109 tvt.2020.3034800 issn 0018 9545 s2cid 228989788 yoosefzadeh najafabadi mohsen hugh earl tulpan dan sulik john eskandari milad 2021 application machine learning algorithms plant breeding predicting yield hyperspectral reflectance soybean plant sci 11 624273 doi:10.3389 fpls.2020.624273 pmc 7835636 pmid 33510761 bishop c. m. 2006 pattern recognition machine learning springer isbn 978 0 387 31073 2 machine learning pattern recognition viewed facets field\".[5 vii friedman jerome h. 1998 data mining statistics connection computing science statistics 29 1 3–9 samuel arthur 1959 studies machine learning game checkers ibm journal research development 3 3 210–229 citeseerx 10.1.1.368.2254 doi:10.1147 rd.33.0210 s2cid 2126705 r. kohavi f. provost glossary terms machine learning vol 30 2–3 pp 271–274 1998 gerovitch slava 9 april 2015 computer got revenge soviet union nautilus archived original 22 september 2021 retrieved 19 september 2021 lindsay richard p. 1 september 1964 impact automation public administration western political quarterly 17 3 78–81 doi:10.1177/106591296401700364 issn 0043 4078 s2cid 154021253 archived original 6 october 2021 retrieved 6 october 2021 history evolution machine learning timeline whatis archived original 2023 12 08 retrieved 2023 12 08 milner peter m. 1993 mind donald o. hebb scientific american 268 1 124–129 bibcode:1993sciam.268a.124m. doi:10.1038 scientificamerican0193 124 issn 0036 8733 jstor 24941344 pmid 8418480 archived original 2023 12 20 retrieved 2023 12 09', 'science goof button time magazine 18 august 1961 nilsson n. learning machines mcgraw hill 1965 duda r. hart p. pattern recognition scene analysis wiley interscience 1973 s. bozinovski teaching space representation concept adaptive pattern classification coins technical report 81 28 computer information science department university massachusetts amherst ma 1981 https://web.cs.umass.edu/publication/docs/1981/um-cs-1981-028.pdf archived 2021 02 25 wayback machine mitchell t. 1997 machine learning mcgraw hill p. 2 isbn 978 0 07 042807 2 harnad stevan 2008 annotation game turing 1950 computing machinery intelligence epstein robert peters grace eds turing test sourcebook philosophical methodological issues quest thinking computer kluwer pp 23–66 isbn 9781402067082 archived original 2012 03 09 retrieved 2012 12 11 introduction ai 1 edzion 2020 12 08 archived original 2021 02 18 retrieved 2020 12 09 sindhu v nivedha s prakash m february 2020 empirical science research bioinformatics machine learning journal mechanics continua mathematical sciences 7 doi:10.26782 jmcms.spl.7/2020.02.00006 sarle warren s. 1994 neural networks statistical models sugi 19 proceedings nineteenth annual sas users group international conference sas institute pp 1538–50 isbn 9781555446116 oclc 35546178 russell stuart norvig peter 2003 1995 artificial intelligence modern approach 2nd ed prentice hall isbn 978 0137903955 langley pat 2011 changing science machine learning machine learning 82 3 275–9 doi:10.1007 s10994 011 5242 y. mahoney matt rationale large text compression benchmark florida institute technology retrieved 5 march 2013 shmilovici a. kahiri y. ben gal i. hauser s. 2009 measuring efficiency intraday forex market universal data compression algorithm pdf computational economics 33 2 131–154 citeseerx 10.1.1.627.3751 doi:10.1007 s10614 008 9153 3 s2cid 17234503 archived pdf original 2009 07 09 i. ben gal 2008', \"use data compression measures analyze robust designs pdf ieee transactions reliability 54 3 381–388 doi:10.1109 tr.2005.853280 s2cid 9376086 d. scully carla e. brodley 2006 compression machine learning new perspective feature space vectors data compression conference dcc'06 p. 332 doi:10.1109 dcc.2006.13 isbn 0 7695 2545 8 s2cid 12311412 gary adcock january 5 2023 ai video compression massive.io retrieved 6 april 2023 mentzer fabian toderici george tschannen michael agustsson eirikur 2020 high fidelity generative image compression arxiv:2006.09965 eess iv unsupervised learning | ibm www.ibm.com 23 september 2021 retrieved 2024 02 05 differentially private clustering large scale datasets blog.research.google 2023 05 25 retrieved 2024 03 16 edwards benj 2023 09 28 ai language models exceed png flac lossless compression says study ars technica retrieved 2024 03 07 le roux nicolas bengio yoshua fitzgibbon andrew 2012 improving second order methods modeling uncertainty sra suvrit nowozin sebastian wright stephen j. eds optimization machine learning mit press p. 404 isbn 9780262016469 archived original 2023 01 17 retrieved 2020 11 12 bzdok danilo altman naomi krzywinski martin 2018 statistics versus machine learning nature methods 15 4 233–234 doi:10.1038 nmeth.4642 pmc 6082636 pmid 30100822 michael i. jordan 2014 09 10 statistics machine learning reddit archived original 2017 10 18 retrieved 2014 10 01 hung et al algorithms measure surgeon performance anticipate clinical outcomes robotic surgery jama surg 2018 cornell university library august 2001 breiman statistical modeling cultures comments rejoinder author statistical science 16 3 doi:10.1214 ss/1009213726 s2cid 62729017 archived original 26 june 2017 retrieved 8 august 2015 gareth james daniela witten trevor hastie robert tibshirani 2013 introduction statistical learning springer p. vii archived original 2019\", '06 23 retrieved 2014 10 25 ramezanpour a. beam a.l. chen j.h. mashaghi a. 17 november 2020 statistical physics medical diagnostics learning inference optimization algorithms diagnostics 10 11 972 doi:10.3390 diagnostics10110972 pmc 7699346 pmid 33228143 mashaghi a. ramezanpour a. 16 march 2018 statistical physics medical diagnostics study probabilistic model physical review e. 97 3–1 032118 arxiv:1803.10019 bibcode:2018phrve 97c2118m. doi:10.1103 physreve.97.032118 pmid 29776109 s2cid 4955393 mohri mehryar rostamizadeh afshin talwalkar ameet 2012 foundations machine learning massachusetts mit press isbn 9780262018258 alpaydin ethem 2010 introduction machine learning london mit press isbn 978 0 262 01243 0 retrieved 4 february 2017 jordan m. i. mitchell t. m. 17 july 2015 machine learning trends perspectives prospects science 349 6245 255–260 bibcode:2015sci 349 255j. doi:10.1126 science.aaa8415 pmid 26185243 s2cid 677218 el naqa issam murphy martin j. 2015 machine learning machine learning radiation oncology pp 3–11 doi:10.1007/978 3 319 18305 3_1 isbn 978 3 319 18304 6 s2cid 178586107 okolie jude a. savage shauna ogbaga chukwuma c. gunes burcu june 2022 assessing potential machine learning methods study removal pharmaceuticals wastewater biochar activated carbon total environment research themes 1–2 100001 doi:10.1016 j.totert.2022.100001 s2cid 249022386 russell stuart j. norvig peter 2010 artificial intelligence modern approach ed prentice hall isbn 9780136042594 mohri mehryar rostamizadeh afshin talwalkar ameet 2012 foundations machine learning mit press isbn 9780262018258 alpaydin ethem 2010 introduction machine learning mit press p. 9 isbn 978 0 262 01243 0 archived original 2023 01 17 retrieved 2018 11 25 lecture 2 notes supervised learning www.cs.cornell.edu retrieved 2024 07 01 jordan michael i. bishop christopher m. 2004 neural networks allen b. tucker ed computer science handbook', 'second edition section vii intelligent systems boca raton florida chapman hall crc press llc isbn 978 1 58488 360 9 zhang bosen huang haiyan tibbs cortes laura e. vanous adam zhang zhiwu sanguinet karen garland campbell kimberly a. yu jianming li xianran 2023 streamline unsupervised machine learning survey graph indel based haplotypes pan genomes molecular plant 16 6 975–978 doi:10.1016 j.molp.2023.05.005 pmid 37202927 zhang bosen huang haiyan tibbs cortes laura e. vanous adam zhang zhiwu sanguinet karen garland campbell kimberly a. yu jianming li xianran 2023 02 13 streamline unsupervised machine learning survey graph indel based haplotypes pan genomes report doi:10.1101/2023.02.11.527743 misra ishan maaten laurens van der 2020 self supervised learning pretext invariant representations 6707–6717 cite journal cite journal requires |journal= help jaiswal ashish babu ashwin ramesh zadeh mohammad zaki banerjee debapriya makedon fillia march 2021 survey contrastive self supervised learning technologies 9 1 2 arxiv:2011.00362 doi:10.3390 technologies9010002 issn 2227 7080 alex ratner stephen bach paroma varma chris weak supervision new programming paradigm machine learning hazyresearch.github.io referencing work members hazy research archived original 2019 06 06 retrieved 2019 06 06 van otterlo m. wiering m. 2012 reinforcement learning markov decision processes reinforcement learning adaptation learning optimization vol 12 pp 3–42 doi:10.1007/978 3 642 27645 3_1 isbn 978 3 642 27644 6 roweis sam t. saul lawrence k. 22 dec 2000 nonlinear dimensionality reduction locally linear embedding science 290 5500 2323–2326 bibcode:2000sci 290.2323r. doi:10.1126 science.290.5500.2323 pmid 11125150 s2cid 5987139 archived original 15 august 2021 retrieved 17 july 2023 pavel brazdil christophe giraud carrier carlos soares ricardo vilalta 2009 metalearning applications data mining fourth ed springer science+business media pp 10–14 passim isbn 978 3540732624 bozinovski s.', \"1982 self learning system secondary reinforcement trappl robert ed cybernetics systems research proceedings sixth european meeting cybernetics systems research north holland pp 397–402 isbn 978 0 444 86488 8 bozinovski stevo 2014 modeling mechanisms cognition emotion interaction artificial neural networks 1981 procedia computer science p. 255 263 bozinovski s. 2001 self learning agents connectionist theory emotion based crossbar value judgment cybernetics systems 32(6 637–667 y. bengio a. courville p. vincent 2013 representation learning review new perspectives ieee transactions pattern analysis machine intelligence 35 8) 1798–1828 arxiv:1206.5538 doi:10.1109 tpami.2013.50 pmid 23787338 s2cid 393948 nathan srebro jason d. m. rennie tommi s. jaakkola 2004 maximum margin matrix factorization nips coates adam lee honglak ng andrew y. 2011 analysis single layer networks unsupervised feature learning pdf int'l conf ai statistics aistats archived original pdf 2017 08 13 retrieved 2018 11 25 csurka gabriella dance christopher c. fan lixin willamowski jutta bray cédric 2004 visual categorization bags keypoints pdf eccv workshop statistical learning computer vision archived pdf original 2019 07 13 retrieved 2019 08 29 daniel jurafsky james h. martin 2009 speech language processing pearson education international pp 145–146 lu haiping plataniotis k.n. venetsanopoulos a.n. 2011 survey multilinear subspace learning tensor data pdf pattern recognition 44 7 1540–1551 bibcode:2011patre 44.1540l. doi:10.1016 j.patcog.2011.01.004 archived pdf original 2019 07 10 retrieved 2015 09 04 yoshua bengio 2009 learning deep architectures ai publishers inc. pp 1–3 isbn 978 1 60198 294 0 archived original 2023 01 17 retrieved 2016 02 15 tillmann a. m. 2015 computational intractability exact approximate dictionary learning ieee signal processing letters 22 1 45–49 arxiv:1405.6664 bibcode:2015ispl 22 45t. doi:10.1109 lsp.2014.2345761 s2cid\", \"13342762 aharon m m elad bruckstein 2006 k svd algorithm designing overcomplete dictionaries sparse representation archived 2018 11 23 wayback machine signal processing ieee transactions 54 11 4311–4322 zimek arthur schubert erich 2017 outlier detection encyclopedia database systems springer new york pp 1–5 doi:10.1007/978 1 4899 7993 3_80719 1 isbn 9781489979933 hodge v. j. austin j. 2004 survey outlier detection methodologies pdf artificial intelligence review 22 2 85–126 citeseerx 10.1.1.318.4023 doi:10.1007 s10462 004 4304 y. s2cid 59941878 archived pdf original 2015 06 22 retrieved 2018 11 25 dokas paul ertoz levent kumar vipin lazarevic aleksandar srivastava jaideep tan pang ning 2002 data mining network intrusion detection pdf proceedings nsf workshop generation data mining archived pdf original 2015 09 23 retrieved 2023 03 26 chandola v. banerjee a. kumar v. 2009 anomaly detection survey acm computing surveys 41 3 1–58 doi:10.1145/1541880.1541882 s2cid 207172599 fleer s. moringen a. klatzky r. l. ritter h. 2020 learning efficient haptic shape exploration rigid tactile sensor array s. fleer a. moringen r. klatzky h. ritter plos 15 1 e0226880 arxiv:1902.07501 doi:10.1371 journal.pone.0226880 pmc 6940144 pmid 31896135 moringen alexandra fleer sascha walck guillaume ritter helge 2020 nisky ilana hartcher o'brien jess wiertlewski michaël smeets jeroen eds attention based robot learning haptic interaction haptics science technology applications lecture notes computer science vol 12272 cham springer international publishing pp 462–470 doi:10.1007/978 3 030 58147 3_51 isbn 978 3 030 58146 6 s2cid 220069113 piatetsky shapiro gregory 1991 discovery analysis presentation strong rules piatetsky shapiro gregory frawley william j. eds knowledge discovery databases aaai mit press cambridge ma bassel george w. glaab enrico marquez\", 'julietta holdsworth michael j. bacardit jaume 2011 09 01 functional network construction arabidopsis rule based machine learning large scale data sets plant cell 23 9 3101–3116 doi:10.1105 tpc.111.088153 issn 1532 298x. pmc 3203449 pmid 21896882 agrawal r. imieliński t. swami a. 1993 mining association rules sets items large databases proceedings 1993 acm sigmod international conference management data sigmod 93 p. 207 citeseerx 10.1.1.40.6984 doi:10.1145/170035.170072 isbn 978 0897915922 s2cid 490415 urbanowicz ryan j. moore jason h. 2009 09 22 learning classifier systems complete introduction review roadmap journal artificial evolution applications 2009 1–25 doi:10.1155/2009/736398 issn 1687 6229 plotkin g.d. automatic methods inductive inference archived 2017 12 22 wayback machine phd thesis university edinburgh 1970 shapiro ehud y. inductive inference theories facts archived 2021 08 21 wayback machine research report 192 yale university department computer science 1981 reprinted j.-l. lassez g. plotkin eds computational logic mit press cambridge ma 1991 pp 199–254 shapiro ehud y. 1983 algorithmic program debugging cambridge mass mit press isbn 0 262 19218 7 shapiro ehud y. model inference system archived 2023 04 06 wayback machine proceedings 7th international joint conference artificial intelligence volume 2 morgan kaufmann publishers inc. 1981 burkov andriy 2019 page machine learning book polen andriy burkov isbn 978 1 9995795 0 0 russell stuart j. norvig peter 2021 artificial intelligence modern approach pearson series artificial intelligence fourth ed hoboken pearson isbn 978 0 13 461099 3 honglak lee roger grosse rajesh ranganath andrew y. ng convolutional deep belief networks scalable unsupervised learning hierarchical representations archived 2017 10 18 wayback machine proceedings 26th annual international conference machine learning 2009 cortes corinna vapnik vladimir n. 1995 support vector networks machine learning 20 3 273–297 doi:10.1007 bf00994018 stevenson christopher tutorial polynomial regression', 'excel facultystaff.richmond.edu archived original 2 june 2013 retrieved 22 january 2017 documentation scikit learn similar examples archived 2022 11 02 wayback machine goldberg david e. holland john h. 1988 genetic algorithms machine learning pdf machine learning 3 2 95–99 doi:10.1007 bf00113892 s2cid 35506513 archived pdf original 2011 05 16 retrieved 2019 09 03 michie d. spiegelhalter d. j. taylor c. c. 1994 machine learning neural statistical classification ellis horwood series artificial intelligence bibcode:1994mlns.book m. zhang jun zhan zhi hui lin ying chen ni gong yue jiao zhong jing hui chung henry s.h. li yun shi yu hui 2011 evolutionary computation meets machine learning survey computational intelligence magazine 6 4 68–75 doi:10.1109 mci.2011.942584 s2cid 6760276 federated learning collaborative machine learning centralized training data google ai blog 6 april 2017 archived original 2019 06 07 retrieved 2019 06 08 machine learning included cfa curriculum discussion kathleen derose christophe le lanno 2020 machine learning archived 2020 01 13 wayback machine ivanenko mikhail smolik waldemar t. wanta damian midura mateusz wróblewski przemysław hou xiaohan yan xiaoheng 2023 image reconstruction supervised learning wearable electrical impedance tomography thorax sensors 23 18 7774 bibcode:2023senso 23.7774i. doi:10.3390 s23187774 pmc 10538128 pmid 37765831 belkor home page research.att.com netflix tech blog netflix recommendations 5 stars 1 2012 04 06 archived original 31 2016 retrieved 8 august 2015 scott patterson 13 july 2010 letting machines decide wall street journal archived original 24 june 2018 retrieved 24 june 2018 vinod khosla january 10 2012 need doctors algorithms tech crunch archived original june 18 2018 retrieved october 20 2016 machine learning algorithm studied fine art paintings saw things art historians noticed', 'archived 2016 06 04 wayback machine physics arxiv blog vincent james 2019 04 10 ai generated textbook shows robot writers actually good verge archived original 2019 05 05 retrieved 2019 05 05 vaishya raju javaid mohd khan ibrahim haleem haleem abid july 1 2020 artificial intelligence ai applications covid-19 pandemic diabetes metabolic syndrome clinical research reviews 14 4 337–339 doi:10.1016 j.dsx.2020.04.012 pmc 7195043 pmid 32305024 rezapouraghdam hamed akhshik arash ramkissoon haywantee march 10 2021 application machine learning predict visitors green behavior marine protected areas evidence cyprus journal sustainable tourism 31 11 2479–2505 doi:10.1080/09669582.2021.1887878 hdl:10037/24073 dey somdip singh amit kumar wang xiaohang mcdonald maier klaus 2020 06 15 user interaction aware reinforcement learning power thermal efficiency cpu gpu mobile mpsocs 2020 design automation test europe conference exhibition date pdf pp 1728–1733 doi:10.23919 date48585.2020.9116294 isbn 978 3 9819263 4 7 s2cid 219858480 archived original 2021 12 13 retrieved 2022 01 20 quested tony smartphones smarter essex innovation business weekly archived original 2021 06 24 retrieved 2021 06 17 williams rhiannon 2020 07 21 future smartphones prolong battery life monitoring owners behaviour i. archived original 2021 06 24 retrieved 2021 06 17 rasekhschaffe keywan christian jones robert c. 2019 07 01 machine learning stock selection financial analysts journal 75 3 70–88 doi:10.1080/0015198x.2019.1596678 issn 0015 198x. s2cid 108312507 archived original 2023 11 26 retrieved 2023 11 26 chung yunsie green william h. 2024 machine learning quantum chemistry predict experimental solvent effects reaction rates chemical science 15 7 2410–2424 doi:10.1039 d3sc05353a. issn 2041 6520 pmc 10866337 pmid 38362410 archived original 2024 05 19 retrieved 2024 04 21 sun yuran huang shih', 'kai zhao xilei 2024 02 01 predicting hurricane evacuation decisions interpretable machine learning methods international journal disaster risk science 15 1 134–148 doi:10.1007 s13753 024 00541 1 issn 2192 6395 sun yuran zhao xilei lovreglio ruggiero kuligowski erica 2024 01 01 naser m. z. ed 8 ai large scale evacuation modeling promises challenges interpretable machine learning analysis design assessment informed decision making civil infrastructure woodhead publishing series civil structural engineering woodhead publishing pp 185–204 isbn 978 0 12 824073 1 archived original 2024 05 19 retrieved 2024 05 19 xu ningzhe lovreglio ruggiero kuligowski erica d. cova thomas j. nilsson daniel zhao xilei 2023 03 01 predicting assessing wildfire evacuation decision making machine learning findings 2019 kincade fire fire technology 59 2 793–825 doi:10.1007 s10694 023 01363 1 issn 1572 8099 archived original 2024 05 19 retrieved 2024 05 19 wang ke shi xiupeng goh algena pei xuan qian shunzhi 2019 06 01 machine learning based study pedestrian movement dynamics emergency evacuation fire safety journal 106 163–176 doi:10.1016 j.firesaf.2019.04.008 hdl:10356/143390 issn 0379 7112 archived original 2024 05 19 retrieved 2024 05 19 zhao xilei lovreglio ruggiero nilsson daniel 2020 05 01 modelling interpreting pre evacuation decision making machine learning automation construction 113 103140 doi:10.1016 j.autcon.2020.103140 issn 0926 5805 archived original 2024 05 19 retrieved 2024 05 19 machine learning models fail learn quicktake q&a bloomberg.com 2016 11 10 archived original 2017 03 20 retrieved 2017 04 10 wave corporate ai doomed fail harvard business review 2017 04 18 archived original 2018 08 21 retrieved 2018 08 20 a.i. euphoria doomed fail venturebeat 2016 09', '18 archived original 2018 08 19 retrieved 2018 08 20 9 reasons machine learning project fail www.kdnuggets.com archived original 2018 08 21 retrieved 2018 08 20 babuta alexander oswald marion rinik christine 2018 transparency intelligibility report royal united services institute rusi pp 17–22 archived original 2023 12 09 retrieved 2023 12 09 uber self driving car killed pedestrian economist archived original 2018 08 21 retrieved 2018 08 20 ibm watson recommended unsafe incorrect cancer treatments stat stat 2018 07 25 archived original 2018 08 21 retrieved 2018 08 21 hernandez daniela greenwald ted 2018 08 11 ibm watson dilemma wall street journal issn 0099 9660 archived original 2018 08 21 retrieved 2018 08 21 allyn bobby feb 27 2023 microsoft experiment artificial intelligence tech backfired national public radio archived original december 8 2023 retrieved dec 8 2023 reddy shivani m. patel sheila weyrich meghan fenton joshua viswanathan meera 2020 comparison traditional systematic review approach review reviews semi automation strategies update evidence systematic reviews 9 1 243 doi:10.1186 s13643 020 01450 2 issn 2046 4053 pmc 7574591 pmid 33076975 garcia megan 2016 racist machine world policy journal 33 4 111–117 doi:10.1215/07402775 3813015 issn 0740 2775 s2cid 151595343 caliskan aylin bryson joanna j. narayanan arvind 2017 04 14 semantics derived automatically language corpora contain human like biases science 356 6334 183–186 arxiv:1608.07187 bibcode:2017sci 356 183c. doi:10.1126 science.aal4230 issn 0036 8075 pmid 28408601 s2cid 23163324 wang xinan dasgupta sanjoy 2016 lee d. d. sugiyama m. luxburg u. v. guyon i. eds algorithm l1 nearest neighbor search monotonic embedding pdf', 'advances neural information processing systems 29 curran associates inc. pp 983–991 archived pdf original 2017 04 07 retrieved 2018 08 20 silva selena kenney martin 2018 algorithms platforms ethnic bias integrative essay pdf phylon 55 1 2 9–37 issn 0031 8906 jstor 26545017 archived pdf original jan 27 2024 vincent james jan 12 2018 google fixed racist algorithm removing gorillas image labeling tech verge archived original 2018 08 21 retrieved 2018 08 20 crawford kate 25 june 2016 opinion | artificial intelligence white guy problem new york times archived original 2021 01 14 retrieved 2018 08 20 metz rachel march 24 2016 microsoft accidentally unleashed neo nazi sexbot mit technology review archived original 2018 11 09 retrieved 2018 08 20 simonite tom march 30 2017 microsoft ai adaptable help businesses mit technology review archived original 2018 11 09 retrieved 2018 08 20 hempel jessi 2018 11 13 fei fei li quest machines better humanity wired issn 1059 1028 archived original 2020 12 14 retrieved 2019 02 17 rudin cynthia 2019 stop explaining black box machine learning models high stakes decisions use interpretable models instead nature machine intelligence 1 5 206–215 doi:10.1038 s42256 019 0048 x. pmc 9122117 pmid 35603010 hu tongxi zhang xuesong bohrer gil liu yanlan zhou yuyu martin jay li yang zhao kaiguang 2023 crop yield prediction explainable ai interpretable machine learning dangers black box models evaluating climate change impacts crop yield agricultural forest meteorology 336 109458 doi:10.1016 j.agrformet.2023.109458 s2cid 258552400 domingos 2015 chapter 6 chapter 7 domingos 2015 p. 286 single pixel change fools ai programs bbc news 3 november 2017 archived original 22 march 2018 retrieved 12 march', '2018 ai hallucination problem proving tough fix wired 2018 archived original 12 march 2018 retrieved 12 march 2018 madry a. makelov a. schmidt l. tsipras d. vladu a. 4 september 2019 deep learning models resistant adversarial attacks arxiv:1706.06083 stat ml adversarial machine learning cltc uc berkeley center long term cybersecurity cltc archived original 2022 05 17 retrieved 2022 05 25 machine learning models vulnerable undetectable backdoors register archived original 13 2022 retrieved 13 2022 undetectable backdoors plantable machine learning algorithm ieee spectrum 10 2022 archived original 11 2022 retrieved 13 2022 goldwasser shafi kim michael p. vaikuntanathan vinod zamir 14 april 2022 planting undetectable backdoors machine learning models arxiv:2204.06974 cs lg kohavi ron 1995 study cross validation bootstrap accuracy estimation model selection pdf international joint conference artificial intelligence archived pdf original 2018 07 12 retrieved 2023 03 26 pontius robert gilmore si kangping 2014 total operating characteristic measure diagnostic ability multiple thresholds international journal geographical information science 28 3 570–583 bibcode:2014ijgis 28 570p. doi:10.1080/13658816.2013.862623 s2cid 29204880 bostrom nick 2011 ethics artificial intelligence pdf archived original pdf 4 march 2016 retrieved 11 april 2016 edionwe tolulope fight racist algorithms outline archived original 17 november 2017 retrieved 17 november 2017 jeffries adrianne machine learning racist internet racist outline archived original 17 november 2017 retrieved 17 november 2017 wong carissa 2023 03 30 ai fairness research held lack diversity nature doi:10.1038 d41586 023 00935 z. pmid 36997714 s2cid 257857012 archived original 2023 04 12 retrieved 2023 12 09 zhang jack clark artificial intelligence index report 2021 pdf stanford institute human centered artificial intelligence', 'archived pdf original 2024 05 19 retrieved 2023 12 09 bostrom nick yudkowsky eliezer 2011 ethics artificial intelligence pdf nick bostrom archived pdf original 2015 12 20 retrieved 2020 11 18 m.o.r. prates p.h.c. avelar l.c. lamb 11 mar 2019 assessing gender bias machine translation case study google translate arxiv:1809.02208 cs cy narayanan arvind august 24 2016 language necessarily contains human biases machines trained language corpora freedom tinker archived original june 25 2018 retrieved november 19 2016 char danton s. shah nigam h. magnus david 2018 03 15 implementing machine learning health care addressing ethical challenges new england journal medicine 378 11 981–983 doi:10.1056 nejmp1714229 issn 0028 4793 pmc 5962261 pmid 29539284 char d. s. shah n. h. magnus d. 2018 implementing machine learning health care addressing ethical challenges new england journal medicine 378 11 981–983 doi:10.1056 nejmp1714229 pmc 5962261 pmid 29539284 research ai 23 october 2015 deep neural networks acoustic modeling speech recognition airesearch.com archived original 1 february 2016 retrieved 23 october 2015 gpus continue dominate ai accelerator market informationweek december 2019 archived original 10 june 2020 retrieved 11 june 2020 ray tiernan 2019 ai changing entire nature compute zdnet archived original 25 2020 retrieved 11 june 2020 ai compute openai 16 2018 archived original 17 june 2020 retrieved 11 june 2020 cornell ntt physical neural networks radical alternative implementing deep neural networks enables arbitrary physical systems training | synced 27 2021 archived original 27 october 2021 retrieved 12 october 2021 nano spaghetti solve neural network power consumption archived original 2021 10 06 retrieved 2021 10 12 fafoutis xenofon marchegiani letizia elsts atis pope james piechocki robert craddock ian 2018 05 07', 'extending battery lifetime wearable sensors embedded machine learning 2018 ieee 4th world forum internet things wf iot pp 269–274 doi:10.1109 wf iot.2018.8355116 hdl:1983 b8fdb58b-7114 45c6 82e4 4ab239c1327f isbn 978 1 4673 9944 9 s2cid 19192912 archived original 2022 01 18 retrieved 2022 01 17 beginner guide machine learning embedded systems analytics india magazine 2021 06 02 archived original 2022 01 18 retrieved 2022 01 17 synced 2022 01 12 google purdue harvard u open source framework tinyml achieves 75x speedups fpgas | synced syncedreview.com archived original 2022 01 18 retrieved 2022 01 17 giri davide chiu kuan lin di guglielmo giuseppe mantovani paolo carloni luca p. 2020 06 15 esp4ml platform based design systems chip embedded machine learning 2020 design automation test europe conference exhibition date pp 1049–1054 arxiv:2004.03640 doi:10.23919 date48585.2020.9116317 isbn 978 3 9819263 4 7 s2cid 210928161 archived original 2022 01 18 retrieved 2022 01 17 louis marcia sahaya azad zahra delshadtehrani leila gupta suyog warden pete reddi vijay janapa joshi ajay 2019 deep learning tensorflow lite risc v harvard university archived original 2022 01 17 retrieved 2022 01 17 ibrahim ali osta mario alameh mohamad saleh moustafa chible hussein valle maurizio 2019 01 21 approximate computing methods embedded machine learning 2018 25th ieee international conference electronics circuits systems icecs pp 845–848 doi:10.1109 icecs.2018.8617877 isbn 978 1 5386 9562 3 s2cid 58670712 archived original 2022 01 17 retrieved 2022 01 17 dblp tensorflow eager multi stage python embedded dsl machine learning dblp.org archived original 2022 01 18 retrieved 2022 01 17 branco sérgio ferreira andré g. cabral jorge 2019 11 05', 'machine learning resource scarce embedded systems fpgas end devices survey electronics 8 11 1289 doi:10.3390 electronics8111289 hdl:1822/62521 issn 2079 9292 sources domingos pedro september 22 2015 master algorithm quest ultimate learning machine remake world basic books isbn 978 0465065707 nilsson nils 1998 artificial intelligence new synthesis morgan kaufmann isbn 978 1 55860 467 4 archived original 26 july 2020 retrieved 18 november 2019 russell stuart j. norvig peter 2003 artificial intelligence modern approach 2nd ed upper saddle river new jersey prentice hall isbn 0 13 790395 2 poole david mackworth alan goebel randy 1998 computational intelligence logical approach new york oxford university press isbn 978 0 19 510270 3 archived original 26 july 2020 retrieved 22 august 2020 reading nils j. nilsson introduction machine learning archived 2019 08 16 wayback machine trevor hastie robert tibshirani jerome h. friedman 2001 elements statistical learning archived 2013 10 27 wayback machine springer isbn 0 387 95284 5 pedro domingos september 2015 master algorithm basic books isbn 978 0 465 06570 7 ian h. witten eibe frank 2011 data mining practical machine learning tools techniques morgan kaufmann 664pp isbn 978 0 12 374856 0 ethem alpaydin 2004 introduction machine learning mit press isbn 978 0 262 01243 0 david j. c. mackay information theory inference learning algorithms archived 2016 02 17 wayback machine cambridge cambridge university press 2003 isbn 0 521 64298 1 richard o. duda peter e. hart david g. stork 2001 pattern classification 2nd edition wiley new york isbn 0 471 05669 3 christopher bishop 1995 neural networks pattern recognition oxford university press isbn 0 19 853864 2 stuart russell peter norvig 2009 artificial intelligence modern approach archived 2011 02 28 wayback machine pearson isbn 9789332543515 ray solomonoff', 'inductive inference machine ire convention record section information theory 2 pp 56–62 1957 ray solomonoff inductive inference machine archived 2011 04 26 wayback machine privately circulated report 1956 dartmouth summer research conference ai kevin p. murphy 2021 probabilistic machine learning introduction archived 2021 04 11 wayback machine mit press external links wikimedia commons media related machine learning quotations related machine learning wikiquote international machine learning society mloss academic database open source machine learning software']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from FlagEmbedding import BGEM3FlagModel\n",
        "\n",
        "model = BGEM3FlagModel('BAAI/bge-m3',\n",
        "                       use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "dad12d06c1a44a018c6026fb27244c6a",
            "8ce480ef53764d6485afe8063bf2b2d0",
            "e1bcc1acf1d342bbb59bf98936fa112a",
            "3fa53b961f394848b6031ad986699e1a",
            "5f56720d07c540e1b1145c06efbccf7a",
            "ba1dcbb19bb84283925a5b3849ab5e4c",
            "ef974dc5bbd849d8881174903c251ecf",
            "6b43bf0a6d21403f914acf762fa61682",
            "9054c7eb35f840a990d5a10f26cb82e9",
            "5c3c47250bb145bebc202815be3aea2a",
            "362dede522cd4fbe96f86790d2c403e8"
          ]
        },
        "id": "L6J2nlvR15tZ",
        "outputId": "7b37da65-eb1f-4799-8d09-151b1b351bb1"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 30 files:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dad12d06c1a44a018c6026fb27244c6a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_1 = model.encode(chunks,\n",
        "                            return_dense=True, return_sparse=False, return_colbert_vecs=False,\n",
        "                            batch_size=12,\n",
        "                            max_length=512, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.\n",
        "                            )['dense_vecs']\n",
        "\n",
        "## Store it in indexdb"
      ],
      "metadata": {
        "id": "4ryqMxZk2h5E"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def retrieve_relevant_chunks(query, chunks, embeddings, top_k=10):\n",
        "\n",
        "  # embedding = select query from indexid whch is the indexdb\n",
        "\n",
        "    # Encode the query\n",
        "    query_embedding = model.encode([query])['dense_vecs'][0]\n",
        "\n",
        "\n",
        "    limit = 3600\n",
        "\n",
        "\n",
        "    # Compute inner product between query embedding and chunk embeddings\n",
        "    similarities = np.inner(query_embedding, embeddings)\n",
        "\n",
        "    # Sort the similarities and get the indices of top-k similar chunks\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "\n",
        "    # Retrieve the top-k similar chunks\n",
        "    contexts = [chunks[idx] for idx in top_indices]\n",
        "\n",
        "\n",
        "    prompt_start = (\n",
        "        \"Given the contextual information and not prior knowledge, answer the question. If the answer is not in the context, inform the user that you can't answer the question.\\n\\n\"+\n",
        "        \"Context:\\n\"\n",
        "    )\n",
        "    prompt_end = (\n",
        "        f\"\\n\\nQuestion: {query}\\nAnswer:\"\n",
        "    )\n",
        "    # append contexts until hitting limit\n",
        "    for i in range(1, len(contexts)):\n",
        "        if len(\"\\n\\n---\\n\\n\".join(contexts[:i])) >= limit:\n",
        "            prompt = (\n",
        "                prompt_start +\n",
        "                \"\\n\\n---\\n\\n\".join(contexts[:i-1]) +\n",
        "                prompt_end\n",
        "            )\n",
        "            break\n",
        "        elif i == len(contexts)-1:\n",
        "            prompt = (\n",
        "                prompt_start +\n",
        "                \"\\n\\n---\\n\\n\".join(contexts) +\n",
        "                prompt_end\n",
        "            )\n",
        "    return prompt\n",
        "\n",
        "    return relevant_chunks\n",
        "\n",
        "# Example usage\n",
        "query = \"what is machine learning\"\n",
        "relevant_chunks = retrieve_relevant_chunks(query, chunks, embeddings_1, top_k=3)\n",
        "\n",
        "print(relevant_chunks)\n",
        "# Output: ['a new car', 'affordable', 'fuel-efficient']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJxBzCYl8q1K",
        "outputId": "a22f9a94-bf78-47d4-b318-0dfb8cab934a"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the contextual information and not prior knowledge, answer the question. If the answer is not in the context, inform the user that you can't answer the question.\n",
            "\n",
            "Context:\n",
            "journal machine learning journal statistical learning redirects statistical learning linguistics statistical learning language acquisition series machine learning data mining paradigms problems supervised learning classification regression clustering dimensionality reduction structured prediction anomaly detection artificial neural network reinforcement learning learning humans model diagnostics mathematical foundations machine learning venues related articles vte series artificial intelligence major goals artificial general intelligenceintelligent agentrecursive self improvementplanningcomputer visiongeneral game playingknowledge reasoningnatural language processingroboticsai safety approaches applications philosophy history glossary vte machine learning ml field study artificial intelligence concerned development study statistical algorithms learn data generalize unseen data perform tasks explicit instructions.[1 recently artificial neural networks able surpass previous approaches performance.[2 ml finds application fields including natural language processing computer vision speech recognition email filtering agriculture medicine.[3][4 applied business problems known predictive analytics machine learning statistically based computational statistics important source field methods mathematical foundations ml provided mathematical optimization mathematical programming methods data mining related parallel field study focusing exploratory data analysis eda unsupervised learning.[6][7 theoretical viewpoint probably approximately correct pac learning provides framework describing machine learning history timeline machine learning term machine learning coined 1959 arthur samuel ibm employee pioneer field computer gaming artificial intelligence.[8][9 synonym self teaching computers time period.[10][11 earliest machine learning model introduced 1950s arthur samuel invented program calculated winning chance checkers history machine learning roots decades human desire effort study human cognitive processes.[12 1949 canadian psychologist donald hebb published book organization behavior introduced theoretical neural structure formed certain interactions nerve cells.[13 hebb model neurons interacting set groundwork ais machine learning algorithms work nodes artificial neurons computers communicate data.[12 researchers studied human cognitive systems contributed modern machine learning technologies including logician walter pitts warren mcculloch proposed\n",
            "\n",
            "Question: what is machine learning\n",
            "Answer:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Copy the output and pass it to azure playground to test"
      ],
      "metadata": {
        "id": "yWCghH_96iIM"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EjTfFG3ePFNk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}